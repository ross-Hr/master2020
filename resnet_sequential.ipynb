{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version:  1.2.0\n",
      "cuda available:  False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "from math import *\n",
    "from backpack import backpack, extend\n",
    "from backpack.extensions import KFAC, DiagHessian\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy\n",
    "from tqdm import tqdm, trange\n",
    "import pytest\n",
    "import matplotlib.pyplot as plt\n",
    "from DirLPA_utils import * \n",
    "\n",
    "print(\"pytorch version: \", torch.__version__)\n",
    "print(\"cuda available: \", torch.cuda.is_available())\n",
    "\n",
    "s = 123\n",
    "np.random.seed(s)\n",
    "torch.manual_seed(s)\n",
    "torch.cuda.manual_seed(s)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE_TRAIN_CIFAR10 = 5 #128\n",
    "BATCH_SIZE_TEST_CIFAR10 = 128\n",
    "\n",
    "transform_base = [transforms.ToTensor()]\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "    ] + transform_base)\n",
    "\n",
    "transform_test = transforms.Compose(transform_base)\n",
    "transform_train = transforms.RandomChoice([transform_train, transform_test])\n",
    "\n",
    "#~/data/cifar10\n",
    "CIFAR10_trainset = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=True, download=True, transform=transform_train)\n",
    "CIFAR10_train_loader = torch.utils.data.DataLoader(CIFAR10_trainset, batch_size=BATCH_SIZE_TRAIN_CIFAR10, shuffle=True, num_workers=2)\n",
    "\n",
    "#~/data/cifar10\n",
    "CIFAR10_testset = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=False, download=True, transform=transform_test)\n",
    "CIFAR10_test_loader = torch.utils.data.DataLoader(CIFAR10_testset, batch_size=BATCH_SIZE_TEST_CIFAR10, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "dataiter = iter(CIFAR10_train_loader)\n",
    "images, labels = dataiter.next()\n",
    "nrow = int(BATCH_SIZE_TRAIN_CIFAR10/4)\n",
    "imshow(torchvision.utils.make_grid(images, nrow=nrow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, num_of_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_of_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "    def features(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18(num_of_channels=3, num_classes=10):\n",
    "    if num_classes <= 2:\n",
    "        num_classes = 1\n",
    "\n",
    "    return ResNet(BasicBlock, [2,2,2,2],\n",
    "                  num_of_channels=num_of_channels,\n",
    "                  num_classes=num_classes)\n",
    "\n",
    "def ResNet18(num_classes=10):\n",
    "    return ResNet(BasicBlock, [2,2,2,2], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet as sequential\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, shortcut, shortcut_bool):\n",
    "        super().__init__()\n",
    "        self.shortcut = shortcut\n",
    "        self.shortcut_bool = shortcut_bool\n",
    "        \n",
    "        self.activation = {}\n",
    "        def get_activation(name):\n",
    "            def hook(self, input, output):\n",
    "                self.activation[name] = output.detach()\n",
    "            return hook\n",
    "        \n",
    "        def hookFunc(self, gradInput, gradOutput):\n",
    "            print(\"grad input: \", len(gradInput))\n",
    "        \n",
    "        if shortcut_bool:\n",
    "            self.shortcut[1].register_forward_hook(get_activation('shortcut_cout'))\n",
    "            self.shortcut[1].register_forward_hook(hookFunc)\n",
    "            self.shortcut[1].register_backward_hook(hookFunc)\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Adds the residual to the normal stream\n",
    "        '''\n",
    "        \n",
    "        print(\"shortcut: \", self.shortcut)\n",
    "        if not self.shortcut_bool:\n",
    "            out = input\n",
    "        else:\n",
    "            print(self.shortcut[1])\n",
    "            print(self.activation)\n",
    "            out = input + self.activation['shortcut_out']\n",
    "        return(out)\n",
    "\n",
    "def BasicBlockSeq(in_planes, planes, stride=1):\n",
    "    \n",
    "    expansion=1 #where does this come from?\n",
    "    \n",
    "    shortcut_bool = False\n",
    "    shortcut = nn.Sequential()\n",
    "    if stride != 1 or in_planes != expansion*planes:\n",
    "        shortcut_bool = True\n",
    "        shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(expansion*planes)\n",
    "        )        \n",
    "    \n",
    "    basic_block1 = nn.Sequential(\n",
    "        nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(planes),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(planes),\n",
    "        Residual(shortcut, shortcut_bool),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "    basic_block = nn.Sequential(\n",
    "        #*(list(basic_block1)+list(shortcut)),\n",
    "        #*(np.array(list(basic_block1)) + np.array(list(shortcut))),\n",
    "        Residual(shortcut)),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    return(basic_block1)\n",
    "\n",
    "def make_layer(block, in_planes, planes, num_blocks, stride):\n",
    "        \n",
    "        #global in_planes\n",
    "        \n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(in_planes, planes, stride))\n",
    "            in_planes = planes * 1 #replacement for block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "def ResNetSeq(block, num_blocks, num_classes=10, num_of_channels=3):\n",
    "    \n",
    "    #global in_planes\n",
    "    #in_planes= 64\n",
    "\n",
    "    features = nn.Sequential(\n",
    "        nn.Conv2d(num_of_channels, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        make_layer(block, 64, 64, num_blocks[0], stride=1),\n",
    "        #nn.Conv2d(num_of_channels, 1234, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "        make_layer(block, 64, 128, num_blocks[1], stride=2),\n",
    "        make_layer(block, 128, 256, num_blocks[2], stride=2),\n",
    "        make_layer(block, 256, 512, num_blocks[3], stride=2),\n",
    "        nn.AvgPool2d(4),\n",
    "        nn.Flatten()\n",
    "    )\n",
    "        \n",
    "    linear = nn.Linear(512*1, num_classes) #1 is standin for block.expansion\n",
    "    \n",
    "    resnet = nn.Sequential(\n",
    "        features,\n",
    "        linear\n",
    "    )\n",
    "    \n",
    "    return(resnet)\n",
    "\n",
    "def ResNet18Seq(num_classes=10):\n",
    "    return ResNetSeq(BasicBlockSeq, [2,2,2,2], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "cuda_status = torch.cuda.is_available()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, epoch, testloader, path, save=False):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "        acc = correct/total\n",
    "        if acc > best_acc and save: \n",
    "            best_acc = acc\n",
    "            print(\"saving model at: {}\".format(path))\n",
    "            torch.save(net.state_dict(), path)\n",
    "\n",
    "\n",
    "        print(\"test loss: \", test_loss)\n",
    "        print(\"current acc: {}; best acc: {}\".format(acc, best_acc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### if you already have a trained model ##############\n",
    "CIFAR10_PATH = 'weights/CIFAR10_pretrained.pt'\n",
    "#CIFAR10_model = ResNet18().to(device)\n",
    "#print(\"loading model from: {}\".format(CIFAR10_PATH))\n",
    "#CIFAR10_model.load_state_dict(torch.load(CIFAR10_PATH))#, map_location=torch.device('cpu')))\n",
    "#test the model\n",
    "#test(CIFAR10_model, 0, CIFAR10_test_loader, save=False, path=CIFAR10_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading state dict:  122\n",
      "model state dict:  122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CIFAR10_model_Seq = ResNet18Seq(num_classes=10)\n",
    "state_dict = torch.load(CIFAR10_PATH)\n",
    "\n",
    "def rename_keys(d, keys):\n",
    "    return dict([(keys.get(k), v) for k, v in d.items()])\n",
    "\n",
    "sd_keys = list(state_dict.keys())\n",
    "model_keys = list(CIFAR10_model_Seq.state_dict().keys())\n",
    "\n",
    "print(\"loading state dict: \", len(sd_keys))\n",
    "print(\"model state dict: \", len(model_keys))\n",
    "\n",
    "translation = {sd_keys[i] : model_keys[i] for i in range(len(model_keys))}\n",
    "\n",
    "new_state_dict = rename_keys(state_dict, translation)\n",
    "\n",
    "CIFAR10_model_Seq.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shortcut:  Sequential()\n",
      "shortcut:  Sequential()\n",
      "shortcut:  Sequential(\n",
      "  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "{}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'shortcut_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-31a372e2ffd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mCIFAR10_model_Seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet18Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCIFAR10_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mCIFAR10_model_Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-178-ac5556d071ba>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shortcut_out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'shortcut_out'"
     ]
    }
   ],
   "source": [
    "CIFAR10_model_Seq = ResNet18Seq(num_classes=10)\n",
    "test_X, _ = next(iter(CIFAR10_train_loader))\n",
    "CIFAR10_model_Seq(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Hessian_NN(model, train_loader, prec0, device='cpu', verbose=True):\n",
    "    lossfunc = torch.nn.CrossEntropyLoss()\n",
    "    #lossfunc = torch.nn.BCELoss()\n",
    "\n",
    "    extend(lossfunc, debug=False)\n",
    "    extend(model, debug=False)\n",
    "\n",
    "    Hessian_diag = []\n",
    "    for param in model.parameters():\n",
    "        ps = param.size()\n",
    "        print(\"parameter size: \", ps)\n",
    "        Hessian_diag.append(torch.zeros(ps, device=device))\n",
    "        #print(param.numel())\n",
    "\n",
    "    var0 = 1/prec0\n",
    "    max_len = len(train_loader)\n",
    "\n",
    "    with backpack(DiagHessian()):\n",
    "\n",
    "        for batch_idx, (x, y) in enumerate(train_loader):\n",
    "\n",
    "            if device == 'cuda':\n",
    "                x, y = x.float().cuda(), y.long().cuda()\n",
    "\n",
    "            model.zero_grad()\n",
    "            lossfunc(model(x), y).backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Hessian of weight\n",
    "                for idx, param in enumerate(model.parameters()):\n",
    "\n",
    "                    H_ = param.diag_h\n",
    "                    #add prior here\n",
    "                    H_ += var0 * torch.ones(H_.size())\n",
    "\n",
    "                    rho = 1-1/(batch_idx+1)\n",
    "\n",
    "                    Hessian_diag[idx] = rho*Hessian_diag[idx] + (1-rho)* H_\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Batch: {}/{}\".format(batch_idx, max_len))\n",
    "    \n",
    "    return(Hessian_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_diag_Hessian = get_Hessian_NN(CIFAR10_model_Seq, CIFAR10_train_loader, prec0=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal working Resnet Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "\n",
    "BATCH_SIZE_TRAIN_CIFAR10 = 5 #128\n",
    "BATCH_SIZE_TEST_CIFAR10 = 128\n",
    "\n",
    "transform_base = [transforms.ToTensor()]\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "    ] + transform_base)\n",
    "\n",
    "transform_test = transforms.Compose(transform_base)\n",
    "transform_train = transforms.RandomChoice([transform_train, transform_test])\n",
    "\n",
    "#~/data/cifar10\n",
    "CIFAR10_trainset = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=True, download=True, transform=transform_train)\n",
    "CIFAR10_train_loader = torch.utils.data.DataLoader(CIFAR10_trainset, batch_size=BATCH_SIZE_TRAIN_CIFAR10, shuffle=True, num_workers=2)\n",
    "\n",
    "#~/data/cifar10\n",
    "CIFAR10_testset = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=False, download=True, transform=transform_test)\n",
    "CIFAR10_test_loader = torch.utils.data.DataLoader(CIFAR10_testset, batch_size=BATCH_SIZE_TEST_CIFAR10, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal example in the \"classic\" (non-sequential) fashion\n",
    "class MiniNet(nn.Module):\n",
    "    def __init__(self, input_size=32*32, num_classes=10):\n",
    "        super(MiniNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.linear1 = nn.Linear(input_size, 32) \n",
    "        self.linear2 = nn.Linear(32, input_size)\n",
    "        \n",
    "        self.skip = nn.Sequential()\n",
    "        self.linear3 = nn.Linear(input_size, num_classes) \n",
    "\n",
    "    def forward(self, x):\n",
    "        flat_inp = x.view(-1, self.input_size)\n",
    "        out = self.linear1(flat_inp)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        \n",
    "        out += self.skip(flat_inp) #this is the residual/skip/shortcut connection\n",
    "        \n",
    "        out = F.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        \n",
    "        return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4973, -0.0799, -0.3279, -0.4526,  0.1181,  0.6824, -0.1357,  0.2714,\n",
       "         -0.2514, -0.3652],\n",
       "        [ 0.5190, -0.0853, -0.3222, -0.4598,  0.1172,  0.7234, -0.1312,  0.2935,\n",
       "         -0.2659, -0.3756],\n",
       "        [ 0.3841, -0.0797, -0.2848, -0.4395,  0.0845,  0.5778, -0.1317,  0.2965,\n",
       "         -0.2231, -0.3266],\n",
       "        [ 0.6029, -0.4460, -0.2653, -0.4012,  0.1394,  1.4164, -0.1854,  0.3005,\n",
       "         -0.3686, -0.2970],\n",
       "        [ 0.5876, -0.4188, -0.3367, -0.4381,  0.1577,  1.3537, -0.1903,  0.2880,\n",
       "         -0.3459, -0.3448],\n",
       "        [ 0.6085, -0.3416, -0.3882, -0.4506,  0.1777,  1.1680, -0.1808,  0.1902,\n",
       "         -0.3165, -0.4483],\n",
       "        [ 0.4077, -0.2051, -0.0622, -0.3051,  0.0499,  0.9265, -0.2150,  0.2162,\n",
       "         -0.1734, -0.1458],\n",
       "        [ 0.5065, -0.1166, -0.2810, -0.4933,  0.1653,  0.9874, -0.2526,  0.1511,\n",
       "         -0.1708, -0.2113],\n",
       "        [ 0.2627, -0.1724, -0.0028, -0.2112,  0.0301,  0.6532, -0.1570,  0.1148,\n",
       "         -0.1365, -0.1002],\n",
       "        [ 0.5141,  0.0270, -0.4600, -0.4231,  0.1841,  0.8655, -0.3343,  0.1202,\n",
       "         -0.3040, -0.2684],\n",
       "        [ 0.5918,  0.0450, -0.4953, -0.4344,  0.1883,  0.9082, -0.3517,  0.1407,\n",
       "         -0.3065, -0.3005],\n",
       "        [ 0.6279,  0.0989, -0.4844, -0.3907,  0.1825,  0.8416, -0.3459,  0.0903,\n",
       "         -0.2987, -0.2665],\n",
       "        [ 0.5094,  0.1397, -0.2291, -0.2147,  0.0427,  0.3913, -0.1807, -0.2087,\n",
       "         -0.0593, -0.2276],\n",
       "        [ 0.4377,  0.1346, -0.1908, -0.1850,  0.0363,  0.3506, -0.1559, -0.2189,\n",
       "         -0.0548, -0.1911],\n",
       "        [ 0.3996,  0.1201, -0.1672, -0.1807,  0.0354,  0.3440, -0.1442, -0.2222,\n",
       "         -0.0598, -0.1886]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MiniNet = MiniNet()\n",
    "test_X, _ = next(iter(CIFAR10_train_loader))\n",
    "MiniNet(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Mini Resnet as a sequential\n",
    "def get_outputs_(x):\n",
    "        return(None)  #<- I have tried to work around with forward and backward hooks\n",
    "                      # but that does not seem to work so far\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, skip):\n",
    "        super().__init__()\n",
    "        self.skip = skip\n",
    "        \n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Adds the residual to the normal stream\n",
    "        '''\n",
    "        out_skip = get_outputs_(self.skip) #<- this is where the magic needs to happen\n",
    "        out = input + out_skip\n",
    "        return(out)\n",
    "\n",
    "def MiniNetSeq(input_size=32*32, num_classes=10, color_channels=3):\n",
    "    \n",
    "    skip = nn.Sequential()\n",
    "    \n",
    "    mini_net = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(input_size*color_channels, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, input_size*color_channels),\n",
    "        Residual(skip),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(input_size, num_classes)\n",
    "    )\n",
    "    \n",
    "    return(mini_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add(): argument 'other' (position 1) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8573ffa6bf1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mMiniNetSeq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMiniNetSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mMiniNetSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-7e09513ff092>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     13\u001b[0m         '''\n\u001b[1;32m     14\u001b[0m         \u001b[0mout_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_outputs_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#<- this is where the magic needs to happen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout_skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: add(): argument 'other' (position 1) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "MiniNetSeq = MiniNetSeq(num_classes=10)\n",
    "MiniNetSeq(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
