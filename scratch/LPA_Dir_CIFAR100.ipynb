{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Quick example: A small second-order optimizer with BackPACK\n",
    "on the classic MNIST example from PyTorch,\n",
    "https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "\n",
    "The optimizer we implement uses a constant damping parameter\n",
    "and uses the diagonal of the GGN/Fisher matrix as a preconditioner;\n",
    "\n",
    "```\n",
    "x_{t+1} = x_t - (G_t + bI)^{-1} g_t\n",
    "```\n",
    "\n",
    "- `x_t` are the parameters of the model\n",
    "- `G_t` is the diagonal of the Gauss-Newton/Fisher matrix at `x_t`\n",
    "- `b` is a damping parameter\n",
    "- `g_t` is the gradient\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "# The main BackPACK functionalities\n",
    "#from backpack import backpack, extend\n",
    "# The diagonal GGN extension\n",
    "#from backpack.extensions import DiagGGNMC\n",
    "# This layer did not exist in Pytorch 1.0\n",
    "#from backpack.core.layers import Flatten\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "STEP_SIZE_TRAIN = 0.00001 #from 0.01\n",
    "STEP_SIZE_HESS = 0.0001\n",
    "DAMPING = 1.0\n",
    "MAX_ITER = 6\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def get_accuracy(output, targets):\n",
    "    \"\"\"Helper function to print the accuracy\"\"\"\n",
    "    predictions = output.argmax(dim=1, keepdim=True).view_as(targets)\n",
    "    return predictions.eq(targets).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 2: Create the optimizer.\n",
    "\n",
    "After we call the backward pass with backpack,\n",
    "every parameter will have a `diag_ggn_mc` field\n",
    "in addition to a `grad` field.\n",
    "\n",
    "We can use it to compute the search direction for that parameter,\n",
    "```\n",
    "step_direction = p.grad / (p.diag_ggn_mc + group[\"damping\"])\n",
    "```\n",
    "and update the weights\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class DiagGGNOptimizer(torch.optim.Optimizer):\n",
    "    def __init__(self, parameters, step_size, damping):\n",
    "        super().__init__(\n",
    "            parameters, \n",
    "            dict(step_size=step_size, damping=damping)\n",
    "        )\n",
    "\n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                step_direction = p.grad / (p.diag_ggn_mc + group[\"damping\"])\n",
    "                p.data.add_(-group[\"step_size\"], step_direction)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_second_order_infos(model, data_loader, optimizer, num_classes, batch_size, save_path):\n",
    "    print(\"get the second order information for the trained model\")\n",
    "\n",
    "    mus_last_layer_w = []\n",
    "    mus_last_layer_b = []\n",
    "    sigmas_last_layer_w = []\n",
    "    sigmas_last_layer_b = []\n",
    "    \n",
    "    extend(model)\n",
    "    extend(loss_function)\n",
    "\n",
    "\n",
    "    for hessian_idx, (x,y) in enumerate(data_loader):\n",
    "\n",
    "        output = model(x)\n",
    "        max_len = int(np.ceil(len(data_loader.dataset)/batch_size))\n",
    "\n",
    "        accuracy = get_accuracy(output, y)\n",
    "\n",
    "        with backpack(DiagGGNMC()):\n",
    "            loss = loss_function(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"{}/{} batches \\t acc: {:3f}\".format(hessian_idx, max_len, accuracy))\n",
    "        groups = optimizer.param_groups\n",
    "        #print(\"groups: \", groups)\n",
    "        mus = []\n",
    "        sigmas = []\n",
    "        for g in groups:\n",
    "            for p in g['params']:\n",
    "                #print(\"p.size: \", p.size())\n",
    "                mus.append(p)\n",
    "                #print(\"diag size: \", p.diag_ggn_mc.size())\n",
    "                sigmas.append(p.diag_ggn_mc)\n",
    "\n",
    "\n",
    "        #print(\"mus w: \", mus[-2])\n",
    "        #print(\"sigma w: \", sigmas[-2])\n",
    "        mus_last_layer_w.append(mus[-2].detach())\n",
    "        mus_last_layer_b.append(mus[-1].detach())\n",
    "        sigmas_last_layer_w.append(sigmas[-2].detach())\n",
    "        sigmas_last_layer_b.append(sigmas[-1].detach())\n",
    "\n",
    "        #if hessian_idx >= 10:\n",
    "        #    break\n",
    "\n",
    "    print(\"saving model at: {}\".format(save_path))\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    #print(mus_last_layer_w).size()\n",
    "    mus_w_mean = torch.cat(mus_last_layer_w).view(-1, num_classes, 500).mean(dim=0)\n",
    "    mus_b_mean = torch.cat(mus_last_layer_b).view(-1, num_classes).mean(dim=0)\n",
    "    sigmas_w_mean = torch.cat(sigmas_last_layer_w).view(-1, num_classes, 500).mean(dim=0)\n",
    "    sigmas_b_mean = torch.cat(sigmas_last_layer_b).view(-1, num_classes).mean(dim=0)\n",
    "    print(\"mus w mean: \", mus_w_mean.size())\n",
    "    print(\"mus b mean: \", mus_b_mean.size())\n",
    "    print(\"sigmas w mean: \", sigmas_w_mean.size())\n",
    "    print(\"sigmas b mean: \", sigmas_b_mean.size())\n",
    "    \n",
    "    return(mus_w_mean, mus_b_mean, sigmas_w_mean, sigmas_b_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mu_from_Dirichlet(alpha):\n",
    "    K = len(alpha)\n",
    "    mu = torch.zeros(K)\n",
    "    for i in range(K):\n",
    "        mu_i = torch.log(alpha[i]) - 1/K * torch.sum(torch.log(alpha))\n",
    "        mu[i] = mu_i\n",
    "        \n",
    "    return(torch.Tensor(mu))\n",
    "\n",
    "def get_Sigma_from_Dirichlet(alpha):\n",
    "    K = len(alpha)\n",
    "    sum_of_inv = 1/K * torch.sum(1/alpha)\n",
    "    Sigma = torch.zeros((K,K))\n",
    "    for k in range(K):\n",
    "        for l in range(K):\n",
    "            delta = 1 if k==l else 0\n",
    "            Sigma[k][l] = delta * 1/alpha[k] - 1/K*(1/alpha[k] + 1/alpha[l] - sum_of_inv)\n",
    "            \n",
    "    return(torch.Tensor(Sigma))\n",
    "\n",
    "\n",
    "def get_alpha_from_Normal(mu, Sigma):\n",
    "    alpha = []\n",
    "    K = len(Sigma[0])\n",
    "    sum_exp = torch.sum(torch.exp(-1*torch.Tensor(mu)))\n",
    "    for k in range(K):\n",
    "        alpha.append(1/Sigma[k][k]*(1 - 2/K + torch.exp(mu[k])/K**2 * sum_exp))\n",
    "        \n",
    "    return(torch.Tensor(alpha))\n",
    "\n",
    "def get_Gaussian_output(x, mu_w, mu_b, sigma_w, sigma_b):\n",
    "    #get the distributions per class\n",
    "    n = len(mu_b)\n",
    "    x = x.view(-1)\n",
    "    #per_class_mus = []\n",
    "    per_class_sigmas = []\n",
    "    for i in range(n):\n",
    "        #per_class_mus.append(torch.matmul(mu_w[i], x) + mu_b[i])\n",
    "        #create a diagonal Hessian\n",
    "        hess = torch.diag(sigma_w[i])\n",
    "        per_class_sigmas.append(torch.matmul(torch.matmul(x, hess), x) + sigma_b[i])\n",
    "    \n",
    "    per_class_mus = torch.matmul(mu_w, x) + mu_b\n",
    "    mu = torch.tensor(per_class_mus)\n",
    "    Sigma = torch.diag(torch.tensor(per_class_sigmas))\n",
    "    #print(mu.size(), Sigma.size())\n",
    "    return(mu, Sigma)\n",
    "\n",
    "alpha_test = torch.Tensor([1.3, 1.3])\n",
    "#print(\"alpha start: \", alpha_test)\n",
    "mu_test = get_mu_from_Dirichlet(alpha_test)\n",
    "#print(\"mu: \", mu_test)\n",
    "Sigma_test = get_Sigma_from_Dirichlet(alpha_test)\n",
    "#print(\"Sigma: \", Sigma_test)\n",
    "alpha_end = get_alpha_from_Normal(mu_test, Sigma_test)\n",
    "#print(\"alpha end: \", alpha_end)\n",
    "assert(alpha_test.equal(alpha_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN_CIFAR100_DN = 1 * 10e-6\n",
    "BATCH_SIZE_CIFAR100_DN = 128\n",
    "MAX_ITER_CIFAR100_DN = 70\n",
    "TEST_BATCH_SIZE_CIFAR100_DN = 1\n",
    "HESS_BATCH_SIZE_CIFAR100_DN = 128\n",
    "STEP_SIZE_HESS_CIFAR100_DN = 1 * 10e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./cifar100', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "CIFAR100_train_dataset, CIFAR100_val_dataset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "CIFAR100_train_loader = torch.utils.data.DataLoader(CIFAR100_train_dataset, batch_size=BATCH_SIZE_CIFAR100_DN,\n",
    "                                          shuffle=True)\n",
    "\n",
    "CIFAR100_val_loader = torch.utils.data.DataLoader(CIFAR100_val_dataset, batch_size=BATCH_SIZE_CIFAR100_DN,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./cifar100', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "CIFAR100_test_loader = torch.utils.data.DataLoader(testset, batch_size=TEST_BATCH_SIZE_CIFAR100_DN,\n",
    "                                         shuffle=False)\n",
    "\n",
    "CIFAR100_classes = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "    'worm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just rip the code of densenet on pytorch\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as cp\n",
    "from collections import OrderedDict\n",
    "from torchvision.models.utils import load_state_dict_from_url\n",
    "\n",
    "\n",
    "__all__ = ['DenseNet', 'densenet121', 'densenet169', 'densenet201', 'densenet161']\n",
    "\n",
    "model_urls = {\n",
    "    'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\n",
    "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
    "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
    "    'densenet161': 'https://download.pytorch.org/models/densenet161-8d451a50.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def _bn_function_factory(norm, relu, conv):\n",
    "    def bn_function(*inputs):\n",
    "        concated_features = torch.cat(inputs, 1)\n",
    "        bottleneck_output = conv(relu(norm(concated_features)))\n",
    "        return bottleneck_output\n",
    "\n",
    "    return bn_function\n",
    "\n",
    "\n",
    "class _DenseLayer(nn.Sequential):\n",
    "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate, memory_efficient=False):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
    "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
    "                                           growth_rate, kernel_size=1, stride=1,\n",
    "                                           bias=False)),\n",
    "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
    "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "                                           kernel_size=3, stride=1, padding=1,\n",
    "                                           bias=False)),\n",
    "        self.drop_rate = drop_rate\n",
    "        self.memory_efficient = memory_efficient\n",
    "\n",
    "    def forward(self, *prev_features):\n",
    "        bn_function = _bn_function_factory(self.norm1, self.relu1, self.conv1)\n",
    "        if self.memory_efficient and any(prev_feature.requires_grad for prev_feature in prev_features):\n",
    "            bottleneck_output = cp.checkpoint(bn_function, *prev_features)\n",
    "        else:\n",
    "            bottleneck_output = bn_function(*prev_features)\n",
    "        new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate,\n",
    "                                     training=self.training)\n",
    "        return new_features\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.Module):\n",
    "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate, memory_efficient=False):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(\n",
    "                num_input_features + i * growth_rate,\n",
    "                growth_rate=growth_rate,\n",
    "                bn_size=bn_size,\n",
    "                drop_rate=drop_rate,\n",
    "                memory_efficient=memory_efficient,\n",
    "            )\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)\n",
    "\n",
    "    def forward(self, init_features):\n",
    "        features = [init_features]\n",
    "        for name, layer in self.named_children():\n",
    "            new_features = layer(*features)\n",
    "            features.append(new_features)\n",
    "        return torch.cat(features, 1)\n",
    "\n",
    "\n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super(_Transition, self).__init__()\n",
    "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    r\"\"\"Densenet-BC model class, based on\n",
    "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
    "        block_config (list of 4 ints) - how many layers in each pooling block\n",
    "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
    "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
    "          (i.e. bn_size * k features in the bottleneck layer)\n",
    "        drop_rate (float) - dropout rate after each dense layer\n",
    "        num_classes (int) - number of classification classes\n",
    "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
    "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000, memory_efficient=False):\n",
    "\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        # First convolution\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2,\n",
    "                                padding=3, bias=False)),\n",
    "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
    "            ('relu0', nn.ReLU(inplace=True)),\n",
    "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "        ]))\n",
    "\n",
    "        # Each denseblock\n",
    "        num_features = num_init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(\n",
    "                num_layers=num_layers,\n",
    "                num_input_features=num_features,\n",
    "                bn_size=bn_size,\n",
    "                growth_rate=growth_rate,\n",
    "                drop_rate=drop_rate,\n",
    "                memory_efficient=memory_efficient\n",
    "            )\n",
    "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                trans = _Transition(num_input_features=num_features,\n",
    "                                    num_output_features=num_features // 2)\n",
    "                self.features.add_module('transition%d' % (i + 1), trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "        # Final batch norm\n",
    "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
    "\n",
    "        # Linear layer\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "        # Official init from torch repo.\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x, phi=False):  #added phi\n",
    "        features = self.features(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
    "        out = torch.flatten(out, 1)\n",
    "        if phi:              #changed\n",
    "            return(out)      #changed\n",
    "        else:               #changed\n",
    "            out = self.classifier(out)     #changed\n",
    "            return out            #changed\n",
    "\n",
    "\n",
    "def _load_state_dict(model, model_url, progress):\n",
    "    # '.'s are no longer allowed in module names, but previous _DenseLayer\n",
    "    # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
    "    # They are also in the checkpoints in model_urls. This pattern is used\n",
    "    # to find such keys.\n",
    "    pattern = re.compile(\n",
    "        r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
    "\n",
    "    state_dict = load_state_dict_from_url(model_url, progress=progress)\n",
    "    for key in list(state_dict.keys()):\n",
    "        res = pattern.match(key)\n",
    "        if res:\n",
    "            new_key = res.group(1) + res.group(2)\n",
    "            state_dict[new_key] = state_dict[key]\n",
    "            del state_dict[key]\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "def _densenet(arch, growth_rate, block_config, num_init_features, pretrained, progress,\n",
    "              **kwargs):\n",
    "    model = DenseNet(growth_rate, block_config, num_init_features, **kwargs)\n",
    "    if pretrained:\n",
    "        _load_state_dict(model, model_urls[arch], progress)\n",
    "    return model\n",
    "\n",
    "\n",
    "def densenet121(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"Densenet-121 model from\n",
    "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
    "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
    "    \"\"\"\n",
    "    return _densenet('densenet121', 32, (6, 12, 24, 16), 64, pretrained, progress,\n",
    "                     **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "def densenet161(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"Densenet-161 model from\n",
    "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
    "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
    "    \"\"\"\n",
    "    return _densenet('densenet161', 48, (6, 12, 36, 24), 96, pretrained, progress,\n",
    "                     **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "def densenet169(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"Densenet-169 model from\n",
    "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
    "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
    "    \"\"\"\n",
    "    return _densenet('densenet169', 32, (6, 12, 32, 32), 64, pretrained, progress,\n",
    "                     **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "def densenet201(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"Densenet-201 model from\n",
    "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
    "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
    "    \"\"\"\n",
    "    return _densenet('densenet201', 32, (6, 12, 48, 32), 64, pretrained, progress,\n",
    "                     **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR100_model_DN = densenet201(pretrained=True).cuda()\n",
    "loss_function = torch.nn.CrossEntropyLoss()       \n",
    "\n",
    "#CIFAR100_DN_train_optimizer = torch.optim.Adam(CIFAR100_model_DN.parameters(), lr=STEP_SIZE_TRAIN_CIFAR100_DN)\n",
    "CIFAR100_DN_train_optimizer = torch.optim.SGD(CIFAR100_model_DN.parameters(), lr=STEP_SIZE_TRAIN_CIFAR100_DN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0; 0/313 \tMinibatch Loss 9.373  Accuracy 1%\n",
      "Iteration 0; 1/313 \tMinibatch Loss 9.071  Accuracy 0%\n"
     ]
    }
   ],
   "source": [
    "CIFAR100_DN_PATH = \"models/CIFAR100_DN_model_SGD.pth\"\n",
    "current_best_mva = 0\n",
    "\n",
    "for iter in range(MAX_ITER_CIFAR100_DN):\n",
    "    train_acc = []\n",
    "    for batch_idx, (x, y) in enumerate(CIFAR100_train_loader):\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        max_len = int(np.ceil(len(CIFAR100_train_loader.dataset)/BATCH_SIZE_CIFAR100_DN))\n",
    "        output = CIFAR100_model_DN(x, phi=False)\n",
    "\n",
    "        accuracy = get_accuracy(output, y)\n",
    "        train_acc.append(accuracy)\n",
    "\n",
    "        #with backpack(DiagGGNMC()):\n",
    "        #    loss = loss_function(output, y)\n",
    "        #    loss.backward()\n",
    "        #    mnist_optimizer.step()\n",
    "        \n",
    "        loss = loss_function(output, y)\n",
    "        loss.backward()\n",
    "        CIFAR100_DN_train_optimizer.step()\n",
    "\n",
    "        print(\n",
    "            \"Iteration {}; {}/{} \\t\".format(iter, batch_idx, max_len) +\n",
    "            \"Minibatch Loss %.3f  \" % (loss) +\n",
    "            \"Accuracy %.0f\" % (accuracy * 100) + \"%\"\n",
    "        )\n",
    "        \n",
    "    val_acc = []\n",
    "    for batch_idx, (x, y) in enumerate(CIFAR100_val_loader):\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        max_len = int(np.ceil(len(CIFAR100_val_loader.dataset)/BATCH_SIZE_CIFAR100_DN))\n",
    "        output = CIFAR100_model_DN(x, phi=False)\n",
    "\n",
    "        accuracy = get_accuracy(output, y)\n",
    "        val_acc.append(accuracy)\n",
    "        print(\"Iteration {}; {}/{} \\t\".format(iter, batch_idx, max_len) + \n",
    "              \"Validation accuracy: {:.03f}\".format(accuracy))\n",
    "\n",
    "    mva = np.mean(val_acc)\n",
    "    mta = np.mean(train_acc)\n",
    "    print(\"mean train acc: \", mta)\n",
    "    print(\"mean val acc: \", mva)\n",
    "    \n",
    "    \n",
    "    if mva > current_best_mva:\n",
    "        current_best_mva = mva\n",
    "        print(\"saving model at: {}\".format(CIFAR100_DN_PATH))\n",
    "        torch.save(CIFAR100_model_DN.state_dict(), CIFAR100_DN_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
