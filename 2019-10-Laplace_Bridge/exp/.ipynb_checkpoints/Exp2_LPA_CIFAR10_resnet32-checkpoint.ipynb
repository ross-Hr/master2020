{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version:  1.3.1\n",
      "cuda available:  True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "from math import *\n",
    "from backpack import backpack, extend\n",
    "from backpack.extensions import KFAC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy\n",
    "from tqdm import tqdm, trange\n",
    "import pytest\n",
    "import matplotlib.pyplot as plt\n",
    "from DirLPA_utils import * \n",
    "\n",
    "print(\"pytorch version: \", torch.__version__)\n",
    "print(\"cuda available: \", torch.cuda.is_available())\n",
    "\n",
    "s = 127\n",
    "np.random.seed(s)\n",
    "torch.manual_seed(s)\n",
    "torch.cuda.manual_seed(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Cifar10 on Resnet32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TRAIN_CIFAR10 = 128\n",
    "BATCH_SIZE_TEST_CIFAR10 = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(output, targets):\n",
    "    \"\"\"Helper function to print the accuracy\"\"\"\n",
    "    predictions = output.argmax(dim=1, keepdim=True).view_as(targets)\n",
    "    return predictions.eq(targets).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "\n",
    "train_size = int(0.9 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "CIFAR10_train_dataset, CIFAR10_val_dataset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
    "\n",
    "CIFAR10_train_loader = torch.utils.data.DataLoader(CIFAR10_train_dataset, batch_size=BATCH_SIZE_TRAIN_CIFAR10,\n",
    "                                          shuffle=False)\n",
    "\n",
    "CIFAR10_val_loader = torch.utils.data.DataLoader(CIFAR10_val_dataset, batch_size=BATCH_SIZE_TRAIN_CIFAR10,\n",
    "                                          shuffle=False)\n",
    "\n",
    "CIFAR10_test = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "CIFAR10_test_loader = torch.utils.data.DataLoader(CIFAR10_test, batch_size=BATCH_SIZE_TEST_CIFAR10,\n",
    "                                         shuffle=False)\n",
    "\n",
    "CIFAR10_classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(CIFAR10_train_loader)\n",
    "images, labels = dataiter.next()\n",
    "nrow = int(BATCH_SIZE_TRAIN_CIFAR10/4)\n",
    "imshow(torchvision.utils.make_grid(images, nrow=nrow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#load in CIFAR100\n",
    "BATCH_SIZE_TRAIN_CIFAR100 = 128\n",
    "BATCH_SIZE_TEST_CIFAR100 = 128\n",
    "\n",
    "CIFAR100_train = torchvision.datasets.CIFAR100(root='~/data/cifar100', train=True,\n",
    "                                       download=True, transform=transform_test)\n",
    "CIFAR100_train_loader = torch.utils.data.DataLoader(CIFAR100_train, batch_size=BATCH_SIZE_TRAIN_CIFAR100,\n",
    "                                         shuffle=False)\n",
    "\n",
    "CIFAR100_test = torchvision.datasets.CIFAR100(root='~/data/cifar100', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "CIFAR100_test_loader = torch.utils.data.DataLoader(CIFAR100_test, batch_size=BATCH_SIZE_TEST_CIFAR100,\n",
    "                                         shuffle=False)\n",
    "\n",
    "CIFAR100_classes = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "    'worm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/marius/data/SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: /home/marius/data/SVHN/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "# load SVHN\n",
    "BATCH_SIZE_TRAIN_SVHN = 128\n",
    "BATCH_SIZE_TEST_SVHN = 128\n",
    "\n",
    "train_data_SVHN = torchvision.datasets.SVHN('~/data/SVHN', split='train',\n",
    "                             download=True, transform=transform_train)\n",
    "\n",
    "test_data_SVHN = torchvision.datasets.SVHN('~/data/SVHN', split='test',\n",
    "                             download=True, transform=transform_test)\n",
    "\n",
    "train_loader_SVHN = torch.utils.data.DataLoader(test_data_SVHN, batch_size=BATCH_SIZE_TRAIN_SVHN)\n",
    "test_loader_SVHN = torch.utils.data.DataLoader(test_data_SVHN, batch_size=BATCH_SIZE_TEST_SVHN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CIFAR10 on ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE_TRAIN_CIFAR10, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE_TEST_CIFAR10, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(CIFAR10_train_loader)\n",
    "images, labels = dataiter.next()\n",
    "nrow = int(BATCH_SIZE_TRAIN_CIFAR10/4)\n",
    "imshow(torchvision.utils.make_grid(images, nrow=nrow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.fc = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def phi(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.phi(x)\n",
    "        out = self.fc(out)\n",
    "        return(out)\n",
    "\n",
    "\n",
    "def ResNet18(num_classes=10):\n",
    "    return ResNet(BasicBlock, [2,2,2,2], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "CIFAR10_model = ResNet18().to(device)\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(CIFAR10_model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(net, epoch, optimizer, trainloader, filename):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    \n",
    "    print(\"train loss: \", train_loss)\n",
    "    print(\"train accuracy: \", correct/total)\n",
    "    print(\"saving model at: {}\".format(filename))\n",
    "    torch.save(net.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, epoch, testloader):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "        print(\"test loss: \", test_loss)\n",
    "        print(\"test accuracy: \", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all():\n",
    "    CIFAR10_path = 'weights/cifar10_resnet18_SGD.pth'\n",
    "    lr = 0.1\n",
    "    epoch = 0\n",
    "    for e in [100, 50, 50]:\n",
    "        print(\"current learning rate: \", lr)\n",
    "        for _ in range(e):\n",
    "            optimizer = optim.SGD(CIFAR10_model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "            train(CIFAR10_model, epoch, optimizer, trainloader, CIFAR10_path)\n",
    "            test(CIFAR10_model, epoch, testloader)\n",
    "            epoch += 1\n",
    "        lr /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current learning rate:  0.1\n",
      "\n",
      "Epoch: 0\n",
      "train loss:  735.2782756090164\n",
      "train accuracy:  0.32482\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  122.92022550106049\n",
      "test accuracy:  0.4207\n",
      "\n",
      "Epoch: 1\n",
      "train loss:  549.5818940401077\n",
      "train accuracy:  0.48396\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  102.8718353509903\n",
      "test accuracy:  0.5241\n",
      "\n",
      "Epoch: 2\n",
      "train loss:  441.67920756340027\n",
      "train accuracy:  0.59368\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  120.26511776447296\n",
      "test accuracy:  0.5313\n",
      "\n",
      "Epoch: 3\n",
      "train loss:  363.2937567830086\n",
      "train accuracy:  0.67208\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  73.24164694547653\n",
      "test accuracy:  0.6793\n",
      "\n",
      "Epoch: 4\n",
      "train loss:  307.59092301130295\n",
      "train accuracy:  0.72514\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  62.32203954458237\n",
      "test accuracy:  0.7245\n",
      "\n",
      "Epoch: 5\n",
      "train loss:  259.6400728225708\n",
      "train accuracy:  0.7697\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  63.78632813692093\n",
      "test accuracy:  0.7294\n",
      "\n",
      "Epoch: 6\n",
      "train loss:  234.68083626031876\n",
      "train accuracy:  0.79464\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  54.20434129238129\n",
      "test accuracy:  0.7699\n",
      "\n",
      "Epoch: 7\n",
      "train loss:  220.6452583372593\n",
      "train accuracy:  0.80546\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  74.70105791091919\n",
      "test accuracy:  0.6883\n",
      "\n",
      "Epoch: 8\n",
      "train loss:  208.96894630789757\n",
      "train accuracy:  0.81706\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  52.42300161719322\n",
      "test accuracy:  0.7751\n",
      "\n",
      "Epoch: 9\n",
      "train loss:  197.9608652293682\n",
      "train accuracy:  0.82674\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  43.445687621831894\n",
      "test accuracy:  0.8084\n",
      "\n",
      "Epoch: 10\n",
      "train loss:  191.92938047647476\n",
      "train accuracy:  0.8313\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  45.472194850444794\n",
      "test accuracy:  0.8047\n",
      "\n",
      "Epoch: 11\n",
      "train loss:  183.22814339399338\n",
      "train accuracy:  0.83848\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  49.94606575369835\n",
      "test accuracy:  0.7937\n",
      "\n",
      "Epoch: 12\n",
      "train loss:  177.1351764947176\n",
      "train accuracy:  0.84428\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  41.601422727108\n",
      "test accuracy:  0.8241\n",
      "\n",
      "Epoch: 13\n",
      "train loss:  173.64965426921844\n",
      "train accuracy:  0.84808\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  50.47848695516586\n",
      "test accuracy:  0.7832\n",
      "\n",
      "Epoch: 14\n",
      "train loss:  168.9003986865282\n",
      "train accuracy:  0.85272\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  42.03575322031975\n",
      "test accuracy:  0.8201\n",
      "\n",
      "Epoch: 15\n",
      "train loss:  166.36166819930077\n",
      "train accuracy:  0.85418\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  48.62107786536217\n",
      "test accuracy:  0.7997\n",
      "\n",
      "Epoch: 16\n",
      "train loss:  161.1516668200493\n",
      "train accuracy:  0.86122\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  37.85386994481087\n",
      "test accuracy:  0.8381\n",
      "\n",
      "Epoch: 17\n",
      "train loss:  159.48876737058163\n",
      "train accuracy:  0.86262\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  45.891616344451904\n",
      "test accuracy:  0.8059\n",
      "\n",
      "Epoch: 18\n",
      "train loss:  158.6100970953703\n",
      "train accuracy:  0.86168\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  45.009265810251236\n",
      "test accuracy:  0.8092\n",
      "\n",
      "Epoch: 19\n",
      "train loss:  153.41581417620182\n",
      "train accuracy:  0.86586\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  62.399791836738586\n",
      "test accuracy:  0.7732\n",
      "\n",
      "Epoch: 20\n",
      "train loss:  153.22674678266048\n",
      "train accuracy:  0.867\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  38.46659451723099\n",
      "test accuracy:  0.8337\n",
      "\n",
      "Epoch: 21\n",
      "train loss:  151.41149884462357\n",
      "train accuracy:  0.86652\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  39.3250874876976\n",
      "test accuracy:  0.8308\n",
      "\n",
      "Epoch: 22\n",
      "train loss:  147.56377239525318\n",
      "train accuracy:  0.87076\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  38.83779215812683\n",
      "test accuracy:  0.834\n",
      "\n",
      "Epoch: 23\n",
      "train loss:  146.43692187964916\n",
      "train accuracy:  0.87116\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  37.48514437675476\n",
      "test accuracy:  0.8429\n",
      "\n",
      "Epoch: 24\n",
      "train loss:  146.25257217884064\n",
      "train accuracy:  0.87154\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  39.27301988005638\n",
      "test accuracy:  0.8346\n",
      "\n",
      "Epoch: 25\n",
      "train loss:  144.00774157047272\n",
      "train accuracy:  0.874\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  40.15346199274063\n",
      "test accuracy:  0.8299\n",
      "\n",
      "Epoch: 26\n",
      "train loss:  145.0283734947443\n",
      "train accuracy:  0.87166\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  51.259469747543335\n",
      "test accuracy:  0.7954\n",
      "\n",
      "Epoch: 27\n",
      "train loss:  141.95609113574028\n",
      "train accuracy:  0.87572\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  42.2141595184803\n",
      "test accuracy:  0.8266\n",
      "\n",
      "Epoch: 28\n",
      "train loss:  141.04627867043018\n",
      "train accuracy:  0.87708\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  34.367194443941116\n",
      "test accuracy:  0.8554\n",
      "\n",
      "Epoch: 29\n",
      "train loss:  138.92403322458267\n",
      "train accuracy:  0.87816\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  45.50177337229252\n",
      "test accuracy:  0.81\n",
      "\n",
      "Epoch: 30\n",
      "train loss:  138.70095413923264\n",
      "train accuracy:  0.87938\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  41.137366861104965\n",
      "test accuracy:  0.8265\n",
      "\n",
      "Epoch: 31\n",
      "train loss:  137.76476934552193\n",
      "train accuracy:  0.88044\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  40.11628299951553\n",
      "test accuracy:  0.834\n",
      "\n",
      "Epoch: 32\n",
      "train loss:  136.8565664589405\n",
      "train accuracy:  0.8822\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  37.93354448676109\n",
      "test accuracy:  0.8399\n",
      "\n",
      "Epoch: 33\n",
      "train loss:  135.8086083829403\n",
      "train accuracy:  0.88248\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  42.32056511938572\n",
      "test accuracy:  0.8285\n",
      "\n",
      "Epoch: 34\n",
      "train loss:  136.14403495192528\n",
      "train accuracy:  0.88194\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  37.620365619659424\n",
      "test accuracy:  0.8398\n",
      "\n",
      "Epoch: 35\n",
      "train loss:  134.57910558581352\n",
      "train accuracy:  0.88208\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  49.844798535108566\n",
      "test accuracy:  0.7975\n",
      "\n",
      "Epoch: 36\n",
      "train loss:  133.8311863988638\n",
      "train accuracy:  0.88232\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  48.578622192144394\n",
      "test accuracy:  0.7996\n",
      "\n",
      "Epoch: 37\n",
      "train loss:  133.12614685297012\n",
      "train accuracy:  0.88412\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  37.03795041143894\n",
      "test accuracy:  0.837\n",
      "\n",
      "Epoch: 38\n",
      "train loss:  133.39302895963192\n",
      "train accuracy:  0.88262\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  46.30499216914177\n",
      "test accuracy:  0.8189\n",
      "\n",
      "Epoch: 39\n",
      "train loss:  132.67175567150116\n",
      "train accuracy:  0.8845\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  37.93428233265877\n",
      "test accuracy:  0.8364\n",
      "\n",
      "Epoch: 40\n",
      "train loss:  130.46961656212807\n",
      "train accuracy:  0.88686\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  40.968283891677856\n",
      "test accuracy:  0.8349\n",
      "\n",
      "Epoch: 41\n",
      "train loss:  135.82418631017208\n",
      "train accuracy:  0.88212\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  43.09888792037964\n",
      "test accuracy:  0.8224\n",
      "\n",
      "Epoch: 42\n",
      "train loss:  131.3018907904625\n",
      "train accuracy:  0.8863\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  40.08290043473244\n",
      "test accuracy:  0.8286\n",
      "\n",
      "Epoch: 43\n",
      "train loss:  130.1330772191286\n",
      "train accuracy:  0.8865\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  49.13764998316765\n",
      "test accuracy:  0.8061\n",
      "\n",
      "Epoch: 44\n",
      "train loss:  130.8436713963747\n",
      "train accuracy:  0.886\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  34.32694208621979\n",
      "test accuracy:  0.8571\n",
      "\n",
      "Epoch: 45\n",
      "train loss:  129.93266320228577\n",
      "train accuracy:  0.88732\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  45.229412376880646\n",
      "test accuracy:  0.8103\n",
      "\n",
      "Epoch: 46\n",
      "train loss:  129.0844328701496\n",
      "train accuracy:  0.8864\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  38.058562591671944\n",
      "test accuracy:  0.8445\n",
      "\n",
      "Epoch: 47\n",
      "train loss:  129.09183740615845\n",
      "train accuracy:  0.88742\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  44.743534207344055\n",
      "test accuracy:  0.8233\n",
      "\n",
      "Epoch: 48\n",
      "train loss:  126.61730471253395\n",
      "train accuracy:  0.89024\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  47.30108866095543\n",
      "test accuracy:  0.8138\n",
      "\n",
      "Epoch: 49\n",
      "train loss:  129.40179263055325\n",
      "train accuracy:  0.88776\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  35.689236000180244\n",
      "test accuracy:  0.8549\n",
      "\n",
      "Epoch: 50\n",
      "train loss:  128.40078946948051\n",
      "train accuracy:  0.88714\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  34.13819809257984\n",
      "test accuracy:  0.8544\n",
      "\n",
      "Epoch: 51\n",
      "train loss:  128.55023358762264\n",
      "train accuracy:  0.8883\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  39.56062787771225\n",
      "test accuracy:  0.8426\n",
      "\n",
      "Epoch: 52\n",
      "train loss:  129.28291402757168\n",
      "train accuracy:  0.88804\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  41.26557415723801\n",
      "test accuracy:  0.8313\n",
      "\n",
      "Epoch: 53\n",
      "train loss:  128.0588103532791\n",
      "train accuracy:  0.88908\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  43.67113682627678\n",
      "test accuracy:  0.8236\n",
      "\n",
      "Epoch: 54\n",
      "train loss:  125.51014702022076\n",
      "train accuracy:  0.89082\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  33.68338191509247\n",
      "test accuracy:  0.8545\n",
      "\n",
      "Epoch: 55\n",
      "train loss:  126.34681706130505\n",
      "train accuracy:  0.88976\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  38.31580209732056\n",
      "test accuracy:  0.8419\n",
      "\n",
      "Epoch: 56\n",
      "train loss:  125.7595289349556\n",
      "train accuracy:  0.89168\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  45.115991294384\n",
      "test accuracy:  0.813\n",
      "\n",
      "Epoch: 57\n",
      "train loss:  127.52363722026348\n",
      "train accuracy:  0.88882\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  42.10357782244682\n",
      "test accuracy:  0.8248\n",
      "\n",
      "Epoch: 58\n",
      "train loss:  125.7120059132576\n",
      "train accuracy:  0.89096\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  46.74441596865654\n",
      "test accuracy:  0.8151\n",
      "\n",
      "Epoch: 59\n",
      "train loss:  127.77247519791126\n",
      "train accuracy:  0.88984\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  38.64498269557953\n",
      "test accuracy:  0.8426\n",
      "\n",
      "Epoch: 60\n",
      "train loss:  124.45226323604584\n",
      "train accuracy:  0.89198\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  39.392548114061356\n",
      "test accuracy:  0.8387\n",
      "\n",
      "Epoch: 61\n",
      "train loss:  125.59126272797585\n",
      "train accuracy:  0.8907\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  32.47063934803009\n",
      "test accuracy:  0.8686\n",
      "\n",
      "Epoch: 62\n",
      "train loss:  125.90072256326675\n",
      "train accuracy:  0.89018\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  43.99706721305847\n",
      "test accuracy:  0.8185\n",
      "\n",
      "Epoch: 63\n",
      "train loss:  125.19762627780437\n",
      "train accuracy:  0.89066\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  37.37919861078262\n",
      "test accuracy:  0.844\n",
      "\n",
      "Epoch: 64\n",
      "train loss:  125.96083442866802\n",
      "train accuracy:  0.89044\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  30.64273777604103\n",
      "test accuracy:  0.8708\n",
      "\n",
      "Epoch: 65\n",
      "train loss:  126.20467455685139\n",
      "train accuracy:  0.89048\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  35.959047973155975\n",
      "test accuracy:  0.8469\n",
      "\n",
      "Epoch: 66\n",
      "train loss:  123.76024435460567\n",
      "train accuracy:  0.89338\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  41.27850419282913\n",
      "test accuracy:  0.8357\n",
      "\n",
      "Epoch: 67\n",
      "train loss:  123.94511878490448\n",
      "train accuracy:  0.89196\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  56.05960103869438\n",
      "test accuracy:  0.7863\n",
      "\n",
      "Epoch: 68\n",
      "train loss:  125.56964348256588\n",
      "train accuracy:  0.89008\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  35.01720058917999\n",
      "test accuracy:  0.8539\n",
      "\n",
      "Epoch: 69\n",
      "train loss:  123.3416563719511\n",
      "train accuracy:  0.89284\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  36.56856954097748\n",
      "test accuracy:  0.8383\n",
      "\n",
      "Epoch: 70\n",
      "train loss:  123.20300368964672\n",
      "train accuracy:  0.8928\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  43.83230763673782\n",
      "test accuracy:  0.8334\n",
      "\n",
      "Epoch: 71\n",
      "train loss:  125.02663416415453\n",
      "train accuracy:  0.89016\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  40.62821885943413\n",
      "test accuracy:  0.8325\n",
      "\n",
      "Epoch: 72\n",
      "train loss:  123.82918241620064\n",
      "train accuracy:  0.89312\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  35.473335951566696\n",
      "test accuracy:  0.8445\n",
      "\n",
      "Epoch: 73\n",
      "train loss:  123.05767947435379\n",
      "train accuracy:  0.89386\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  51.53806033730507\n",
      "test accuracy:  0.8042\n",
      "\n",
      "Epoch: 74\n",
      "train loss:  124.45881925523281\n",
      "train accuracy:  0.89266\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  32.9300282895565\n",
      "test accuracy:  0.8571\n",
      "\n",
      "Epoch: 75\n",
      "train loss:  121.84680977463722\n",
      "train accuracy:  0.89498\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  31.890491262078285\n",
      "test accuracy:  0.868\n",
      "\n",
      "Epoch: 76\n",
      "train loss:  121.34215394407511\n",
      "train accuracy:  0.89492\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  36.555488616228104\n",
      "test accuracy:  0.8491\n",
      "\n",
      "Epoch: 77\n",
      "train loss:  124.32656449079514\n",
      "train accuracy:  0.89188\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  37.01793244481087\n",
      "test accuracy:  0.8431\n",
      "\n",
      "Epoch: 78\n",
      "train loss:  123.377555757761\n",
      "train accuracy:  0.8918\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  35.10664168000221\n",
      "test accuracy:  0.8546\n",
      "\n",
      "Epoch: 79\n",
      "train loss:  123.32625532150269\n",
      "train accuracy:  0.89284\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  40.586500614881516\n",
      "test accuracy:  0.8329\n",
      "\n",
      "Epoch: 80\n",
      "train loss:  123.50754772126675\n",
      "train accuracy:  0.89278\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  34.117792159318924\n",
      "test accuracy:  0.8556\n",
      "\n",
      "Epoch: 81\n",
      "train loss:  124.8787127584219\n",
      "train accuracy:  0.88956\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  41.20957365632057\n",
      "test accuracy:  0.8277\n",
      "\n",
      "Epoch: 82\n",
      "train loss:  122.90561197698116\n",
      "train accuracy:  0.89204\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  31.41836841404438\n",
      "test accuracy:  0.8653\n",
      "\n",
      "Epoch: 83\n",
      "train loss:  122.96219101548195\n",
      "train accuracy:  0.895\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  60.00528208911419\n",
      "test accuracy:  0.7797\n",
      "\n",
      "Epoch: 84\n",
      "train loss:  122.0858574360609\n",
      "train accuracy:  0.8944\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  32.588352501392365\n",
      "test accuracy:  0.8636\n",
      "\n",
      "Epoch: 85\n",
      "train loss:  122.35585448145866\n",
      "train accuracy:  0.89312\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  36.52269667387009\n",
      "test accuracy:  0.8459\n",
      "\n",
      "Epoch: 86\n",
      "train loss:  121.53147161006927\n",
      "train accuracy:  0.89566\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  39.48566557466984\n",
      "test accuracy:  0.8422\n",
      "\n",
      "Epoch: 87\n",
      "train loss:  121.92821857333183\n",
      "train accuracy:  0.89448\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  30.239537075161934\n",
      "test accuracy:  0.873\n",
      "\n",
      "Epoch: 88\n",
      "train loss:  120.6724538654089\n",
      "train accuracy:  0.8962\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  34.99002377688885\n",
      "test accuracy:  0.853\n",
      "\n",
      "Epoch: 89\n",
      "train loss:  122.08653259277344\n",
      "train accuracy:  0.89488\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  38.423144683241844\n",
      "test accuracy:  0.8449\n",
      "\n",
      "Epoch: 90\n",
      "train loss:  124.4649215489626\n",
      "train accuracy:  0.89296\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  34.10139709711075\n",
      "test accuracy:  0.8545\n",
      "\n",
      "Epoch: 91\n",
      "train loss:  122.59224581718445\n",
      "train accuracy:  0.89296\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  33.311301693320274\n",
      "test accuracy:  0.8593\n",
      "\n",
      "Epoch: 92\n",
      "train loss:  121.5404092669487\n",
      "train accuracy:  0.89424\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  37.98545742034912\n",
      "test accuracy:  0.8481\n",
      "\n",
      "Epoch: 93\n",
      "train loss:  121.17199827730656\n",
      "train accuracy:  0.89592\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  44.41413041949272\n",
      "test accuracy:  0.826\n",
      "\n",
      "Epoch: 94\n",
      "train loss:  122.08380080759525\n",
      "train accuracy:  0.89422\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  34.55571573972702\n",
      "test accuracy:  0.8531\n",
      "\n",
      "Epoch: 95\n",
      "train loss:  121.88795667886734\n",
      "train accuracy:  0.89542\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  39.3612824678421\n",
      "test accuracy:  0.8422\n",
      "\n",
      "Epoch: 96\n",
      "train loss:  122.20713892579079\n",
      "train accuracy:  0.89412\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  40.09773635864258\n",
      "test accuracy:  0.833\n",
      "\n",
      "Epoch: 97\n",
      "train loss:  120.82792742550373\n",
      "train accuracy:  0.89372\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  35.29389515519142\n",
      "test accuracy:  0.8521\n",
      "\n",
      "Epoch: 98\n",
      "train loss:  122.62900297343731\n",
      "train accuracy:  0.8935\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  40.32561373710632\n",
      "test accuracy:  0.8361\n",
      "\n",
      "Epoch: 99\n",
      "train loss:  122.49335362017155\n",
      "train accuracy:  0.89298\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  61.7334361076355\n",
      "test accuracy:  0.7739\n",
      "current learning rate:  0.01\n",
      "\n",
      "Epoch: 100\n",
      "train loss:  66.39613330364227\n",
      "train accuracy:  0.94336\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.767706099897623\n",
      "test accuracy:  0.9286\n",
      "\n",
      "Epoch: 101\n",
      "train loss:  45.67028550803661\n",
      "train accuracy:  0.96096\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.523209258913994\n",
      "test accuracy:  0.937\n",
      "\n",
      "Epoch: 102\n",
      "train loss:  37.35347820259631\n",
      "train accuracy:  0.9689\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.072382349520922\n",
      "test accuracy:  0.9376\n",
      "\n",
      "Epoch: 103\n",
      "train loss:  32.16447488591075\n",
      "train accuracy:  0.97248\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.161146376281977\n",
      "test accuracy:  0.9371\n",
      "\n",
      "Epoch: 104\n",
      "train loss:  29.654664343222976\n",
      "train accuracy:  0.97526\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.101696774363518\n",
      "test accuracy:  0.9393\n",
      "\n",
      "Epoch: 105\n",
      "train loss:  25.574491364881396\n",
      "train accuracy:  0.9782\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.955663822591305\n",
      "test accuracy:  0.9422\n",
      "\n",
      "Epoch: 106\n",
      "train loss:  22.286871498450637\n",
      "train accuracy:  0.98114\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.465611312538385\n",
      "test accuracy:  0.94\n",
      "\n",
      "Epoch: 107\n",
      "train loss:  20.753661155700684\n",
      "train accuracy:  0.98314\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.050706814974546\n",
      "test accuracy:  0.9405\n",
      "\n",
      "Epoch: 108\n",
      "train loss:  19.22425278648734\n",
      "train accuracy:  0.98358\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.422849263995886\n",
      "test accuracy:  0.9382\n",
      "\n",
      "Epoch: 109\n",
      "train loss:  17.365010015666485\n",
      "train accuracy:  0.9858\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.082497771829367\n",
      "test accuracy:  0.9396\n",
      "\n",
      "Epoch: 110\n",
      "train loss:  14.989303315756842\n",
      "train accuracy:  0.98766\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.440493308007717\n",
      "test accuracy:  0.9382\n",
      "\n",
      "Epoch: 111\n",
      "train loss:  14.387911669909954\n",
      "train accuracy:  0.98852\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.694645207375288\n",
      "test accuracy:  0.9403\n",
      "\n",
      "Epoch: 112\n",
      "train loss:  14.674033211544156\n",
      "train accuracy:  0.9878\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.33341544494033\n",
      "test accuracy:  0.9391\n",
      "\n",
      "Epoch: 113\n",
      "train loss:  13.091193426400423\n",
      "train accuracy:  0.98878\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  17.34790463745594\n",
      "test accuracy:  0.937\n",
      "\n",
      "Epoch: 114\n",
      "train loss:  12.482844000682235\n",
      "train accuracy:  0.98946\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.5622566267848\n",
      "test accuracy:  0.9406\n",
      "\n",
      "Epoch: 115\n",
      "train loss:  12.456603622063994\n",
      "train accuracy:  0.99012\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.51494330354035\n",
      "test accuracy:  0.9428\n",
      "\n",
      "Epoch: 116\n",
      "train loss:  11.322378072887659\n",
      "train accuracy:  0.99074\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.955997474491596\n",
      "test accuracy:  0.9347\n",
      "\n",
      "Epoch: 117\n",
      "train loss:  12.735555151477456\n",
      "train accuracy:  0.98942\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  19.594983752816916\n",
      "test accuracy:  0.9321\n",
      "\n",
      "Epoch: 118\n",
      "train loss:  11.942582977935672\n",
      "train accuracy:  0.99006\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.061766851693392\n",
      "test accuracy:  0.9384\n",
      "\n",
      "Epoch: 119\n",
      "train loss:  11.169333131983876\n",
      "train accuracy:  0.9915\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  17.555693432688713\n",
      "test accuracy:  0.9398\n",
      "\n",
      "Epoch: 120\n",
      "train loss:  10.17173426784575\n",
      "train accuracy:  0.9918\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.84408687800169\n",
      "test accuracy:  0.9346\n",
      "\n",
      "Epoch: 121\n",
      "train loss:  10.867040617391467\n",
      "train accuracy:  0.9912\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.195425549522042\n",
      "test accuracy:  0.9369\n",
      "\n",
      "Epoch: 122\n",
      "train loss:  11.229990359395742\n",
      "train accuracy:  0.99108\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.335826823487878\n",
      "test accuracy:  0.9383\n",
      "\n",
      "Epoch: 123\n",
      "train loss:  12.88961859792471\n",
      "train accuracy:  0.989\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  17.295239757746458\n",
      "test accuracy:  0.9388\n",
      "\n",
      "Epoch: 124\n",
      "train loss:  10.929857495240867\n",
      "train accuracy:  0.99156\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  17.901841763406992\n",
      "test accuracy:  0.9384\n",
      "\n",
      "Epoch: 125\n",
      "train loss:  13.380953254178166\n",
      "train accuracy:  0.98904\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.4537762850523\n",
      "test accuracy:  0.9349\n",
      "\n",
      "Epoch: 126\n",
      "train loss:  13.347205340862274\n",
      "train accuracy:  0.98894\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  19.314103044569492\n",
      "test accuracy:  0.9303\n",
      "\n",
      "Epoch: 127\n",
      "train loss:  13.532526221126318\n",
      "train accuracy:  0.98942\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  21.63170713186264\n",
      "test accuracy:  0.928\n",
      "\n",
      "Epoch: 128\n",
      "train loss:  13.52905555255711\n",
      "train accuracy:  0.9886\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  19.679073682054877\n",
      "test accuracy:  0.9312\n",
      "\n",
      "Epoch: 129\n",
      "train loss:  13.545726235955954\n",
      "train accuracy:  0.9888\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.831919241696596\n",
      "test accuracy:  0.9354\n",
      "\n",
      "Epoch: 130\n",
      "train loss:  13.730150444433093\n",
      "train accuracy:  0.98858\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.236595034599304\n",
      "test accuracy:  0.935\n",
      "\n",
      "Epoch: 131\n",
      "train loss:  12.85647538304329\n",
      "train accuracy:  0.9893\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.878124583512545\n",
      "test accuracy:  0.9323\n",
      "\n",
      "Epoch: 132\n",
      "train loss:  15.049981394782662\n",
      "train accuracy:  0.98762\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  19.08083748817444\n",
      "test accuracy:  0.9327\n",
      "\n",
      "Epoch: 133\n",
      "train loss:  15.003418968990445\n",
      "train accuracy:  0.9877\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.498359866440296\n",
      "test accuracy:  0.9344\n",
      "\n",
      "Epoch: 134\n",
      "train loss:  12.811658151447773\n",
      "train accuracy:  0.98964\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  22.703773200511932\n",
      "test accuracy:  0.9234\n",
      "\n",
      "Epoch: 135\n",
      "train loss:  15.526876515708864\n",
      "train accuracy:  0.98692\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  22.287795208394527\n",
      "test accuracy:  0.9229\n",
      "\n",
      "Epoch: 136\n",
      "train loss:  16.47803338803351\n",
      "train accuracy:  0.98592\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  20.20143112540245\n",
      "test accuracy:  0.9297\n",
      "\n",
      "Epoch: 137\n",
      "train loss:  15.064475597813725\n",
      "train accuracy:  0.98798\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  19.963835567235947\n",
      "test accuracy:  0.9304\n",
      "\n",
      "Epoch: 138\n",
      "train loss:  16.87589494138956\n",
      "train accuracy:  0.9855\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  20.784238137304783\n",
      "test accuracy:  0.9254\n",
      "\n",
      "Epoch: 139\n",
      "train loss:  16.882707135751843\n",
      "train accuracy:  0.98592\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  20.813866294920444\n",
      "test accuracy:  0.9253\n",
      "\n",
      "Epoch: 140\n",
      "train loss:  16.540887402370572\n",
      "train accuracy:  0.98612\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  20.090889144688845\n",
      "test accuracy:  0.9294\n",
      "\n",
      "Epoch: 141\n",
      "train loss:  17.08864925056696\n",
      "train accuracy:  0.98578\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  22.315816789865494\n",
      "test accuracy:  0.9234\n",
      "\n",
      "Epoch: 142\n",
      "train loss:  17.514839159324765\n",
      "train accuracy:  0.985\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  21.269278831779957\n",
      "test accuracy:  0.9234\n",
      "\n",
      "Epoch: 143\n",
      "train loss:  16.7257383428514\n",
      "train accuracy:  0.98594\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  23.372163772583008\n",
      "test accuracy:  0.9178\n",
      "\n",
      "Epoch: 144\n",
      "train loss:  17.352841082960367\n",
      "train accuracy:  0.98556\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  21.143735218793154\n",
      "test accuracy:  0.9259\n",
      "\n",
      "Epoch: 145\n",
      "train loss:  17.120632462203503\n",
      "train accuracy:  0.9854\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  21.442637592554092\n",
      "test accuracy:  0.9248\n",
      "\n",
      "Epoch: 146\n",
      "train loss:  17.31250584870577\n",
      "train accuracy:  0.98616\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  19.74347485229373\n",
      "test accuracy:  0.9329\n",
      "\n",
      "Epoch: 147\n",
      "train loss:  17.630178233608603\n",
      "train accuracy:  0.98566\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  20.270843237638474\n",
      "test accuracy:  0.9263\n",
      "\n",
      "Epoch: 148\n",
      "train loss:  16.49289245903492\n",
      "train accuracy:  0.98622\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  20.998866010457277\n",
      "test accuracy:  0.9298\n",
      "\n",
      "Epoch: 149\n",
      "train loss:  17.34373877197504\n",
      "train accuracy:  0.9855\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  22.933839440345764\n",
      "test accuracy:  0.9207\n",
      "current learning rate:  0.001\n",
      "\n",
      "Epoch: 150\n",
      "train loss:  8.636022572405636\n",
      "train accuracy:  0.99344\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.339120537042618\n",
      "test accuracy:  0.9442\n",
      "\n",
      "Epoch: 151\n",
      "train loss:  5.235173522494733\n",
      "train accuracy:  0.9969\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.984362717717886\n",
      "test accuracy:  0.9459\n",
      "\n",
      "Epoch: 152\n",
      "train loss:  3.8846122233662754\n",
      "train accuracy:  0.99804\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.769236352294683\n",
      "test accuracy:  0.9469\n",
      "\n",
      "Epoch: 153\n",
      "train loss:  3.3964273650199175\n",
      "train accuracy:  0.99826\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.809267349541187\n",
      "test accuracy:  0.9466\n",
      "\n",
      "Epoch: 154\n",
      "train loss:  2.994706624187529\n",
      "train accuracy:  0.9983\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.80453421920538\n",
      "test accuracy:  0.9465\n",
      "\n",
      "Epoch: 155\n",
      "train loss:  2.7786742988973856\n",
      "train accuracy:  0.9985\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.747978614643216\n",
      "test accuracy:  0.9479\n",
      "\n",
      "Epoch: 156\n",
      "train loss:  2.5336654046550393\n",
      "train accuracy:  0.99872\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.89111702889204\n",
      "test accuracy:  0.9489\n",
      "\n",
      "Epoch: 157\n",
      "train loss:  2.329383977688849\n",
      "train accuracy:  0.99898\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.591088980436325\n",
      "test accuracy:  0.9485\n",
      "\n",
      "Epoch: 158\n",
      "train loss:  1.9609612943604589\n",
      "train accuracy:  0.99928\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.646157456561923\n",
      "test accuracy:  0.9482\n",
      "\n",
      "Epoch: 159\n",
      "train loss:  1.9393472732044756\n",
      "train accuracy:  0.99922\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.624318275600672\n",
      "test accuracy:  0.9488\n",
      "\n",
      "Epoch: 160\n",
      "train loss:  1.8300698153907433\n",
      "train accuracy:  0.99926\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.522314505651593\n",
      "test accuracy:  0.9502\n",
      "\n",
      "Epoch: 161\n",
      "train loss:  1.7369658679235727\n",
      "train accuracy:  0.99942\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.618867367506027\n",
      "test accuracy:  0.9505\n",
      "\n",
      "Epoch: 162\n",
      "train loss:  1.6093602613545954\n",
      "train accuracy:  0.99964\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.573331970721483\n",
      "test accuracy:  0.9497\n",
      "\n",
      "Epoch: 163\n",
      "train loss:  1.5005869145970792\n",
      "train accuracy:  0.9995\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.585350789129734\n",
      "test accuracy:  0.9486\n",
      "\n",
      "Epoch: 164\n",
      "train loss:  1.593872619792819\n",
      "train accuracy:  0.99942\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.606304679065943\n",
      "test accuracy:  0.9487\n",
      "\n",
      "Epoch: 165\n",
      "train loss:  1.5879587214440107\n",
      "train accuracy:  0.99938\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.490257455036044\n",
      "test accuracy:  0.9506\n",
      "\n",
      "Epoch: 166\n",
      "train loss:  1.457038113847375\n",
      "train accuracy:  0.99964\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.721052270382643\n",
      "test accuracy:  0.949\n",
      "\n",
      "Epoch: 167\n",
      "train loss:  1.2179931411519647\n",
      "train accuracy:  0.99976\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.386471254751086\n",
      "test accuracy:  0.9502\n",
      "\n",
      "Epoch: 168\n",
      "train loss:  1.3535570977255702\n",
      "train accuracy:  0.99968\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.462865652516484\n",
      "test accuracy:  0.9506\n",
      "\n",
      "Epoch: 169\n",
      "train loss:  1.330433847848326\n",
      "train accuracy:  0.99968\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.455211129039526\n",
      "test accuracy:  0.9496\n",
      "\n",
      "Epoch: 170\n",
      "train loss:  1.2714231787249446\n",
      "train accuracy:  0.99968\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.46971782296896\n",
      "test accuracy:  0.9507\n",
      "\n",
      "Epoch: 171\n",
      "train loss:  1.2841395461000502\n",
      "train accuracy:  0.99966\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.317947294563055\n",
      "test accuracy:  0.9503\n",
      "\n",
      "Epoch: 172\n",
      "train loss:  1.2699052831158042\n",
      "train accuracy:  0.99966\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.3701601177454\n",
      "test accuracy:  0.9502\n",
      "\n",
      "Epoch: 173\n",
      "train loss:  1.1828599270666018\n",
      "train accuracy:  0.99966\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.222714640200138\n",
      "test accuracy:  0.9501\n",
      "\n",
      "Epoch: 174\n",
      "train loss:  1.147503487765789\n",
      "train accuracy:  0.99978\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.489087861031294\n",
      "test accuracy:  0.9501\n",
      "\n",
      "Epoch: 175\n",
      "train loss:  1.0777389432769269\n",
      "train accuracy:  0.99984\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.203954134136438\n",
      "test accuracy:  0.9508\n",
      "\n",
      "Epoch: 176\n",
      "train loss:  1.1111783739179373\n",
      "train accuracy:  0.99968\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.275537975132465\n",
      "test accuracy:  0.9495\n",
      "\n",
      "Epoch: 177\n",
      "train loss:  1.1519240352790803\n",
      "train accuracy:  0.99978\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.298295874148607\n",
      "test accuracy:  0.9499\n",
      "\n",
      "Epoch: 178\n",
      "train loss:  1.057872922741808\n",
      "train accuracy:  0.99978\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.372676432132721\n",
      "test accuracy:  0.9505\n",
      "\n",
      "Epoch: 179\n",
      "train loss:  1.1236812446732074\n",
      "train accuracy:  0.9997\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.235905228182673\n",
      "test accuracy:  0.9503\n",
      "\n",
      "Epoch: 180\n",
      "train loss:  1.1583253651624545\n",
      "train accuracy:  0.99956\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.299770284444094\n",
      "test accuracy:  0.9517\n",
      "\n",
      "Epoch: 181\n",
      "train loss:  1.0644086111569777\n",
      "train accuracy:  0.99976\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.458507964387536\n",
      "test accuracy:  0.9497\n",
      "\n",
      "Epoch: 182\n",
      "train loss:  0.9388992905151099\n",
      "train accuracy:  0.9999\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.384122371673584\n",
      "test accuracy:  0.9505\n",
      "\n",
      "Epoch: 183\n",
      "train loss:  1.0289553866023198\n",
      "train accuracy:  0.99978\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.15849014185369\n",
      "test accuracy:  0.9502\n",
      "\n",
      "Epoch: 184\n",
      "train loss:  1.031205628067255\n",
      "train accuracy:  0.99972\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.114386226981878\n",
      "test accuracy:  0.9501\n",
      "\n",
      "Epoch: 185\n",
      "train loss:  0.9361818197648972\n",
      "train accuracy:  0.9999\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.382950050756335\n",
      "test accuracy:  0.9496\n",
      "\n",
      "Epoch: 186\n",
      "train loss:  1.024460696382448\n",
      "train accuracy:  0.99974\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.218942938372493\n",
      "test accuracy:  0.9496\n",
      "\n",
      "Epoch: 187\n",
      "train loss:  1.017115727532655\n",
      "train accuracy:  0.99976\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.069010380655527\n",
      "test accuracy:  0.9517\n",
      "\n",
      "Epoch: 188\n",
      "train loss:  1.0165825735311955\n",
      "train accuracy:  0.99984\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.907794652506709\n",
      "test accuracy:  0.9519\n",
      "\n",
      "Epoch: 189\n",
      "train loss:  0.9771692915819585\n",
      "train accuracy:  0.99982\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.0648725181818\n",
      "test accuracy:  0.9503\n",
      "\n",
      "Epoch: 190\n",
      "train loss:  0.8888269863091409\n",
      "train accuracy:  0.99984\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.227352829650044\n",
      "test accuracy:  0.9498\n",
      "\n",
      "Epoch: 191\n",
      "train loss:  0.9624035758897662\n",
      "train accuracy:  0.99986\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.17323330976069\n",
      "test accuracy:  0.951\n",
      "\n",
      "Epoch: 192\n",
      "train loss:  0.9856910102535039\n",
      "train accuracy:  0.9998\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.246055249124765\n",
      "test accuracy:  0.9505\n",
      "\n",
      "Epoch: 193\n",
      "train loss:  0.9304495635442436\n",
      "train accuracy:  0.9999\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.074654497206211\n",
      "test accuracy:  0.9518\n",
      "\n",
      "Epoch: 194\n",
      "train loss:  0.904881423804909\n",
      "train accuracy:  0.99986\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.099167078733444\n",
      "test accuracy:  0.9521\n",
      "\n",
      "Epoch: 195\n",
      "train loss:  0.8987862772773951\n",
      "train accuracy:  0.99986\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.033713150769472\n",
      "test accuracy:  0.9509\n",
      "\n",
      "Epoch: 196\n",
      "train loss:  0.8817692615557462\n",
      "train accuracy:  0.99986\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.904804438352585\n",
      "test accuracy:  0.9521\n",
      "\n",
      "Epoch: 197\n",
      "train loss:  0.8422361873090267\n",
      "train accuracy:  0.99988\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.142486630007625\n",
      "test accuracy:  0.9502\n",
      "\n",
      "Epoch: 198\n",
      "train loss:  0.9006566650932655\n",
      "train accuracy:  0.99986\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.228581195697188\n",
      "test accuracy:  0.9511\n",
      "\n",
      "Epoch: 199\n",
      "train loss:  0.9034080009441823\n",
      "train accuracy:  0.99984\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.137750057503581\n",
      "test accuracy:  0.9518\n"
     ]
    }
   ],
   "source": [
    "train_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.137750057503581\n",
      "test accuracy:  0.9518\n"
     ]
    }
   ],
   "source": [
    "##### if you already have a trained model ##############\n",
    "CIFAR10_PATH = 'weights/cifar10_resnet18_SGD.pth'\n",
    "CIFAR10_model = ResNet18().to(device)\n",
    "print(\"loading model from: {}\".format(CIFAR10_PATH))\n",
    "CIFAR10_model.load_state_dict(torch.load(CIFAR10_PATH))#, map_location=torch.device('cpu')))\n",
    "#test the model\n",
    "test(CIFAR10_model, 0, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Diag_second_order(model, train_loader, var0 = 10, device='cpu'):\n",
    "\n",
    "    W = list(model.parameters())[-2]\n",
    "    b = list(model.parameters())[-1]\n",
    "    m, n = W.shape\n",
    "    print(\"n: {} inputs to linear layer with m: {} classes\".format(n, m))\n",
    "    lossfunc = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    tau = 1/var0\n",
    "\n",
    "    extend(lossfunc, debug=False)\n",
    "    extend(model.fc, debug=False)\n",
    "\n",
    "    with backpack(DiagHessian()):\n",
    "\n",
    "        max_len = len(train_loader)\n",
    "        weights_cov = torch.zeros(max_len, m, n, device=device)\n",
    "        biases_cov = torch.zeros(max_len, m, device=device)\n",
    "\n",
    "        for batch_idx, (x, y) in enumerate(train_loader):\n",
    "\n",
    "            if device == 'cuda':\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "\n",
    "            model.zero_grad()\n",
    "            lossfunc(model(x), y).backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Hessian of weight\n",
    "                W_ = W.diag_h\n",
    "                b_ = b.diag_h\n",
    "\n",
    "                #add_prior: since it will be flattened later we can just add the prior like that\n",
    "                W_ += tau * torch.ones(W_.size(), device=device)\n",
    "                b_ += tau * torch.ones(b_.size(), device=device)\n",
    "\n",
    "\n",
    "            weights_cov[batch_idx] = W_\n",
    "            biases_cov[batch_idx] = b_\n",
    "\n",
    "            print(\"Batch: {}/{}\".format(batch_idx, max_len))\n",
    "\n",
    "        print(len(weights_cov))\n",
    "        C_W = torch.mean(weights_cov, dim=0)\n",
    "        C_b = torch.mean(biases_cov, dim=0)\n",
    "\n",
    "    # Predictive distribution\n",
    "    with torch.no_grad():\n",
    "        M_W_post = W.t()\n",
    "        M_b_post = b\n",
    "\n",
    "        C_W_post = C_W\n",
    "        C_b_post = C_b\n",
    "        \n",
    "    print(\"M_W_post size: \", M_W_post.size())\n",
    "    print(\"M_b_post size: \", M_b_post.size())\n",
    "    print(\"C_W_post size: \", C_W_post.size())\n",
    "    print(\"C_b_post size: \", C_b_post.size())\n",
    "\n",
    "    return(M_W_post, M_b_post, C_W_post, C_b_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 512 inputs to linear layer with m: 10 classes\n",
      "Batch: 0/391\n",
      "Batch: 1/391\n",
      "Batch: 2/391\n",
      "Batch: 3/391\n",
      "Batch: 4/391\n",
      "Batch: 5/391\n",
      "Batch: 6/391\n",
      "Batch: 7/391\n",
      "Batch: 8/391\n",
      "Batch: 9/391\n",
      "Batch: 10/391\n",
      "Batch: 11/391\n",
      "Batch: 12/391\n",
      "Batch: 13/391\n",
      "Batch: 14/391\n",
      "Batch: 15/391\n",
      "Batch: 16/391\n",
      "Batch: 17/391\n",
      "Batch: 18/391\n",
      "Batch: 19/391\n",
      "Batch: 20/391\n",
      "Batch: 21/391\n",
      "Batch: 22/391\n",
      "Batch: 23/391\n",
      "Batch: 24/391\n",
      "Batch: 25/391\n",
      "Batch: 26/391\n",
      "Batch: 27/391\n",
      "Batch: 28/391\n",
      "Batch: 29/391\n",
      "Batch: 30/391\n",
      "Batch: 31/391\n",
      "Batch: 32/391\n",
      "Batch: 33/391\n",
      "Batch: 34/391\n",
      "Batch: 35/391\n",
      "Batch: 36/391\n",
      "Batch: 37/391\n",
      "Batch: 38/391\n",
      "Batch: 39/391\n",
      "Batch: 40/391\n",
      "Batch: 41/391\n",
      "Batch: 42/391\n",
      "Batch: 43/391\n",
      "Batch: 44/391\n",
      "Batch: 45/391\n",
      "Batch: 46/391\n",
      "Batch: 47/391\n",
      "Batch: 48/391\n",
      "Batch: 49/391\n",
      "Batch: 50/391\n",
      "Batch: 51/391\n",
      "Batch: 52/391\n",
      "Batch: 53/391\n",
      "Batch: 54/391\n",
      "Batch: 55/391\n",
      "Batch: 56/391\n",
      "Batch: 57/391\n",
      "Batch: 58/391\n",
      "Batch: 59/391\n",
      "Batch: 60/391\n",
      "Batch: 61/391\n",
      "Batch: 62/391\n",
      "Batch: 63/391\n",
      "Batch: 64/391\n",
      "Batch: 65/391\n",
      "Batch: 66/391\n",
      "Batch: 67/391\n",
      "Batch: 68/391\n",
      "Batch: 69/391\n",
      "Batch: 70/391\n",
      "Batch: 71/391\n",
      "Batch: 72/391\n",
      "Batch: 73/391\n",
      "Batch: 74/391\n",
      "Batch: 75/391\n",
      "Batch: 76/391\n",
      "Batch: 77/391\n",
      "Batch: 78/391\n",
      "Batch: 79/391\n",
      "Batch: 80/391\n",
      "Batch: 81/391\n",
      "Batch: 82/391\n",
      "Batch: 83/391\n",
      "Batch: 84/391\n",
      "Batch: 85/391\n",
      "Batch: 86/391\n",
      "Batch: 87/391\n",
      "Batch: 88/391\n",
      "Batch: 89/391\n",
      "Batch: 90/391\n",
      "Batch: 91/391\n",
      "Batch: 92/391\n",
      "Batch: 93/391\n",
      "Batch: 94/391\n",
      "Batch: 95/391\n",
      "Batch: 96/391\n",
      "Batch: 97/391\n",
      "Batch: 98/391\n",
      "Batch: 99/391\n",
      "Batch: 100/391\n",
      "Batch: 101/391\n",
      "Batch: 102/391\n",
      "Batch: 103/391\n",
      "Batch: 104/391\n",
      "Batch: 105/391\n",
      "Batch: 106/391\n",
      "Batch: 107/391\n",
      "Batch: 108/391\n",
      "Batch: 109/391\n",
      "Batch: 110/391\n",
      "Batch: 111/391\n",
      "Batch: 112/391\n",
      "Batch: 113/391\n",
      "Batch: 114/391\n",
      "Batch: 115/391\n",
      "Batch: 116/391\n",
      "Batch: 117/391\n",
      "Batch: 118/391\n",
      "Batch: 119/391\n",
      "Batch: 120/391\n",
      "Batch: 121/391\n",
      "Batch: 122/391\n",
      "Batch: 123/391\n",
      "Batch: 124/391\n",
      "Batch: 125/391\n",
      "Batch: 126/391\n",
      "Batch: 127/391\n",
      "Batch: 128/391\n",
      "Batch: 129/391\n",
      "Batch: 130/391\n",
      "Batch: 131/391\n",
      "Batch: 132/391\n",
      "Batch: 133/391\n",
      "Batch: 134/391\n",
      "Batch: 135/391\n",
      "Batch: 136/391\n",
      "Batch: 137/391\n",
      "Batch: 138/391\n",
      "Batch: 139/391\n",
      "Batch: 140/391\n",
      "Batch: 141/391\n",
      "Batch: 142/391\n",
      "Batch: 143/391\n",
      "Batch: 144/391\n",
      "Batch: 145/391\n",
      "Batch: 146/391\n",
      "Batch: 147/391\n",
      "Batch: 148/391\n",
      "Batch: 149/391\n",
      "Batch: 150/391\n",
      "Batch: 151/391\n",
      "Batch: 152/391\n",
      "Batch: 153/391\n",
      "Batch: 154/391\n",
      "Batch: 155/391\n",
      "Batch: 156/391\n",
      "Batch: 157/391\n",
      "Batch: 158/391\n",
      "Batch: 159/391\n",
      "Batch: 160/391\n",
      "Batch: 161/391\n",
      "Batch: 162/391\n",
      "Batch: 163/391\n",
      "Batch: 164/391\n",
      "Batch: 165/391\n",
      "Batch: 166/391\n",
      "Batch: 167/391\n",
      "Batch: 168/391\n",
      "Batch: 169/391\n",
      "Batch: 170/391\n",
      "Batch: 171/391\n",
      "Batch: 172/391\n",
      "Batch: 173/391\n",
      "Batch: 174/391\n",
      "Batch: 175/391\n",
      "Batch: 176/391\n",
      "Batch: 177/391\n",
      "Batch: 178/391\n",
      "Batch: 179/391\n",
      "Batch: 180/391\n",
      "Batch: 181/391\n",
      "Batch: 182/391\n",
      "Batch: 183/391\n",
      "Batch: 184/391\n",
      "Batch: 185/391\n",
      "Batch: 186/391\n",
      "Batch: 187/391\n",
      "Batch: 188/391\n",
      "Batch: 189/391\n",
      "Batch: 190/391\n",
      "Batch: 191/391\n",
      "Batch: 192/391\n",
      "Batch: 193/391\n",
      "Batch: 194/391\n",
      "Batch: 195/391\n",
      "Batch: 196/391\n",
      "Batch: 197/391\n",
      "Batch: 198/391\n",
      "Batch: 199/391\n",
      "Batch: 200/391\n",
      "Batch: 201/391\n",
      "Batch: 202/391\n",
      "Batch: 203/391\n",
      "Batch: 204/391\n",
      "Batch: 205/391\n",
      "Batch: 206/391\n",
      "Batch: 207/391\n",
      "Batch: 208/391\n",
      "Batch: 209/391\n",
      "Batch: 210/391\n",
      "Batch: 211/391\n",
      "Batch: 212/391\n",
      "Batch: 213/391\n",
      "Batch: 214/391\n",
      "Batch: 215/391\n",
      "Batch: 216/391\n",
      "Batch: 217/391\n",
      "Batch: 218/391\n",
      "Batch: 219/391\n",
      "Batch: 220/391\n",
      "Batch: 221/391\n",
      "Batch: 222/391\n",
      "Batch: 223/391\n",
      "Batch: 224/391\n",
      "Batch: 225/391\n",
      "Batch: 226/391\n",
      "Batch: 227/391\n",
      "Batch: 228/391\n",
      "Batch: 229/391\n",
      "Batch: 230/391\n",
      "Batch: 231/391\n",
      "Batch: 232/391\n",
      "Batch: 233/391\n",
      "Batch: 234/391\n",
      "Batch: 235/391\n",
      "Batch: 236/391\n",
      "Batch: 237/391\n",
      "Batch: 238/391\n",
      "Batch: 239/391\n",
      "Batch: 240/391\n",
      "Batch: 241/391\n",
      "Batch: 242/391\n",
      "Batch: 243/391\n",
      "Batch: 244/391\n",
      "Batch: 245/391\n",
      "Batch: 246/391\n",
      "Batch: 247/391\n",
      "Batch: 248/391\n",
      "Batch: 249/391\n",
      "Batch: 250/391\n",
      "Batch: 251/391\n",
      "Batch: 252/391\n",
      "Batch: 253/391\n",
      "Batch: 254/391\n",
      "Batch: 255/391\n",
      "Batch: 256/391\n",
      "Batch: 257/391\n",
      "Batch: 258/391\n",
      "Batch: 259/391\n",
      "Batch: 260/391\n",
      "Batch: 261/391\n",
      "Batch: 262/391\n",
      "Batch: 263/391\n",
      "Batch: 264/391\n",
      "Batch: 265/391\n",
      "Batch: 266/391\n",
      "Batch: 267/391\n",
      "Batch: 268/391\n",
      "Batch: 269/391\n",
      "Batch: 270/391\n",
      "Batch: 271/391\n",
      "Batch: 272/391\n",
      "Batch: 273/391\n",
      "Batch: 274/391\n",
      "Batch: 275/391\n",
      "Batch: 276/391\n",
      "Batch: 277/391\n",
      "Batch: 278/391\n",
      "Batch: 279/391\n",
      "Batch: 280/391\n",
      "Batch: 281/391\n",
      "Batch: 282/391\n",
      "Batch: 283/391\n",
      "Batch: 284/391\n",
      "Batch: 285/391\n",
      "Batch: 286/391\n",
      "Batch: 287/391\n",
      "Batch: 288/391\n",
      "Batch: 289/391\n",
      "Batch: 290/391\n",
      "Batch: 291/391\n",
      "Batch: 292/391\n",
      "Batch: 293/391\n",
      "Batch: 294/391\n",
      "Batch: 295/391\n",
      "Batch: 296/391\n",
      "Batch: 297/391\n",
      "Batch: 298/391\n",
      "Batch: 299/391\n",
      "Batch: 300/391\n",
      "Batch: 301/391\n",
      "Batch: 302/391\n",
      "Batch: 303/391\n",
      "Batch: 304/391\n",
      "Batch: 305/391\n",
      "Batch: 306/391\n",
      "Batch: 307/391\n",
      "Batch: 308/391\n",
      "Batch: 309/391\n",
      "Batch: 310/391\n",
      "Batch: 311/391\n",
      "Batch: 312/391\n",
      "Batch: 313/391\n",
      "Batch: 314/391\n",
      "Batch: 315/391\n",
      "Batch: 316/391\n",
      "Batch: 317/391\n",
      "Batch: 318/391\n",
      "Batch: 319/391\n",
      "Batch: 320/391\n",
      "Batch: 321/391\n",
      "Batch: 322/391\n",
      "Batch: 323/391\n",
      "Batch: 324/391\n",
      "Batch: 325/391\n",
      "Batch: 326/391\n",
      "Batch: 327/391\n",
      "Batch: 328/391\n",
      "Batch: 329/391\n",
      "Batch: 330/391\n",
      "Batch: 331/391\n",
      "Batch: 332/391\n",
      "Batch: 333/391\n",
      "Batch: 334/391\n",
      "Batch: 335/391\n",
      "Batch: 336/391\n",
      "Batch: 337/391\n",
      "Batch: 338/391\n",
      "Batch: 339/391\n",
      "Batch: 340/391\n",
      "Batch: 341/391\n",
      "Batch: 342/391\n",
      "Batch: 343/391\n",
      "Batch: 344/391\n",
      "Batch: 345/391\n",
      "Batch: 346/391\n",
      "Batch: 347/391\n",
      "Batch: 348/391\n",
      "Batch: 349/391\n",
      "Batch: 350/391\n",
      "Batch: 351/391\n",
      "Batch: 352/391\n",
      "Batch: 353/391\n",
      "Batch: 354/391\n",
      "Batch: 355/391\n",
      "Batch: 356/391\n",
      "Batch: 357/391\n",
      "Batch: 358/391\n",
      "Batch: 359/391\n",
      "Batch: 360/391\n",
      "Batch: 361/391\n",
      "Batch: 362/391\n",
      "Batch: 363/391\n",
      "Batch: 364/391\n",
      "Batch: 365/391\n",
      "Batch: 366/391\n",
      "Batch: 367/391\n",
      "Batch: 368/391\n",
      "Batch: 369/391\n",
      "Batch: 370/391\n",
      "Batch: 371/391\n",
      "Batch: 372/391\n",
      "Batch: 373/391\n",
      "Batch: 374/391\n",
      "Batch: 375/391\n",
      "Batch: 376/391\n",
      "Batch: 377/391\n",
      "Batch: 378/391\n",
      "Batch: 379/391\n",
      "Batch: 380/391\n",
      "Batch: 381/391\n",
      "Batch: 382/391\n",
      "Batch: 383/391\n",
      "Batch: 384/391\n",
      "Batch: 385/391\n",
      "Batch: 386/391\n",
      "Batch: 387/391\n",
      "Batch: 388/391\n",
      "Batch: 389/391\n",
      "Batch: 390/391\n",
      "391\n",
      "M_W_post size:  torch.Size([512, 10])\n",
      "M_b_post size:  torch.Size([10])\n",
      "C_W_post size:  torch.Size([10, 512])\n",
      "C_b_post size:  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D = Diag_second_order(model=CIFAR10_model,\n",
    "                                                               train_loader=trainloader,\n",
    "                                                               var0 = 10,\n",
    "                                                               device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_in_dist_values(py_in, targets):\n",
    "    acc_in = np.mean(np.argmax(py_in, 1) == targets)\n",
    "    #prob_correct = np.choose(targets, py_in.T).mean()\n",
    "    prob_correct = py_in[targets].mean()\n",
    "    average_entropy = -np.sum(py_in*np.log(py_in+1e-8), axis=1).mean()\n",
    "    MMC = py_in.max(1).mean()\n",
    "    return(acc_in, prob_correct, average_entropy, MMC)\n",
    "\n",
    "def get_out_dist_values(py_in, py_out, targets):\n",
    "    average_entropy = -np.sum(py_out*np.log(py_out+1e-8), axis=1).mean()\n",
    "    acc_out = np.mean(np.argmax(py_out, 1) == targets)\n",
    "    if max(targets) > len(py_in[0]):\n",
    "        targets = np.array(targets)\n",
    "        targets[targets >= len(py_in[0])] = 0\n",
    "    #prob_correct = np.choose(targets, py_out.T).mean()\n",
    "    prob_correct = py_out[targets].mean()\n",
    "    labels = np.zeros(len(py_in)+len(py_out), dtype='int32')\n",
    "    labels[:len(py_in)] = 1\n",
    "    examples = np.concatenate([py_in.max(1), py_out.max(1)])\n",
    "    auroc = roc_auc_score(labels, examples)\n",
    "    MMC = py_out.max(1).mean()\n",
    "    return(acc_out, prob_correct, average_entropy, MMC, auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Gaussian_output_old(x, mu_w, mu_b, sigma_w, sigma_b):\n",
    "    #get the distributions per class\n",
    "    batch_size = x.size(0)\n",
    "    num_classes = len(mu_b)\n",
    "    #print(\"batch_size, num_classes: \", batch_size, num_classes)\n",
    "    mu_batch = torch.zeros(batch_size, num_classes)\n",
    "    sigma_batch = torch.zeros(batch_size, num_classes, num_classes)\n",
    "    for i in range(batch_size):\n",
    "        per_class_sigmas = torch.zeros(num_classes)\n",
    "        for j in range(num_classes):\n",
    "            #create a diagonal Hessian\n",
    "            hess = torch.diag(sigma_w[j])\n",
    "            #b = x[i] @ hess @ x[i].t()\n",
    "            #a = sigma_b[i]\n",
    "            per_class_sigmas[j] = x[i] @ hess @ x[i].t() + sigma_b[j]\n",
    "\n",
    "        #print(\"sizes: \", mu_w.size(), x[i].size(), mu_b.size())\n",
    "        per_class_mus = x[i] @ mu_w + mu_b\n",
    "        mu_batch[i] = per_class_mus\n",
    "        sigma_batch[i] = torch.diag(per_class_sigmas)\n",
    "\n",
    "    return(mu_batch, sigma_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Gaussian_output(x, mu_w, mu_b, sigma_w, sigma_b):\n",
    "    #get the distributions per class\n",
    "    batch_size = x.size(0)\n",
    "    num_classes = mu_b.size(0)\n",
    "    \n",
    "    # get mu batch\n",
    "    mu_w_batch = mu_w.repeat(batch_size, 1, 1)\n",
    "    mu_b_batch = mu_b.repeat(batch_size, 1)\n",
    "    mu_batch = torch.bmm(x.view(batch_size, 1, -1), mu_w_batch).view(batch_size, -1) + mu_b_batch\n",
    "    \n",
    "    #get sigma batch\n",
    "    sigma_w_batch = sigma_w.repeat(batch_size, 1, 1)\n",
    "    sigma_b_batch = sigma_b.repeat(batch_size, 1)\n",
    "    sigmas_diag = torch.zeros(batch_size, num_classes, device='cuda')\n",
    "    for j in range(num_classes):\n",
    "        h1 = x * sigma_w_batch[:, j]\n",
    "        helper = torch.matmul(h1.view(batch_size, 1, -1), x.view(batch_size, -1, 1))\n",
    "        helper = helper.view(-1) + sigma_b_batch[:,j]\n",
    "        sigmas_diag[:,j] = helper\n",
    "        \n",
    "    sigma_batch = torch.stack([torch.diag(x) for x in sigmas_diag])\n",
    "\n",
    "    \n",
    "    return(mu_batch, sigma_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_diagonal_sampling(model, test_loader, M_W_post, M_b_post, C_W_post, C_b_post, n_samples, verbose=False, cuda=False, timing=False):\n",
    "    py = []\n",
    "    max_len = len(test_loader)\n",
    "    if timing:\n",
    "        time_sum = 0\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(test_loader):\n",
    "\n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        phi = model.phi(x)\n",
    "\n",
    "        mu, Sigma = get_Gaussian_output(phi, M_W_post, M_b_post, C_W_post, C_b_post)\n",
    "        #print(\"mu size: \", mu.size())\n",
    "        #print(\"sigma size: \", Sigma.size())\n",
    "\n",
    "        post_pred = MultivariateNormal(mu, Sigma)\n",
    "\n",
    "        # MC-integral\n",
    "        t0 = time.time()\n",
    "        py_ = 0\n",
    "\n",
    "        for _ in range(n_samples):\n",
    "            f_s = post_pred.rsample()\n",
    "            py_ += torch.softmax(f_s, 1)\n",
    "\n",
    "        py_ /= n_samples\n",
    "        py_ = py_.detach()\n",
    "\n",
    "        py.append(py_)\n",
    "        t1 = time.time()\n",
    "        if timing:\n",
    "            time_sum += (t1 - t0)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Batch: {}/{}\".format(batch_idx, max_len))\n",
    "\n",
    "    if timing: print(\"time used for sampling with {} samples: {}\".format(n_samples, time_sum))\n",
    "    \n",
    "    return torch.cat(py, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_CIFAR10 = testset.targets\n",
    "targets_CIFAR100 = CIFAR100_test.targets\n",
    "targets_SVHN = []\n",
    "for x,y in test_loader_SVHN:\n",
    "    targets_SVHN.append(y)\n",
    "targets_SVHN = torch.cat(targets_SVHN).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_test_in_MAP = predict_MAP(CIFAR10_model, testloader, cuda=True).cpu().numpy()\n",
    "CIFAR10_test_out_CIFAR100_MAP = predict_MAP(CIFAR10_model, CIFAR100_test_loader, cuda=True).cpu().numpy()\n",
    "CIFAR10_test_out_SVHN_MAP = predict_MAP(CIFAR10_model, test_loader_SVHN, cuda=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP = get_in_dist_values(CIFAR10_test_in_MAP, targets_CIFAR10)\n",
    "acc_out_CIFAR100_MAP, prob_correct_out_CIFAR100_MAP, ent_out_CIFAR100, MMC_out_CIFAR100_MAP, auroc_out_CIFAR100_MAP = get_out_dist_values(CIFAR10_test_in_MAP, CIFAR10_test_out_CIFAR100_MAP, targets_CIFAR100)\n",
    "acc_out_SVHN_MAP, prob_correct_out_SVHN_MAP, ent_out_SVHN, MMC_out_SVHN_MAP, auroc_out_SVHN_MAP = get_out_dist_values(CIFAR10_test_in_MAP, CIFAR10_test_out_SVHN_MAP, targets_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, MAP, CIFAR10] Accuracy: 0.952; average entropy: 0.066;     MMC: 0.979; Prob @ correct: 0.100\n",
      "[Out-MAP, KFAC, CIFAR100] Accuracy: 0.009; Average entropy: 0.497;    MMC: 0.828; AUROC: 0.874; Prob @ correct: 0.100\n",
      "[Out-MAP, KFAC, SVHN] Accuracy: 0.112; Average entropy: 0.604;    MMC: 0.793; AUROC: 0.925; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP, 'CIFAR10', 'MAP')\n",
    "print_out_dist_values(acc_out_CIFAR100_MAP, prob_correct_out_CIFAR100_MAP, ent_out_CIFAR100, MMC_out_CIFAR100_MAP, auroc_out_CIFAR100_MAP, 'CIFAR100', 'MAP')\n",
    "print_out_dist_values(acc_out_SVHN_MAP, prob_correct_out_SVHN_MAP, ent_out_SVHN, MMC_out_SVHN_MAP, auroc_out_SVHN_MAP, 'SVHN', 'MAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.952 with std 0.001\n",
      "MMC in: 0.978 with std 0.001\n",
      "MMC out CIFAR100: 0.828 with std 0.001\n",
      "MMC out SVHN: 0.777 with std 0.030\n",
      "AUROC out CIFAR100: 0.872 with std 0.004\n",
      "AUROC out SVHN: 0.925 with std 0.008\n"
     ]
    }
   ],
   "source": [
    "#MAP estimate\n",
    "#seeds are 123,124,125,126,127\n",
    "acc_in = [0.953, 0.952, 0.952, 0.950, 0.952]\n",
    "mmc_in = [0.979, 0.978, 0.979, 0.976, 0.979]\n",
    "mmc_out_CIFAR100 = [0.831, 0.827, 0.829, 0.827, 0.828]\n",
    "mmc_out_SVHN = [0.721, 0.809, 0.780, 0.784, 0.793]\n",
    "\n",
    "auroc_out_CIFAR100 = [0.872, 0.877, 0.874, 0.864, 0.874]\n",
    "auroc_out_SVHN = [0.939, 0.919, 0.927, 0.917, 0.925]\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagonal estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used for sampling with 1000 samples: 6.642724990844727\n",
      "time used for sampling with 1000 samples: 6.6236491203308105\n",
      "time used for sampling with 1000 samples: 17.064507722854614\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_test_in_D = predict_diagonal_sampling(CIFAR10_model, testloader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, n_samples=1000, cuda=True, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_CIFAR100_D = predict_diagonal_sampling(CIFAR10_model, CIFAR100_test_loader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, n_samples=1000, cuda=True, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_SVHN_D = predict_diagonal_sampling(CIFAR10_model, test_loader_SVHN, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, n_samples=1000, cuda=True, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D = get_in_dist_values(CIFAR10_test_in_D, targets_CIFAR10)\n",
    "acc_out_CIFAR100_D, prob_correct_out_CIFAR100_D, ent_out_CIFAR100_D, MMC_out_CIFAR100_D, auroc_out_CIFAR100_D = get_out_dist_values(CIFAR10_test_in_D, CIFAR10_test_out_CIFAR100_D, targets_CIFAR100)\n",
    "acc_out_SVHN_D, prob_correct_out_SVHN_D, ent_out_SVHN_D, MMC_out_SVHN_D, auroc_out_SVHN_D = get_out_dist_values(CIFAR10_test_in_D, CIFAR10_test_out_SVHN_D, targets_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, Diag, CIFAR10] Accuracy: 0.952; average entropy: 0.194;     MMC: 0.950; Prob @ correct: 0.100\n",
      "[Out-Diag, KFAC, CIFAR100] Accuracy: 0.009; Average entropy: 0.497;    MMC: 0.724; AUROC: 0.884; Prob @ correct: 0.100\n",
      "[Out-Diag, KFAC, SVHN] Accuracy: 0.112; Average entropy: 0.971;    MMC: 0.674; AUROC: 0.931; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D, 'CIFAR10', 'Diag')\n",
    "print_out_dist_values(acc_out_CIFAR100_D, prob_correct_out_CIFAR100_D, ent_out_CIFAR100, MMC_out_CIFAR100_D, auroc_out_CIFAR100_D, 'CIFAR100', 'Diag')\n",
    "print_out_dist_values(acc_out_SVHN_D, prob_correct_out_SVHN_D, ent_out_SVHN_D, MMC_out_SVHN_D, auroc_out_SVHN_D, 'SVHN', 'Diag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Bridge time in: 6.635 with std 0.047\n",
      "Sampling Bridge time out CIFAR100: 6.577 with std 0.056\n",
      "Sampling Bridge time out SVHN: 16.983 with std 0.139\n",
      "accuracy: 0.952 with std 0.001\n",
      "MMC in: 0.949 with std 0.001\n",
      "MMC out CIFAR100: 0.724 with std 0.002\n",
      "MMC out SVHN: 0.659 with std 0.028\n",
      "AUROC out CIFAR100: 0.884 with std 0.004\n",
      "AUROC out SVHN: 0.931 with std 0.007\n"
     ]
    }
   ],
   "source": [
    "#Diag Sampling\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [6.636955976486206, 6.716174125671387, 6.57476282119751, 6.605843544006348, 6.642724990844727]\n",
    "time_lpb_out_CIFAR100 = [6.614115238189697, 6.61441969871521, 6.560410737991333, 6.474161148071289, 6.6236491203308105]\n",
    "time_lpb_out_SVHN = [17.011831521987915, 17.094997882843018, 17.031347036361694,16.71169662475586, 17.064507722854614]\n",
    "\n",
    "acc_in = [0.953, 0.952, 0.952, 0.950, 0.952]\n",
    "mmc_in = [0.950, 0.950, 0.950, 0.947, 0.950]\n",
    "mmc_out_CIFAR100 = [0.727, 0.721, 0.725, 0.724, 0.724]\n",
    "mmc_out_SVHN = [0.605, 0.685, 0.661, 0.672, 0.674]\n",
    "\n",
    "auroc_out_CIFAR100 = [0.884, 0.889, 0.885, 0.876, 0.884]\n",
    "auroc_out_SVHN = [0.943, 0.927, 0.933, 0.921, 0.931]\n",
    "\n",
    "print(\"Sampling Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Sampling Bridge time out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR100), np.std(time_lpb_out_CIFAR100)))\n",
    "print(\"Sampling Bridge time out SVHN: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_SVHN), np.std(time_lpb_out_SVHN)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet Laplace estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha_from_Normal(mu, Sigma):\n",
    "    batch_size, K = mu.size(0), mu.size(-1)\n",
    "    Sigma_d = torch.diagonal(Sigma, dim1=1, dim2=2)\n",
    "    sum_exp = torch.sum(torch.exp(-1*mu), dim=1).view(-1,1)\n",
    "    alpha = 1/Sigma_d * (1 - 2/K + torch.exp(mu)/K**2 * sum_exp)\n",
    "    \n",
    "    return(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "#U_post, V_post, B_post\n",
    "def predict_DIR_LPA(model, test_loader, M_W_post, M_b_post, C_W_post, C_b_post, verbose=False, cuda=False, timing=False):\n",
    "    alphas = []\n",
    "    if timing:\n",
    "        time_sum = 0\n",
    "\n",
    "    max_len = int(np.ceil(len(test_loader.dataset)/len(test_loader)))\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(test_loader):\n",
    "        \n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        phi = model.phi(x)\n",
    "\n",
    "        #mu_pred = phi @ M_W_post + M_b_post\n",
    "        #mu_pred -= mu_pred.mean(1).view(-1,1)\n",
    "        #Cov_pred = torch.diag(phi @ U_post @ phi.t()).reshape(-1, 1, 1) * V_post.unsqueeze(0) + B_post.unsqueeze(0)\n",
    "\n",
    "        mu_pred, Cov_pred = get_Gaussian_output(phi, M_W_post, M_b_post, C_W_post, C_b_post)\n",
    "        \n",
    "        t0 = time.time()\n",
    "        alpha = get_alpha_from_Normal(mu_pred, Cov_pred).detach()\n",
    "        t1 = time.time()\n",
    "        if timing:\n",
    "            time_sum += (t1-t0)\n",
    "\n",
    "        alphas.append(alpha)\n",
    "\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Batch: {}/{}\".format(batch_idx, max_len))\n",
    "\n",
    "    if timing:\n",
    "        print(\"total time used for transform: {:.05f}\".format(time_sum))\n",
    "    \n",
    "    return(torch.cat(alphas, dim = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used for transform: 0.01773\n",
      "total time used for transform: 0.01598\n",
      "total time used for transform: 0.04112\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_test_in_DIR_LPA = predict_DIR_LPA(CIFAR10_model, testloader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, cuda=True, verbose=False, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_CIFAR100_DIR_LPA = predict_DIR_LPA(CIFAR10_model, CIFAR100_test_loader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, cuda=True, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_SVHN_DIR_LPA = predict_DIR_LPA(CIFAR10_model, test_loader_SVHN, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, cuda=True, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize to get the MAP estimate (which is the mode) of the Dirichlet\n",
    "CIFAR10_test_in_DIR_LPAn = CIFAR10_test_in_DIR_LPA/CIFAR10_test_in_DIR_LPA.sum(1).reshape(-1,1)\n",
    "CIFAR10_test_out_CIFAR100_DIR_LPAn = CIFAR10_test_out_CIFAR100_DIR_LPA/CIFAR10_test_out_CIFAR100_DIR_LPA.sum(1).reshape(-1,1)\n",
    "CIFAR10_test_out_SVHN_DIR_LPAn = CIFAR10_test_out_SVHN_DIR_LPA/CIFAR10_test_out_SVHN_DIR_LPA.sum(1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_DIR_LPA, prob_correct_in_DIR_LPA, ent_in_DIR_LPA, MMC_in_DIR_LPA = get_in_dist_values(CIFAR10_test_in_DIR_LPAn, targets_CIFAR10)\n",
    "acc_out_CIFAR100_DIR_LPA, prob_correct_out_CIFAR100_DIR_LPA, ent_out_CIFAR100_DIR_LPA, MMC_out_CIFAR100_DIR_LPA, auroc_out_CIFAR100_DIR_LPA = get_out_dist_values(CIFAR10_test_in_DIR_LPAn, CIFAR10_test_out_CIFAR100_DIR_LPAn, targets_CIFAR100)\n",
    "acc_out_SVHN_DIR_LPA, prob_correct_out_SVHN_DIR_LPA, ent_out_SVHN_DIR_LPA, MMC_out_SVHN_DIR_LPA, auroc_out_SVHN_DIR_LPA = get_out_dist_values(CIFAR10_test_in_DIR_LPAn, CIFAR10_test_out_SVHN_DIR_LPAn, targets_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, DIR_LPA, CIFAR10] Accuracy: 0.952; average entropy: 0.120;     MMC: 0.970; Prob @ correct: 0.100\n",
      "[Out-DIR_LPA, KFAC, CIFAR100] Accuracy: 0.009; Average entropy: 0.765;    MMC: 0.771; AUROC: 0.862; Prob @ correct: 0.100\n",
      "[Out-DIR_LPA, KFAC, SVHN] Accuracy: 0.112; Average entropy: 0.962;    MMC: 0.715; AUROC: 0.925; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_DIR_LPA, prob_correct_in_DIR_LPA, ent_in_DIR_LPA, MMC_in_DIR_LPA, 'CIFAR10', 'DIR_LPA')\n",
    "print_out_dist_values(acc_out_CIFAR100_DIR_LPA, prob_correct_out_CIFAR100_DIR_LPA, ent_out_CIFAR100_DIR_LPA, MMC_out_CIFAR100_DIR_LPA, auroc_out_CIFAR100_DIR_LPA, 'CIFAR100', 'DIR_LPA')\n",
    "print_out_dist_values(acc_out_SVHN_DIR_LPA, prob_correct_out_SVHN_DIR_LPA, ent_out_SVHN_DIR_LPA, MMC_out_SVHN_DIR_LPA, auroc_out_SVHN_DIR_LPA, 'SVHN', 'DIR_LPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplace Bridge time in: 0.017 with std 0.000\n",
      "Laplace Bridge time out CIFAR100: 0.016 with std 0.000\n",
      "Laplace Bridge time out notmnist: 0.041 with std 0.000\n",
      "accuracy: 0.952 with std 0.001\n",
      "MMC in: 0.969 with std 0.002\n",
      "MMC out CIFAR100: 0.774 with std 0.003\n",
      "MMC out SVHN: 0.704 with std 0.036\n",
      "AUROC out CIFAR100: 0.858 with std 0.004\n",
      "AUROC out SVHN: 0.923 with std 0.008\n"
     ]
    }
   ],
   "source": [
    "#Laplace Bridge\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [0.01729, 0.01750, 0.01749,0.01724, 0.01773]\n",
    "time_lpb_out_CIFAR100 = [0.01571,0.01601, 0.01570, 0.01580, 0.01598]\n",
    "time_lpb_out_SVHN = [0.04075, 0.04107, 0.04046, 0.04067, 0.04112]\n",
    "\n",
    "\n",
    "acc_in = [0.953, 0.952, 0.952, 0.950, 0.952]\n",
    "mmc_in = [0.971, 0.970, 0.970, 0.966, 0.970]\n",
    "mmc_out_CIFAR100 = [0.779, 0.774, 0.775, 0.771, 0.771]\n",
    "mmc_out_SVHN = [0.639, 0.747, 0.719, 0.698, 0.715]\n",
    "\n",
    "\n",
    "auroc_out_CIFAR100 = [0.856, 0.863, 0.859, 0.852, 0.862]\n",
    "auroc_out_SVHN = [0.935, 0.912, 0.923, 0.919, 0.925]\n",
    "\n",
    "\n",
    "print(\"Laplace Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Laplace Bridge time out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR100), np.std(time_lpb_out_CIFAR100)))\n",
    "print(\"Laplace Bridge time out notmnist: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_SVHN), np.std(time_lpb_out_SVHN)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import digamma, loggamma\n",
    "\n",
    "def beta_function(alpha):\n",
    "    return(np.exp(np.sum([loggamma(a_i) for a_i in alpha]) - loggamma(np.sum(alpha))))\n",
    "\n",
    "def alphas_norm(alphas):\n",
    "    alphas = np.array(alphas)\n",
    "    return(alphas/alphas.sum(axis=1).reshape(-1,1))\n",
    "\n",
    "def alphas_variance(alphas):\n",
    "    alphas = np.array(alphas)\n",
    "    norm = alphas_norm(alphas)\n",
    "    nom = norm * (1 - norm)\n",
    "    den = alphas.sum(axis=1).reshape(-1,1) + 1\n",
    "    return(nom/den)\n",
    "\n",
    "def log_beta_function(alpha):\n",
    "    return(np.sum([loggamma(a_i) for a_i in alpha]) - loggamma(np.sum(alpha)))\n",
    "\n",
    "def alphas_entropy(alphas):\n",
    "    K = len(alphas[0])\n",
    "    alphas = np.array(alphas)\n",
    "    entropy = []\n",
    "    for x in alphas:\n",
    "        B = log_beta_function(x)\n",
    "        alpha_0 = np.sum(x)\n",
    "        C = (alpha_0 - K)*digamma(alpha_0)\n",
    "        D = np.sum((x-1)*digamma(x))\n",
    "        entropy.append(B + C - D)\n",
    "    \n",
    "    return(np.array(entropy))\n",
    "        \n",
    "\n",
    "def alphas_log_prob(alphas):\n",
    "    alphas = np.array(alphas)\n",
    "    dig_sum = digamma(alphas.sum(axis=1).reshape(-1,1))\n",
    "    log_prob = digamma(alphas) - dig_sum\n",
    "    return(log_prob)\n",
    "\n",
    "def auroc_entropy(alphas_in, alphas_out):\n",
    "    \n",
    "    entropy_in = alphas_entropy(alphas_in)\n",
    "    entropy_out = alphas_entropy(alphas_out)\n",
    "    labels = np.zeros(len(entropy_in)+len(entropy_out), dtype='int32')\n",
    "    labels[:len(entropy_in)] = 1\n",
    "    examples = np.concatenate([entropy_in, entropy_out])\n",
    "    auroc_ent = roc_auc_score(labels, examples)\n",
    "    return(auroc_ent)\n",
    "\n",
    "def auroc_variance(alphas_in, alphas_out, method='mean'):\n",
    "    \n",
    "    if method=='mean':\n",
    "        variance_in = alphas_variance(alphas_in).mean(1)\n",
    "        variance_out = alphas_variance(alphas_out).mean(1)\n",
    "    elif method=='max':\n",
    "        variance_in = alphas_variance(alphas_in).max(1)\n",
    "        variance_out = alphas_variance(alphas_out).max(1)\n",
    "    labels = np.zeros(len(variance_in)+len(variance_out), dtype='int32')\n",
    "    labels[:len(variance_in)] = 1\n",
    "    examples = np.concatenate([variance_in, variance_out])\n",
    "    auroc_ent = roc_auc_score(labels, examples)\n",
    "    return(auroc_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc entropy: CIFAR10 in, CIFAR100 out:  0.858544905\n",
      "auroc entropy: CIFAR10 in, SVHN out:  0.9317378879840197\n"
     ]
    }
   ],
   "source": [
    "print(\"auroc entropy: CIFAR10 in, CIFAR100 out: \", 1-auroc_entropy(alphas_in=CIFAR10_test_in_DIR_LPA, alphas_out=CIFAR10_test_out_CIFAR100_DIR_LPA))\n",
    "print(\"auroc entropy: CIFAR10 in, SVHN out: \", 1-auroc_entropy(alphas_in=CIFAR10_test_in_DIR_LPA, alphas_out=CIFAR10_test_out_SVHN_DIR_LPA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc variance: CIFAR10 in, CIFAR100 out:  0.863521435\n",
      "auroc variance: CIFAR10 in, SVHN out:  0.9317233577904118\n"
     ]
    }
   ],
   "source": [
    "print(\"auroc variance: CIFAR10 in, CIFAR100 out: \", 1-auroc_variance(alphas_in=CIFAR10_test_in_DIR_LPA, alphas_out=CIFAR10_test_out_CIFAR100_DIR_LPA, method='mean'))\n",
    "print(\"auroc variance: CIFAR10 in, SVHN out: \", 1-auroc_variance(alphas_in=CIFAR10_test_in_DIR_LPA, alphas_out=CIFAR10_test_out_SVHN_DIR_LPA, method='mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train on SVHN test on CIFAR10 and CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "SVHN_model = ResNet18(num_classes=10).to(device)\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all_SVHN():\n",
    "    SVHN_path = 'weights/SVHN_resnet18_SGD.pth'\n",
    "    lr = 0.1\n",
    "    epoch = 0\n",
    "    for e in [100, 25, 25]:\n",
    "        print(\"current learning rate: \", lr)\n",
    "        for _ in range(e):\n",
    "            optimizer = optim.SGD(SVHN_model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "            train(SVHN_model, epoch, optimizer, train_loader_SVHN, SVHN_path)\n",
    "            test(SVHN_model, epoch, test_loader_SVHN)\n",
    "            epoch += 1\n",
    "        lr /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current learning rate:  0.1\n",
      "\n",
      "Epoch: 0\n",
      "train loss:  507.79862785339355\n",
      "train accuracy:  0.18289028887523048\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  449.6289610862732\n",
      "test accuracy:  0.1997157344806392\n",
      "\n",
      "Epoch: 1\n",
      "train loss:  437.37904465198517\n",
      "train accuracy:  0.2229179471419791\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  400.31377387046814\n",
      "test accuracy:  0.32241087891825443\n",
      "\n",
      "Epoch: 2\n",
      "train loss:  275.33701664209366\n",
      "train accuracy:  0.5440611555009219\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  177.69543308019638\n",
      "test accuracy:  0.7128918254456054\n",
      "\n",
      "Epoch: 3\n",
      "train loss:  120.85261020064354\n",
      "train accuracy:  0.8134219422249539\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  85.54273121058941\n",
      "test accuracy:  0.8700445605408728\n",
      "\n",
      "Epoch: 4\n",
      "train loss:  70.2429259866476\n",
      "train accuracy:  0.8949754148740012\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  61.51713141798973\n",
      "test accuracy:  0.9048478795328826\n",
      "\n",
      "Epoch: 5\n",
      "train loss:  48.21308793127537\n",
      "train accuracy:  0.9315457897971727\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  48.90836404263973\n",
      "test accuracy:  0.9235940381069453\n",
      "\n",
      "Epoch: 6\n",
      "train loss:  35.67053624428809\n",
      "train accuracy:  0.9485248924400738\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  44.744964841753244\n",
      "test accuracy:  0.9310464044253227\n",
      "\n",
      "Epoch: 7\n",
      "train loss:  28.780669862404466\n",
      "train accuracy:  0.957821143208359\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  49.56370855867863\n",
      "test accuracy:  0.9240934234787953\n",
      "\n",
      "Epoch: 8\n",
      "train loss:  23.65544592961669\n",
      "train accuracy:  0.9643899815611555\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  50.29314821586013\n",
      "test accuracy:  0.933658574062692\n",
      "\n",
      "Epoch: 9\n",
      "train loss:  19.297518542036414\n",
      "train accuracy:  0.9721496619545175\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  44.042344365268946\n",
      "test accuracy:  0.9325061462814997\n",
      "\n",
      "Epoch: 10\n",
      "train loss:  16.89285532012582\n",
      "train accuracy:  0.9741087891825445\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  25.928795233368874\n",
      "test accuracy:  0.9597418561770129\n",
      "\n",
      "Epoch: 11\n",
      "train loss:  15.470815962180495\n",
      "train accuracy:  0.9761831591886908\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  27.084487738087773\n",
      "test accuracy:  0.9581284572833436\n",
      "\n",
      "Epoch: 12\n",
      "train loss:  14.886835562065244\n",
      "train accuracy:  0.9769130301167793\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  18.846704074181616\n",
      "test accuracy:  0.969460663798402\n",
      "\n",
      "Epoch: 13\n",
      "train loss:  13.03473200649023\n",
      "train accuracy:  0.9798325138291334\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  26.001703791320324\n",
      "test accuracy:  0.9584741856177013\n",
      "\n",
      "Epoch: 14\n",
      "train loss:  11.823019040748477\n",
      "train accuracy:  0.9813690842040566\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  31.394973708316684\n",
      "test accuracy:  0.9528272894898586\n",
      "\n",
      "Epoch: 15\n",
      "train loss:  10.480591619387269\n",
      "train accuracy:  0.9842501536570375\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  19.648732823319733\n",
      "test accuracy:  0.9685387215734481\n",
      "\n",
      "Epoch: 16\n",
      "train loss:  11.377556256949902\n",
      "train accuracy:  0.9819068838352797\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  22.74193008430302\n",
      "test accuracy:  0.9636985248924401\n",
      "\n",
      "Epoch: 17\n",
      "train loss:  12.15028834529221\n",
      "train accuracy:  0.9806007990165949\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  18.78094266075641\n",
      "test accuracy:  0.9698063921327597\n",
      "\n",
      "Epoch: 18\n",
      "train loss:  10.142344320192933\n",
      "train accuracy:  0.9849416103257529\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  28.445488780736923\n",
      "test accuracy:  0.9550553165334973\n",
      "\n",
      "Epoch: 19\n",
      "train loss:  9.518930239602923\n",
      "train accuracy:  0.9848647818070068\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  30.168405475094914\n",
      "test accuracy:  0.9520974185617701\n",
      "\n",
      "Epoch: 20\n",
      "train loss:  9.018665213137865\n",
      "train accuracy:  0.9863245236631838\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  18.800625298172235\n",
      "test accuracy:  0.9702673632452367\n",
      "\n",
      "Epoch: 21\n",
      "train loss:  9.938528396189213\n",
      "train accuracy:  0.9847879532882606\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  24.162275995127857\n",
      "test accuracy:  0.961240012292563\n",
      "\n",
      "Epoch: 22\n",
      "train loss:  10.8319735173136\n",
      "train accuracy:  0.9837507682851875\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  29.094486091285944\n",
      "test accuracy:  0.9537876459741856\n",
      "\n",
      "Epoch: 23\n",
      "train loss:  10.944019801914692\n",
      "train accuracy:  0.982521511985249\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  35.46630698442459\n",
      "test accuracy:  0.9451828518746158\n",
      "\n",
      "Epoch: 24\n",
      "train loss:  12.446450352668762\n",
      "train accuracy:  0.9809849416103258\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  25.35664828494191\n",
      "test accuracy:  0.9592424708051629\n",
      "\n",
      "Epoch: 25\n",
      "train loss:  9.062683664262295\n",
      "train accuracy:  0.9862476951444377\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  18.068965289276093\n",
      "test accuracy:  0.9698063921327597\n",
      "\n",
      "Epoch: 26\n",
      "train loss:  7.6749859396368265\n",
      "train accuracy:  0.9888982790411801\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  16.774725606665015\n",
      "test accuracy:  0.9728027043638598\n",
      "\n",
      "Epoch: 27\n",
      "train loss:  9.429164430126548\n",
      "train accuracy:  0.9857483097725875\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  13.34803797211498\n",
      "test accuracy:  0.9792178856791641\n",
      "\n",
      "Epoch: 28\n",
      "train loss:  8.574571170844138\n",
      "train accuracy:  0.9875921942224954\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  23.9155250787735\n",
      "test accuracy:  0.9614320835894284\n",
      "\n",
      "Epoch: 29\n",
      "train loss:  10.86925994232297\n",
      "train accuracy:  0.9834818684695759\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  12.623011785326526\n",
      "test accuracy:  0.9804087277197295\n",
      "\n",
      "Epoch: 30\n",
      "train loss:  7.840976981446147\n",
      "train accuracy:  0.9885909649661955\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  10.244140725582838\n",
      "test accuracy:  0.9834434542102028\n",
      "\n",
      "Epoch: 31\n",
      "train loss:  5.681706464849412\n",
      "train accuracy:  0.9922403196066379\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  9.750100796110928\n",
      "test accuracy:  0.9852489244007375\n",
      "\n",
      "Epoch: 32\n",
      "train loss:  8.354566363617778\n",
      "train accuracy:  0.9878995082974801\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  26.84653776139021\n",
      "test accuracy:  0.9575138291333744\n",
      "\n",
      "Epoch: 33\n",
      "train loss:  13.656647300347686\n",
      "train accuracy:  0.9777965580823602\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  44.215946685522795\n",
      "test accuracy:  0.9316226183159189\n",
      "\n",
      "Epoch: 34\n",
      "train loss:  8.558426152914762\n",
      "train accuracy:  0.9876306084818685\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  23.911344485357404\n",
      "test accuracy:  0.9622387830362631\n",
      "\n",
      "Epoch: 35\n",
      "train loss:  6.968549190089107\n",
      "train accuracy:  0.9897818070067609\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  23.333674791734666\n",
      "test accuracy:  0.9648125384142594\n",
      "\n",
      "Epoch: 36\n",
      "train loss:  9.307289170101285\n",
      "train accuracy:  0.9858635525507068\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  17.15140410186723\n",
      "test accuracy:  0.9726106330669945\n",
      "\n",
      "Epoch: 37\n",
      "train loss:  9.592839441262186\n",
      "train accuracy:  0.9857098955132145\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  11.504986909218132\n",
      "test accuracy:  0.9812538414259373\n",
      "\n",
      "Epoch: 38\n",
      "train loss:  8.335863041691482\n",
      "train accuracy:  0.9869391518131531\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  11.921464256942272\n",
      "test accuracy:  0.9807160417947142\n",
      "\n",
      "Epoch: 39\n",
      "train loss:  9.70247264392674\n",
      "train accuracy:  0.9855946527350953\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  10.078562834765762\n",
      "test accuracy:  0.9840964966195451\n",
      "\n",
      "Epoch: 40\n",
      "train loss:  8.043975263834\n",
      "train accuracy:  0.9873232944068838\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  43.87006660178304\n",
      "test accuracy:  0.9323140749846343\n",
      "\n",
      "Epoch: 41\n",
      "train loss:  9.662591714411974\n",
      "train accuracy:  0.9849031960663799\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  35.13204220868647\n",
      "test accuracy:  0.9474877074370006\n",
      "\n",
      "Epoch: 42\n",
      "train loss:  8.421089258044958\n",
      "train accuracy:  0.9872080516287646\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  12.075986402109265\n",
      "test accuracy:  0.9803318992009834\n",
      "\n",
      "Epoch: 43\n",
      "train loss:  7.368784263730049\n",
      "train accuracy:  0.9891671788567916\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  6.877345200045966\n",
      "test accuracy:  0.9898970497848801\n",
      "\n",
      "Epoch: 44\n",
      "train loss:  4.195253210142255\n",
      "train accuracy:  0.9943915181315304\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  13.520202498184517\n",
      "test accuracy:  0.9789489858635525\n",
      "\n",
      "Epoch: 45\n",
      "train loss:  7.094799663871527\n",
      "train accuracy:  0.9897818070067609\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  19.486976396292448\n",
      "test accuracy:  0.9696911493546404\n",
      "\n",
      "Epoch: 46\n",
      "train loss:  8.498406309634447\n",
      "train accuracy:  0.9875537799631223\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  18.519281562417746\n",
      "test accuracy:  0.9705362630608482\n",
      "\n",
      "Epoch: 47\n",
      "train loss:  11.571518940851092\n",
      "train accuracy:  0.9816379840196681\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  29.954905297607183\n",
      "test accuracy:  0.9528272894898586\n",
      "\n",
      "Epoch: 48\n",
      "train loss:  7.484072707593441\n",
      "train accuracy:  0.9890903503380455\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  10.51825590338558\n",
      "test accuracy:  0.9827904118008605\n",
      "\n",
      "Epoch: 49\n",
      "train loss:  7.2803454622626305\n",
      "train accuracy:  0.9892824216349109\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  36.24358595907688\n",
      "test accuracy:  0.943838352796558\n",
      "\n",
      "Epoch: 50\n",
      "train loss:  8.558190394192934\n",
      "train accuracy:  0.9877842655193608\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  30.757234128192067\n",
      "test accuracy:  0.9528657037492317\n",
      "\n",
      "Epoch: 51\n",
      "train loss:  11.227285568602383\n",
      "train accuracy:  0.9825983405039951\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  9.323636638000607\n",
      "test accuracy:  0.9856714812538414\n",
      "\n",
      "Epoch: 52\n",
      "train loss:  7.382606914266944\n",
      "train accuracy:  0.9886293792255685\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  13.824609175790101\n",
      "test accuracy:  0.979179471419791\n",
      "\n",
      "Epoch: 53\n",
      "train loss:  5.715011216700077\n",
      "train accuracy:  0.9923171481253842\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  10.778701779665425\n",
      "test accuracy:  0.9829824830977258\n",
      "\n",
      "Epoch: 54\n",
      "train loss:  4.488346464931965\n",
      "train accuracy:  0.9943146896127842\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  12.637602775357664\n",
      "test accuracy:  0.9805623847572219\n",
      "\n",
      "Epoch: 55\n",
      "train loss:  9.569643765687943\n",
      "train accuracy:  0.9848263675476336\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  29.493774130940437\n",
      "test accuracy:  0.9542102028272895\n",
      "\n",
      "Epoch: 56\n",
      "train loss:  13.029143268242478\n",
      "train accuracy:  0.9797940995697603\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  18.493202473036945\n",
      "test accuracy:  0.9718423478795328\n",
      "\n",
      "Epoch: 57\n",
      "train loss:  8.462234916165471\n",
      "train accuracy:  0.9878995082974801\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  9.89729364681989\n",
      "test accuracy:  0.9843653964351567\n",
      "\n",
      "Epoch: 58\n",
      "train loss:  7.5177846141159534\n",
      "train accuracy:  0.9885525507068224\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  10.829679312184453\n",
      "test accuracy:  0.9829056545789797\n",
      "\n",
      "Epoch: 59\n",
      "train loss:  5.617852182593197\n",
      "train accuracy:  0.9922019053472649\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  12.112697757780552\n",
      "test accuracy:  0.9819068838352797\n",
      "\n",
      "Epoch: 60\n",
      "train loss:  7.024771235883236\n",
      "train accuracy:  0.9895129071911494\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  34.65587465558201\n",
      "test accuracy:  0.9499078057775046\n",
      "\n",
      "Epoch: 61\n",
      "train loss:  9.854432839900255\n",
      "train accuracy:  0.9842885679164106\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  33.777737848460674\n",
      "test accuracy:  0.947180393362016\n",
      "\n",
      "Epoch: 62\n",
      "train loss:  6.243640344589949\n",
      "train accuracy:  0.9912415488629379\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  12.970525737851858\n",
      "test accuracy:  0.9792562999385371\n",
      "\n",
      "Epoch: 63\n",
      "train loss:  6.143762295134366\n",
      "train accuracy:  0.9910878918254457\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  16.31992524303496\n",
      "test accuracy:  0.9756837738168408\n",
      "\n",
      "Epoch: 64\n",
      "train loss:  8.34827957302332\n",
      "train accuracy:  0.9873617086662569\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  11.037436002865434\n",
      "test accuracy:  0.9833666256914567\n",
      "\n",
      "Epoch: 65\n",
      "train loss:  8.796568360179663\n",
      "train accuracy:  0.9861708666256914\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  11.52284206962213\n",
      "test accuracy:  0.9818300553165334\n",
      "\n",
      "Epoch: 66\n",
      "train loss:  9.51278467848897\n",
      "train accuracy:  0.9853257529194838\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  21.73899192083627\n",
      "test accuracy:  0.9663875230485556\n",
      "\n",
      "Epoch: 67\n",
      "train loss:  6.9593251049518585\n",
      "train accuracy:  0.9900891210817455\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  9.715466841123998\n",
      "test accuracy:  0.9846342962507683\n",
      "\n",
      "Epoch: 68\n",
      "train loss:  8.412770751863718\n",
      "train accuracy:  0.9875537799631223\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  9.109594114590436\n",
      "test accuracy:  0.9863245236631838\n",
      "\n",
      "Epoch: 69\n",
      "train loss:  6.679308954626322\n",
      "train accuracy:  0.9897818070067609\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  11.82507874444127\n",
      "test accuracy:  0.9819452980946527\n",
      "\n",
      "Epoch: 70\n",
      "train loss:  7.574068075045943\n",
      "train accuracy:  0.9886677934849416\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  22.258586831390858\n",
      "test accuracy:  0.9687307928703135\n",
      "\n",
      "Epoch: 71\n",
      "train loss:  5.991304091177881\n",
      "train accuracy:  0.991779348494161\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  10.585810450138524\n",
      "test accuracy:  0.9835586969883221\n",
      "\n",
      "Epoch: 72\n",
      "train loss:  9.205032207071781\n",
      "train accuracy:  0.9862092808850645\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  17.49693196360022\n",
      "test accuracy:  0.9734173325138291\n",
      "\n",
      "Epoch: 73\n",
      "train loss:  5.691847864538431\n",
      "train accuracy:  0.9921634910878918\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  20.76028776075691\n",
      "test accuracy:  0.9689228641671789\n",
      "\n",
      "Epoch: 74\n",
      "train loss:  7.632950500585139\n",
      "train accuracy:  0.988821450522434\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  13.988610858097672\n",
      "test accuracy:  0.977220344191764\n",
      "\n",
      "Epoch: 75\n",
      "train loss:  7.1390452440828085\n",
      "train accuracy:  0.9892824216349109\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  15.053425233345479\n",
      "test accuracy:  0.9769514443761524\n",
      "\n",
      "Epoch: 76\n",
      "train loss:  8.385584393516183\n",
      "train accuracy:  0.9874385371850031\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  24.309949128888547\n",
      "test accuracy:  0.9627381684081131\n",
      "\n",
      "Epoch: 77\n",
      "train loss:  7.71061448007822\n",
      "train accuracy:  0.9885525507068224\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  19.99911834485829\n",
      "test accuracy:  0.9678472649047326\n",
      "\n",
      "Epoch: 78\n",
      "train loss:  7.465426029637456\n",
      "train accuracy:  0.9886677934849416\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  16.194718866376206\n",
      "test accuracy:  0.9751075599262446\n",
      "\n",
      "Epoch: 79\n",
      "train loss:  7.841951010748744\n",
      "train accuracy:  0.9880915795943455\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  8.827630588784814\n",
      "test accuracy:  0.986478180700676\n",
      "\n",
      "Epoch: 80\n",
      "train loss:  5.332568310201168\n",
      "train accuracy:  0.9929317762753535\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  12.11134167201817\n",
      "test accuracy:  0.9812154271665642\n",
      "\n",
      "Epoch: 81\n",
      "train loss:  4.459091430529952\n",
      "train accuracy:  0.9938153042409342\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  16.510819100774825\n",
      "test accuracy:  0.9739935464044254\n",
      "\n",
      "Epoch: 82\n",
      "train loss:  10.56685140915215\n",
      "train accuracy:  0.9848647818070068\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  15.01865437370725\n",
      "test accuracy:  0.9764520590043024\n",
      "\n",
      "Epoch: 83\n",
      "train loss:  9.069511391222477\n",
      "train accuracy:  0.9865550092194223\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  34.34482722170651\n",
      "test accuracy:  0.947679778733866\n",
      "\n",
      "Epoch: 84\n",
      "train loss:  7.72682087123394\n",
      "train accuracy:  0.9887062077443147\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  13.28313011676073\n",
      "test accuracy:  0.9807544560540873\n",
      "\n",
      "Epoch: 85\n",
      "train loss:  8.752557208761573\n",
      "train accuracy:  0.986439766441303\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  15.199439235031605\n",
      "test accuracy:  0.9759526736324524\n",
      "\n",
      "Epoch: 86\n",
      "train loss:  8.02195387147367\n",
      "train accuracy:  0.9884757221880762\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  21.268071062862873\n",
      "test accuracy:  0.9698063921327597\n",
      "\n",
      "Epoch: 87\n",
      "train loss:  6.052495764568448\n",
      "train accuracy:  0.9913567916410572\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  14.763567780377343\n",
      "test accuracy:  0.9767593730792871\n",
      "\n",
      "Epoch: 88\n",
      "train loss:  4.9441800359636545\n",
      "train accuracy:  0.9933159188690842\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  6.741570959798992\n",
      "test accuracy:  0.9899738783036263\n",
      "\n",
      "Epoch: 89\n",
      "train loss:  6.774502608925104\n",
      "train accuracy:  0.9897818070067609\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  22.934409951791167\n",
      "test accuracy:  0.9658881376767056\n",
      "\n",
      "Epoch: 90\n",
      "train loss:  10.123280674219131\n",
      "train accuracy:  0.9847495390288875\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  30.374355018138885\n",
      "test accuracy:  0.9521742470805162\n",
      "\n",
      "Epoch: 91\n",
      "train loss:  7.369854387827218\n",
      "train accuracy:  0.9895513214505224\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  15.931423098314553\n",
      "test accuracy:  0.9754917025199754\n",
      "\n",
      "Epoch: 92\n",
      "train loss:  9.68344078026712\n",
      "train accuracy:  0.9855946527350953\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  13.065986917819828\n",
      "test accuracy:  0.9797940995697603\n",
      "\n",
      "Epoch: 93\n",
      "train loss:  6.745038039050996\n",
      "train accuracy:  0.9903580208973571\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  15.549351187422872\n",
      "test accuracy:  0.9755685310387215\n",
      "\n",
      "Epoch: 94\n",
      "train loss:  3.992655798792839\n",
      "train accuracy:  0.9949677320221266\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  4.825957166729495\n",
      "test accuracy:  0.9939689612784266\n",
      "\n",
      "Epoch: 95\n",
      "train loss:  6.8803591169416904\n",
      "train accuracy:  0.9902043638598648\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  55.39508444815874\n",
      "test accuracy:  0.9232098955132145\n",
      "\n",
      "Epoch: 96\n",
      "train loss:  8.765535457059741\n",
      "train accuracy:  0.9863629379225568\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  26.130548683926463\n",
      "test accuracy:  0.9597034419176398\n",
      "\n",
      "Epoch: 97\n",
      "train loss:  9.277285642921925\n",
      "train accuracy:  0.9860940381069453\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  16.85992672853172\n",
      "test accuracy:  0.9741087891825445\n",
      "\n",
      "Epoch: 98\n",
      "train loss:  6.142121194861829\n",
      "train accuracy:  0.9909342347879533\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  14.012433679774404\n",
      "test accuracy:  0.9782575291948371\n",
      "\n",
      "Epoch: 99\n",
      "train loss:  4.425650401972234\n",
      "train accuracy:  0.994161032575292\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  11.067034950479865\n",
      "test accuracy:  0.9831361401352182\n",
      "current learning rate:  0.01\n",
      "\n",
      "Epoch: 100\n",
      "train loss:  1.9038981839548796\n",
      "train accuracy:  0.9981561155500922\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.4769952595233917\n",
      "test accuracy:  0.9999615857406269\n",
      "\n",
      "Epoch: 101\n",
      "train loss:  0.39207988721318543\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.3643133534351364\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 102\n",
      "train loss:  0.31796109676361084\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.31954775750637054\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 103\n",
      "train loss:  0.28682590019889176\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.294506118982099\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 104\n",
      "train loss:  0.2700630675535649\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2793324626982212\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 105\n",
      "train loss:  0.2608020219486207\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.26988461741711944\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 106\n",
      "train loss:  0.25604142737574875\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2641359902918339\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 107\n",
      "train loss:  0.25424107536673546\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.26093255227897316\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 108\n",
      "train loss:  0.2545296710450202\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2595374621450901\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 109\n",
      "train loss:  0.2563159763813019\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.25948053726460785\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 110\n",
      "train loss:  0.25920475157909095\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2603482393315062\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 111\n",
      "train loss:  0.2629257228691131\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2619445224991068\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 112\n",
      "train loss:  0.26724869501776993\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.26405748596880585\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 113\n",
      "train loss:  0.27201496553607285\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2665709679713473\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 114\n",
      "train loss:  0.27709922567009926\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2693311348557472\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 115\n",
      "train loss:  0.2823849432170391\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.27224805823061615\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 116\n",
      "train loss:  0.2877812534570694\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2752292813966051\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 117\n",
      "train loss:  0.2932186797261238\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.27825778850819916\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 118\n",
      "train loss:  0.29862534371204674\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.28126818814780563\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 119\n",
      "train loss:  0.3039381727576256\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2841892814030871\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 120\n",
      "train loss:  0.30913398670963943\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2870147339999676\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 121\n",
      "train loss:  0.3141745366156101\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.28968559205532074\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 122\n",
      "train loss:  0.31902583432383835\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29218847304582596\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 123\n",
      "train loss:  0.3236631329637021\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29452983662486076\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 124\n",
      "train loss:  0.32806971413083375\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29667043313384056\n",
      "test accuracy:  1.0\n",
      "current learning rate:  0.001\n",
      "\n",
      "Epoch: 125\n",
      "train loss:  0.32716378942131996\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2925761428195983\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 126\n",
      "train loss:  0.32759640854783356\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29280245932750404\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 127\n",
      "train loss:  0.3280310370028019\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29303166759200394\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 128\n",
      "train loss:  0.3284661110956222\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2932585577946156\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 129\n",
      "train loss:  0.32889995723962784\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2934856452047825\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 130\n",
      "train loss:  0.3293335847556591\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.293713565915823\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 131\n",
      "train loss:  0.329765010625124\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29393774759955704\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 132\n",
      "train loss:  0.33019520342350006\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2941601190250367\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 133\n",
      "train loss:  0.3306232194881886\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2943810608703643\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 134\n",
      "train loss:  0.33104917663149536\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29460098478011787\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 135\n",
      "train loss:  0.3314720231574029\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2948172229807824\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 136\n",
      "train loss:  0.3318928580265492\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2950311414897442\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 137\n",
      "train loss:  0.33231119182892144\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29524319991469383\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 138\n",
      "train loss:  0.3327265754342079\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29545295727439225\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 139\n",
      "train loss:  0.33313916507177055\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29565955814905465\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 140\n",
      "train loss:  0.333549925358966\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2958648067433387\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 141\n",
      "train loss:  0.333957027643919\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2960686970036477\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 142\n",
      "train loss:  0.3343619790393859\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29627017048187554\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 143\n",
      "train loss:  0.334763552993536\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29646771657280624\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 144\n",
      "train loss:  0.33516272041015327\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29666370153427124\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 145\n",
      "train loss:  0.33555945265106857\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2968566541094333\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 146\n",
      "train loss:  0.33595355600118637\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2970490131992847\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 147\n",
      "train loss:  0.3363439403474331\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29723812523297966\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 148\n",
      "train loss:  0.33673230558633804\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2974250155966729\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 149\n",
      "train loss:  0.33711724844761193\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2976105746347457\n",
      "test accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "train_all_SVHN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2976105746347457\n",
      "test accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "##### if you already have a trained model ##############\n",
    "SVHN_PATH = 'weights/SVHN_resnet18_SGD.pth'\n",
    "SVHN_model = ResNet18().to(device)\n",
    "print(\"loading model from: {}\".format(SVHN_PATH))\n",
    "SVHN_model.load_state_dict(torch.load(SVHN_PATH))#, map_location=torch.device('cpu')))\n",
    "#test the model\n",
    "test(SVHN_model, 0, test_loader_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 512 inputs to linear layer with m: 10 classes\n",
      "Batch: 0/204\n",
      "Batch: 1/204\n",
      "Batch: 2/204\n",
      "Batch: 3/204\n",
      "Batch: 4/204\n",
      "Batch: 5/204\n",
      "Batch: 6/204\n",
      "Batch: 7/204\n",
      "Batch: 8/204\n",
      "Batch: 9/204\n",
      "Batch: 10/204\n",
      "Batch: 11/204\n",
      "Batch: 12/204\n",
      "Batch: 13/204\n",
      "Batch: 14/204\n",
      "Batch: 15/204\n",
      "Batch: 16/204\n",
      "Batch: 17/204\n",
      "Batch: 18/204\n",
      "Batch: 19/204\n",
      "Batch: 20/204\n",
      "Batch: 21/204\n",
      "Batch: 22/204\n",
      "Batch: 23/204\n",
      "Batch: 24/204\n",
      "Batch: 25/204\n",
      "Batch: 26/204\n",
      "Batch: 27/204\n",
      "Batch: 28/204\n",
      "Batch: 29/204\n",
      "Batch: 30/204\n",
      "Batch: 31/204\n",
      "Batch: 32/204\n",
      "Batch: 33/204\n",
      "Batch: 34/204\n",
      "Batch: 35/204\n",
      "Batch: 36/204\n",
      "Batch: 37/204\n",
      "Batch: 38/204\n",
      "Batch: 39/204\n",
      "Batch: 40/204\n",
      "Batch: 41/204\n",
      "Batch: 42/204\n",
      "Batch: 43/204\n",
      "Batch: 44/204\n",
      "Batch: 45/204\n",
      "Batch: 46/204\n",
      "Batch: 47/204\n",
      "Batch: 48/204\n",
      "Batch: 49/204\n",
      "Batch: 50/204\n",
      "Batch: 51/204\n",
      "Batch: 52/204\n",
      "Batch: 53/204\n",
      "Batch: 54/204\n",
      "Batch: 55/204\n",
      "Batch: 56/204\n",
      "Batch: 57/204\n",
      "Batch: 58/204\n",
      "Batch: 59/204\n",
      "Batch: 60/204\n",
      "Batch: 61/204\n",
      "Batch: 62/204\n",
      "Batch: 63/204\n",
      "Batch: 64/204\n",
      "Batch: 65/204\n",
      "Batch: 66/204\n",
      "Batch: 67/204\n",
      "Batch: 68/204\n",
      "Batch: 69/204\n",
      "Batch: 70/204\n",
      "Batch: 71/204\n",
      "Batch: 72/204\n",
      "Batch: 73/204\n",
      "Batch: 74/204\n",
      "Batch: 75/204\n",
      "Batch: 76/204\n",
      "Batch: 77/204\n",
      "Batch: 78/204\n",
      "Batch: 79/204\n",
      "Batch: 80/204\n",
      "Batch: 81/204\n",
      "Batch: 82/204\n",
      "Batch: 83/204\n",
      "Batch: 84/204\n",
      "Batch: 85/204\n",
      "Batch: 86/204\n",
      "Batch: 87/204\n",
      "Batch: 88/204\n",
      "Batch: 89/204\n",
      "Batch: 90/204\n",
      "Batch: 91/204\n",
      "Batch: 92/204\n",
      "Batch: 93/204\n",
      "Batch: 94/204\n",
      "Batch: 95/204\n",
      "Batch: 96/204\n",
      "Batch: 97/204\n",
      "Batch: 98/204\n",
      "Batch: 99/204\n",
      "Batch: 100/204\n",
      "Batch: 101/204\n",
      "Batch: 102/204\n",
      "Batch: 103/204\n",
      "Batch: 104/204\n",
      "Batch: 105/204\n",
      "Batch: 106/204\n",
      "Batch: 107/204\n",
      "Batch: 108/204\n",
      "Batch: 109/204\n",
      "Batch: 110/204\n",
      "Batch: 111/204\n",
      "Batch: 112/204\n",
      "Batch: 113/204\n",
      "Batch: 114/204\n",
      "Batch: 115/204\n",
      "Batch: 116/204\n",
      "Batch: 117/204\n",
      "Batch: 118/204\n",
      "Batch: 119/204\n",
      "Batch: 120/204\n",
      "Batch: 121/204\n",
      "Batch: 122/204\n",
      "Batch: 123/204\n",
      "Batch: 124/204\n",
      "Batch: 125/204\n",
      "Batch: 126/204\n",
      "Batch: 127/204\n",
      "Batch: 128/204\n",
      "Batch: 129/204\n",
      "Batch: 130/204\n",
      "Batch: 131/204\n",
      "Batch: 132/204\n",
      "Batch: 133/204\n",
      "Batch: 134/204\n",
      "Batch: 135/204\n",
      "Batch: 136/204\n",
      "Batch: 137/204\n",
      "Batch: 138/204\n",
      "Batch: 139/204\n",
      "Batch: 140/204\n",
      "Batch: 141/204\n",
      "Batch: 142/204\n",
      "Batch: 143/204\n",
      "Batch: 144/204\n",
      "Batch: 145/204\n",
      "Batch: 146/204\n",
      "Batch: 147/204\n",
      "Batch: 148/204\n",
      "Batch: 149/204\n",
      "Batch: 150/204\n",
      "Batch: 151/204\n",
      "Batch: 152/204\n",
      "Batch: 153/204\n",
      "Batch: 154/204\n",
      "Batch: 155/204\n",
      "Batch: 156/204\n",
      "Batch: 157/204\n",
      "Batch: 158/204\n",
      "Batch: 159/204\n",
      "Batch: 160/204\n",
      "Batch: 161/204\n",
      "Batch: 162/204\n",
      "Batch: 163/204\n",
      "Batch: 164/204\n",
      "Batch: 165/204\n",
      "Batch: 166/204\n",
      "Batch: 167/204\n",
      "Batch: 168/204\n",
      "Batch: 169/204\n",
      "Batch: 170/204\n",
      "Batch: 171/204\n",
      "Batch: 172/204\n",
      "Batch: 173/204\n",
      "Batch: 174/204\n",
      "Batch: 175/204\n",
      "Batch: 176/204\n",
      "Batch: 177/204\n",
      "Batch: 178/204\n",
      "Batch: 179/204\n",
      "Batch: 180/204\n",
      "Batch: 181/204\n",
      "Batch: 182/204\n",
      "Batch: 183/204\n",
      "Batch: 184/204\n",
      "Batch: 185/204\n",
      "Batch: 186/204\n",
      "Batch: 187/204\n",
      "Batch: 188/204\n",
      "Batch: 189/204\n",
      "Batch: 190/204\n",
      "Batch: 191/204\n",
      "Batch: 192/204\n",
      "Batch: 193/204\n",
      "Batch: 194/204\n",
      "Batch: 195/204\n",
      "Batch: 196/204\n",
      "Batch: 197/204\n",
      "Batch: 198/204\n",
      "Batch: 199/204\n",
      "Batch: 200/204\n",
      "Batch: 201/204\n",
      "Batch: 202/204\n",
      "Batch: 203/204\n",
      "204\n",
      "M_W_post size:  torch.Size([512, 10])\n",
      "M_b_post size:  torch.Size([10])\n",
      "C_W_post size:  torch.Size([10, 512])\n",
      "C_b_post size:  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "M_W_post_D_SVHN, M_b_post_D_SVHN, C_W_post_D_SVHN, C_b_post_D_SVHN = Diag_second_order(model=SVHN_model,\n",
    "                                                               train_loader=train_loader_SVHN,\n",
    "                                                               var0 = 10,\n",
    "                                                               device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVHN_test_in_MAP = predict_MAP(SVHN_model, test_loader_SVHN, cuda=True).cpu().numpy()\n",
    "SVHN_test_out_CIFAR10_MAP = predict_MAP(SVHN_model, testloader, cuda=True).cpu().numpy()\n",
    "SVHN_test_out_CIFAR100_MAP = predict_MAP(SVHN_model, CIFAR100_test_loader, cuda=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP = get_in_dist_values(SVHN_test_in_MAP, targets_SVHN)\n",
    "acc_out_CIFAR10_MAP, prob_correct_out_CIFAR10_MAP, ent_out_CIFAR10, MMC_out_CIFAR10_MAP, auroc_out_CIFAR10_MAP = get_out_dist_values(SVHN_test_in_MAP, SVHN_test_out_CIFAR10_MAP, targets_CIFAR10)\n",
    "acc_out_CIFAR100_MAP, prob_correct_out_CIFAR100_MAP, ent_out_CIFAR100_MAP, MMC_out_CIFAR100_MAP, auroc_out_CIFAR100_MAP = get_out_dist_values(SVHN_test_in_MAP, SVHN_test_out_CIFAR100_MAP, targets_CIFAR100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, MAP, SVHN] Accuracy: 1.000; average entropy: 0.012;     MMC: 0.999; Prob @ correct: 0.100\n",
      "[Out-MAP, KFAC, CIFAR10] Accuracy: 0.091; Average entropy: 1.237;    MMC: 0.595; AUROC: 0.997; Prob @ correct: 0.100\n",
      "[Out-MAP, KFAC, CIFAR100] Accuracy: 0.011; Average entropy: 1.205;    MMC: 0.606; AUROC: 0.996; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP, 'SVHN', 'MAP')\n",
    "print_out_dist_values(acc_out_CIFAR10_MAP, prob_correct_out_CIFAR10_MAP, ent_out_CIFAR10, MMC_out_CIFAR10_MAP, auroc_out_CIFAR10_MAP, 'CIFAR10', 'MAP')\n",
    "print_out_dist_values(acc_out_CIFAR100_MAP, prob_correct_out_CIFAR100_MAP, ent_out_CIFAR100_MAP, MMC_out_CIFAR100_MAP, auroc_out_CIFAR100_MAP, 'CIFAR100', 'MAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.000 with std 0.000\n",
      "MMC in: 0.999 with std 0.000\n",
      "MMC out CIFAR10: 0.616 with std 0.013\n",
      "MMC out CIFAR100: 0.621 with std 0.010\n",
      "AUROC out CIFAR10: 0.996 with std 0.000\n",
      "AUROC out CIFAR100: 0.996 with std 0.000\n"
     ]
    }
   ],
   "source": [
    "#MAP estimate\n",
    "#seeds are 123,124,125,126,127\n",
    "acc_in = [1, 1, 1, 1, 1]\n",
    "mmc_in = [0.999, 0.999, 0.998, 0.999, 0.999]\n",
    "mmc_out_CIFAR10 = [0.633, 0.622, 0.620, 0.609, 0.595]\n",
    "mmc_out_CIFAR100 = [0.632, 0.630, 0.624, 0.614, 0.606]\n",
    "\n",
    "auroc_out_CIFAR10 = [0.996, 0.996, 0.996, 0.997, 0.997]\n",
    "auroc_out_CIFAR100 = [0.996, 0.996, 0.996, 0.996, 0.996]\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR10), np.std(mmc_out_CIFAR10)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "\n",
    "print(\"AUROC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR10), np.std(auroc_out_CIFAR10)))\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diag sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used for sampling with 1000 samples: 17.128493070602417\n",
      "time used for sampling with 1000 samples: 6.649439334869385\n",
      "time used for sampling with 1000 samples: 6.62450098991394\n"
     ]
    }
   ],
   "source": [
    "SVHN_test_in_D = predict_diagonal_sampling(SVHN_model, test_loader_SVHN, M_W_post_D_SVHN, M_b_post_D_SVHN, C_W_post_D_SVHN, C_b_post_D_SVHN, n_samples=1000, cuda=True, timing=True).cpu().numpy()\n",
    "SVHN_test_out_CIFAR10_D = predict_diagonal_sampling(SVHN_model, testloader, M_W_post_D_SVHN, M_b_post_D_SVHN, C_W_post_D_SVHN, C_b_post_D_SVHN, n_samples=1000, cuda=True, timing=True).cpu().numpy()\n",
    "SVHN_test_out_CIFAR100_D = predict_diagonal_sampling(SVHN_model, CIFAR100_test_loader, M_W_post_D_SVHN, M_b_post_D_SVHN, C_W_post_D_SVHN, C_b_post_D_SVHN, n_samples=1000, cuda=True, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D = get_in_dist_values(SVHN_test_in_D, targets_SVHN)\n",
    "acc_out_CIFAR10_D, prob_correct_out_CIFAR10_D, ent_out_CIFAR10_D, MMC_out_CIFAR10_D, auroc_out_CIFAR10_D = get_out_dist_values(SVHN_test_in_D, SVHN_test_out_CIFAR10_D, targets_CIFAR10)\n",
    "acc_out_CIFAR100_D, prob_correct_out_CIFAR100_D, ent_out_CIFAR100_D, MMC_out_CIFAR100_D, auroc_out_CIFAR100_D = get_out_dist_values(SVHN_test_in_D, SVHN_test_out_CIFAR100_D, targets_CIFAR100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, Diag, SVHN] Accuracy: 1.000; average entropy: 0.095;     MMC: 0.986; Prob @ correct: 0.100\n",
      "[Out-Diag, KFAC, CIFAR10] Accuracy: 0.091; Average entropy: 1.456;    MMC: 0.519; AUROC: 0.996; Prob @ correct: 0.100\n",
      "[Out-Diag, KFAC, CIFAR100] Accuracy: 0.011; Average entropy: 1.427;    MMC: 0.530; AUROC: 0.995; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D, 'SVHN', 'Diag')\n",
    "print_out_dist_values(acc_out_CIFAR10_D, prob_correct_out_CIFAR10_D, ent_out_CIFAR10_D, MMC_out_CIFAR10_D, auroc_out_CIFAR10_D, 'CIFAR10', 'Diag')\n",
    "print_out_dist_values(acc_out_CIFAR100_D, prob_correct_out_CIFAR100_D, ent_out_CIFAR100_D, MMC_out_CIFAR100_D, auroc_out_CIFAR100_D, 'CIFAR100', 'Diag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Bridge time in: 17.067 with std 0.182\n",
      "Sampling Bridge time out CIFAR10: 6.608 with std 0.046\n",
      "Sampling Bridge time out CIFAR100: 6.607 with std 0.028\n",
      "accuracy: 1.000 with std 0.000\n",
      "MMC in: 0.986 with std 0.000\n",
      "MMC out CIFAR10: 0.537 with std 0.012\n",
      "MMC out CIFAR100: 0.543 with std 0.009\n",
      "AUROC out CIFAR10: 0.995 with std 0.000\n",
      "AUROC out CIFAR100: 0.994 with std 0.000\n"
     ]
    }
   ],
   "source": [
    "#Diag Sampling\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [17.116743326187134, 17.32284379005432, 16.99942111968994, 16.769160509109497,17.128493070602417]\n",
    "time_lpb_out_CIFAR10 = [6.582088470458984, 6.672346353530884,6.582506418228149, 6.551377058029175, 6.649439334869385]\n",
    "time_lpb_out_CIFAR100 = [6.610069751739502, 6.648055791854858, 6.576121807098389, 6.577383518218994, 6.62450098991394]\n",
    "\n",
    "acc_in = [1, 1, 1, 1, 1]\n",
    "mmc_in = [0.986, 0.986, 0.986, 0.986, 0.986]\n",
    "mmc_out_CIFAR10 = [0.554, 0.543, 0.540, 0.530, 0.519]\n",
    "mmc_out_CIFAR100 = [0.554, 0.550, 0.544, 0.535, 0.530]\n",
    "\n",
    "auroc_out_CIFAR10 = [0.995, 0.995, 0.995, 0.996, 0.996]\n",
    "auroc_out_CIFAR100 = [0.994, 0.994, 0.994, 0.995, 0.995]\n",
    "\n",
    "print(\"Sampling Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Sampling Bridge time out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR10), np.std(time_lpb_out_CIFAR10)))\n",
    "print(\"Sampling Bridge time out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR100), np.std(time_lpb_out_CIFAR100)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR10), np.std(mmc_out_CIFAR10)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "\n",
    "print(\"AUROC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR10), np.std(auroc_out_CIFAR10)))\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplace Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used for transform: 0.04123\n",
      "total time used for transform: 0.01716\n",
      "total time used for transform: 0.01610\n"
     ]
    }
   ],
   "source": [
    "SVHN_test_in_DIR_LPA = predict_DIR_LPA(SVHN_model, test_loader_SVHN, M_W_post_D_SVHN, M_b_post_D_SVHN, C_W_post_D_SVHN, C_b_post_D_SVHN, cuda=True, timing=True).cpu().numpy()\n",
    "SVHN_test_out_CIFAR10_DIR_LPA = predict_DIR_LPA(SVHN_model, testloader, M_W_post_D_SVHN, M_b_post_D_SVHN, C_W_post_D_SVHN, C_b_post_D_SVHN, cuda=True, timing=True).cpu().numpy()\n",
    "SVHN_test_out_CIFAR100_DIR_LPA = predict_DIR_LPA(SVHN_model, CIFAR100_test_loader, M_W_post_D_SVHN, M_b_post_D_SVHN, C_W_post_D_SVHN, C_b_post_D_SVHN, cuda=True, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize to get the MAP estimate (which is the mode) of the Dirichlet\n",
    "SVHN_test_in_DIR_LPAn = SVHN_test_in_DIR_LPA/SVHN_test_in_DIR_LPA.sum(1).reshape(-1,1)\n",
    "SVHN_test_out_CIFAR10_DIR_LPAn = SVHN_test_out_CIFAR10_DIR_LPA/SVHN_test_out_CIFAR10_DIR_LPA.sum(1).reshape(-1,1)\n",
    "SVHN_test_out_CIFAR100_DIR_LPAn = SVHN_test_out_CIFAR100_DIR_LPA/SVHN_test_out_CIFAR100_DIR_LPA.sum(1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_DIR_LPA, prob_correct_in_DIR_LPA, ent_in_DIR_LPA, MMC_in_DIR_LPA = get_in_dist_values(SVHN_test_in_DIR_LPAn, targets_SVHN)\n",
    "acc_out_CIFAR10_DIR_LPA, prob_correct_out_CIFAR10_DIR_LPA, ent_out_CIFAR10_DIR_LPA, MMC_out_CIFAR10_DIR_LPA, auroc_out_CIFAR10_DIR_LPA = get_out_dist_values(SVHN_test_in_DIR_LPAn, SVHN_test_out_CIFAR10_DIR_LPAn, targets_CIFAR10)\n",
    "acc_out_CIFAR100_DIR_LPA, prob_correct_out_CIFAR100_DIR_LPA, ent_out_CIFAR100_DIR_LPA, MMC_out_CIFAR100_DIR_LPA, auroc_out_CIFAR100_DIR_LPA = get_out_dist_values(SVHN_test_in_DIR_LPAn, SVHN_test_out_CIFAR100_DIR_LPAn, targets_CIFAR100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, DIR_LPA, SVHN] Accuracy: 1.000; average entropy: 0.062;     MMC: 0.991; Prob @ correct: 0.100\n",
      "[Out-DIR_LPA, KFAC, CIFAR10] Accuracy: 0.091; Average entropy: 1.909;    MMC: 0.365; AUROC: 0.997; Prob @ correct: 0.100\n",
      "[Out-DIR_LPA, KFAC, CIFAR100] Accuracy: 0.011; Average entropy: 1.876;    MMC: 0.379; AUROC: 0.996; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_DIR_LPA, prob_correct_in_DIR_LPA, ent_in_DIR_LPA, MMC_in_DIR_LPA, 'SVHN', 'DIR_LPA')\n",
    "print_out_dist_values(acc_out_CIFAR10_DIR_LPA, prob_correct_out_CIFAR10_DIR_LPA, ent_out_CIFAR10_DIR_LPA, MMC_out_CIFAR10_DIR_LPA, auroc_out_CIFAR10_DIR_LPA, 'CIFAR10', 'DIR_LPA')\n",
    "print_out_dist_values(acc_out_CIFAR100_DIR_LPA, prob_correct_out_CIFAR100_DIR_LPA, ent_out_CIFAR100_DIR_LPA, MMC_out_CIFAR100_DIR_LPA, auroc_out_CIFAR100_DIR_LPA, 'CIFAR100', 'DIR_LPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplace Bridge time in: 0.041 with std 0.000\n",
      "Laplace Bridge time out CIFAR10: 0.017 with std 0.000\n",
      "Laplace Bridge time out CIFAR100: 0.016 with std 0.000\n",
      "accuracy: 1.000 with std 0.000\n",
      "MMC in: 0.991 with std 0.000\n",
      "MMC out CIFAR10: 0.392 with std 0.016\n",
      "MMC out CIFAR100: 0.400 with std 0.013\n",
      "AUROC out CIFAR10: 0.996 with std 0.000\n",
      "AUROC out CIFAR100: 0.996 with std 0.000\n"
     ]
    }
   ],
   "source": [
    "#Laplace Bridge\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [0.04104,0.04193, 0.04068, 0.04087, 0.04123]\n",
    "time_lpb_out_CIFAR10 = [0.01681,0.01735, 0.01730, 0.01707, 0.01716]\n",
    "time_lpb_out_CIFAR100 = [0.01592, 0.01599, 0.01594, 0.01584, 0.01610]\n",
    "\n",
    "\n",
    "acc_in = [1, 1, 1, 1, 1]\n",
    "mmc_in = [0.992, 0.992, 0.991, 0.991, 0.991]\n",
    "mmc_out_CIFAR10 = [0.411, 0.401, 0.398, 0.386, 0.365]\n",
    "mmc_out_CIFAR100 = [0.413, 0.412, 0.405, 0.391, 0.379]\n",
    "\n",
    "auroc_out_CIFAR10 = [0.996, 0.996, 0.996, 0.997, 0.997]\n",
    "auroc_out_CIFAR100 = [0.995, 0.996, 0.995, 0.996, 0.996]\n",
    "\n",
    "\n",
    "print(\"Laplace Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Laplace Bridge time out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR10), np.std(time_lpb_out_CIFAR10)))\n",
    "print(\"Laplace Bridge time out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR100), np.std(time_lpb_out_CIFAR100)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR10), np.std(mmc_out_CIFAR10)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "\n",
    "print(\"AUROC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR10), np.std(auroc_out_CIFAR10)))\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train on CIFAR100 and test on CIFAR10, SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "CIFAR100_model = ResNet18(num_classes=100).to(device)\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all_CIFAR100():\n",
    "    CIFAR100_path = 'weights/CIFAR100_resnet18_SGD.pth'\n",
    "    lr = 0.1\n",
    "    epoch = 0\n",
    "    for e in [100, 50, 50]:\n",
    "        print(\"current learning rate: \", lr)\n",
    "        for _ in range(e):\n",
    "            optimizer = optim.SGD(CIFAR100_model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "            train(CIFAR100_model, epoch, optimizer, CIFAR100_train_loader, CIFAR100_path)\n",
    "            test(CIFAR100_model, epoch, CIFAR100_test_loader)\n",
    "            epoch += 1\n",
    "        lr /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current learning rate:  0.1\n",
      "\n",
      "Epoch: 0\n",
      "train loss:  1519.3433899879456\n",
      "train accuracy:  0.10318\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  273.86104464530945\n",
      "test accuracy:  0.1629\n",
      "\n",
      "Epoch: 1\n",
      "train loss:  1241.35178565979\n",
      "train accuracy:  0.21398\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  240.93409395217896\n",
      "test accuracy:  0.2384\n",
      "\n",
      "Epoch: 2\n",
      "train loss:  1060.6093380451202\n",
      "train accuracy:  0.30282\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  212.40526700019836\n",
      "test accuracy:  0.3127\n",
      "\n",
      "Epoch: 3\n",
      "train loss:  892.957280755043\n",
      "train accuracy:  0.39456\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  211.19521307945251\n",
      "test accuracy:  0.341\n",
      "\n",
      "Epoch: 4\n",
      "train loss:  748.8530287742615\n",
      "train accuracy:  0.47738\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  214.3763608932495\n",
      "test accuracy:  0.3502\n",
      "\n",
      "Epoch: 5\n",
      "train loss:  633.174714922905\n",
      "train accuracy:  0.54868\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  211.86059832572937\n",
      "test accuracy:  0.3707\n",
      "\n",
      "Epoch: 6\n",
      "train loss:  545.163779437542\n",
      "train accuracy:  0.6016\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  221.5753357410431\n",
      "test accuracy:  0.3563\n",
      "\n",
      "Epoch: 7\n",
      "train loss:  478.1413180232048\n",
      "train accuracy:  0.64312\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  213.63994240760803\n",
      "test accuracy:  0.3782\n",
      "\n",
      "Epoch: 8\n",
      "train loss:  407.1239330172539\n",
      "train accuracy:  0.6926\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  216.24189805984497\n",
      "test accuracy:  0.3886\n",
      "\n",
      "Epoch: 9\n",
      "train loss:  358.2215328216553\n",
      "train accuracy:  0.72244\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  244.29642271995544\n",
      "test accuracy:  0.3669\n",
      "\n",
      "Epoch: 10\n",
      "train loss:  311.38639134168625\n",
      "train accuracy:  0.75718\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  261.6777594089508\n",
      "test accuracy:  0.3515\n",
      "\n",
      "Epoch: 11\n",
      "train loss:  284.34690096974373\n",
      "train accuracy:  0.77886\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  232.39333724975586\n",
      "test accuracy:  0.3931\n",
      "\n",
      "Epoch: 12\n",
      "train loss:  254.79921942949295\n",
      "train accuracy:  0.79948\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  231.10125398635864\n",
      "test accuracy:  0.3967\n",
      "\n",
      "Epoch: 13\n",
      "train loss:  236.67460623383522\n",
      "train accuracy:  0.81316\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  242.54660725593567\n",
      "test accuracy:  0.3925\n",
      "\n",
      "Epoch: 14\n",
      "train loss:  220.8453966677189\n",
      "train accuracy:  0.8272\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  282.8220520019531\n",
      "test accuracy:  0.3692\n",
      "\n",
      "Epoch: 15\n",
      "train loss:  221.6640549302101\n",
      "train accuracy:  0.82668\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  233.42301893234253\n",
      "test accuracy:  0.4027\n",
      "\n",
      "Epoch: 16\n",
      "train loss:  204.5950165092945\n",
      "train accuracy:  0.84008\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  230.6710593700409\n",
      "test accuracy:  0.4088\n",
      "\n",
      "Epoch: 17\n",
      "train loss:  199.6768283843994\n",
      "train accuracy:  0.84522\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  266.7383394241333\n",
      "test accuracy:  0.3549\n",
      "\n",
      "Epoch: 18\n",
      "train loss:  190.5213344693184\n",
      "train accuracy:  0.8528\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  249.547128200531\n",
      "test accuracy:  0.3918\n",
      "\n",
      "Epoch: 19\n",
      "train loss:  193.2715134769678\n",
      "train accuracy:  0.84948\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  246.65673995018005\n",
      "test accuracy:  0.3942\n",
      "\n",
      "Epoch: 20\n",
      "train loss:  196.14058762788773\n",
      "train accuracy:  0.84568\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  254.47068548202515\n",
      "test accuracy:  0.3771\n",
      "\n",
      "Epoch: 21\n",
      "train loss:  185.20565137267113\n",
      "train accuracy:  0.85766\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  256.92818427085876\n",
      "test accuracy:  0.3698\n",
      "\n",
      "Epoch: 22\n",
      "train loss:  181.7274989783764\n",
      "train accuracy:  0.85804\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  249.47916054725647\n",
      "test accuracy:  0.369\n",
      "\n",
      "Epoch: 23\n",
      "train loss:  182.37285429239273\n",
      "train accuracy:  0.8594\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  231.24216079711914\n",
      "test accuracy:  0.4099\n",
      "\n",
      "Epoch: 24\n",
      "train loss:  181.68679490685463\n",
      "train accuracy:  0.86126\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  269.65346455574036\n",
      "test accuracy:  0.3828\n",
      "\n",
      "Epoch: 25\n",
      "train loss:  178.4563806951046\n",
      "train accuracy:  0.8614\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  243.533127784729\n",
      "test accuracy:  0.4124\n",
      "\n",
      "Epoch: 26\n",
      "train loss:  172.37080788612366\n",
      "train accuracy:  0.86722\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  236.13210725784302\n",
      "test accuracy:  0.4054\n",
      "\n",
      "Epoch: 27\n",
      "train loss:  175.36175560951233\n",
      "train accuracy:  0.86332\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  246.54867005348206\n",
      "test accuracy:  0.3992\n",
      "\n",
      "Epoch: 28\n",
      "train loss:  182.74293145537376\n",
      "train accuracy:  0.85858\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  245.21122288703918\n",
      "test accuracy:  0.4089\n",
      "\n",
      "Epoch: 29\n",
      "train loss:  166.35448110103607\n",
      "train accuracy:  0.87144\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  246.23614931106567\n",
      "test accuracy:  0.3877\n",
      "\n",
      "Epoch: 30\n",
      "train loss:  171.30809012055397\n",
      "train accuracy:  0.8677\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  241.02705371379852\n",
      "test accuracy:  0.4127\n",
      "\n",
      "Epoch: 31\n",
      "train loss:  173.75517907738686\n",
      "train accuracy:  0.86432\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  230.38679099082947\n",
      "test accuracy:  0.4155\n",
      "\n",
      "Epoch: 32\n",
      "train loss:  170.83442175388336\n",
      "train accuracy:  0.86878\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  242.98730969429016\n",
      "test accuracy:  0.4088\n",
      "\n",
      "Epoch: 33\n",
      "train loss:  166.47737134993076\n",
      "train accuracy:  0.87116\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  256.3429913520813\n",
      "test accuracy:  0.4024\n",
      "\n",
      "Epoch: 34\n",
      "train loss:  173.30683790147305\n",
      "train accuracy:  0.86654\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  271.04534792900085\n",
      "test accuracy:  0.3869\n",
      "\n",
      "Epoch: 35\n",
      "train loss:  171.74047753214836\n",
      "train accuracy:  0.86718\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  258.43635630607605\n",
      "test accuracy:  0.3874\n",
      "\n",
      "Epoch: 36\n",
      "train loss:  161.15541142225266\n",
      "train accuracy:  0.87676\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  246.76572346687317\n",
      "test accuracy:  0.4014\n",
      "\n",
      "Epoch: 37\n",
      "train loss:  165.58331057429314\n",
      "train accuracy:  0.87002\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  244.36190581321716\n",
      "test accuracy:  0.3939\n",
      "\n",
      "Epoch: 38\n",
      "train loss:  167.1105335354805\n",
      "train accuracy:  0.8715\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  286.0277330875397\n",
      "test accuracy:  0.3586\n",
      "\n",
      "Epoch: 39\n",
      "train loss:  168.5481248050928\n",
      "train accuracy:  0.87128\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  251.16184067726135\n",
      "test accuracy:  0.4113\n",
      "\n",
      "Epoch: 40\n",
      "train loss:  169.15667827427387\n",
      "train accuracy:  0.86966\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  253.32846450805664\n",
      "test accuracy:  0.3882\n",
      "\n",
      "Epoch: 41\n",
      "train loss:  163.7902190387249\n",
      "train accuracy:  0.87328\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  266.6159110069275\n",
      "test accuracy:  0.4055\n",
      "\n",
      "Epoch: 42\n",
      "train loss:  157.05823054909706\n",
      "train accuracy:  0.87876\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  235.02931237220764\n",
      "test accuracy:  0.419\n",
      "\n",
      "Epoch: 43\n",
      "train loss:  169.88404205441475\n",
      "train accuracy:  0.86982\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  259.58264541625977\n",
      "test accuracy:  0.4039\n",
      "\n",
      "Epoch: 44\n",
      "train loss:  161.23053766787052\n",
      "train accuracy:  0.8749\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  254.20191764831543\n",
      "test accuracy:  0.3964\n",
      "\n",
      "Epoch: 45\n",
      "train loss:  162.61936923861504\n",
      "train accuracy:  0.873\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  238.18411445617676\n",
      "test accuracy:  0.4068\n",
      "\n",
      "Epoch: 46\n",
      "train loss:  163.36741290986538\n",
      "train accuracy:  0.87482\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  244.00686621665955\n",
      "test accuracy:  0.4217\n",
      "\n",
      "Epoch: 47\n",
      "train loss:  159.80318777263165\n",
      "train accuracy:  0.87764\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  247.5364224910736\n",
      "test accuracy:  0.4255\n",
      "\n",
      "Epoch: 48\n",
      "train loss:  155.44421733915806\n",
      "train accuracy:  0.88054\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  253.38505816459656\n",
      "test accuracy:  0.4073\n",
      "\n",
      "Epoch: 49\n",
      "train loss:  167.0361543893814\n",
      "train accuracy:  0.87174\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  254.76819849014282\n",
      "test accuracy:  0.4002\n",
      "\n",
      "Epoch: 50\n",
      "train loss:  157.40994395315647\n",
      "train accuracy:  0.8787\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  305.4148938655853\n",
      "test accuracy:  0.3665\n",
      "\n",
      "Epoch: 51\n",
      "train loss:  158.4743780940771\n",
      "train accuracy:  0.87938\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  270.80628752708435\n",
      "test accuracy:  0.3933\n",
      "\n",
      "Epoch: 52\n",
      "train loss:  164.59687712788582\n",
      "train accuracy:  0.87376\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  245.9244203567505\n",
      "test accuracy:  0.4064\n",
      "\n",
      "Epoch: 53\n",
      "train loss:  154.1295166760683\n",
      "train accuracy:  0.8813\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  257.7778968811035\n",
      "test accuracy:  0.3912\n",
      "\n",
      "Epoch: 54\n",
      "train loss:  162.79114352166653\n",
      "train accuracy:  0.87502\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  266.5663924217224\n",
      "test accuracy:  0.3872\n",
      "\n",
      "Epoch: 55\n",
      "train loss:  158.47857534885406\n",
      "train accuracy:  0.87808\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  261.74596667289734\n",
      "test accuracy:  0.4016\n",
      "\n",
      "Epoch: 56\n",
      "train loss:  157.2150834351778\n",
      "train accuracy:  0.87792\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  237.32545852661133\n",
      "test accuracy:  0.4203\n",
      "\n",
      "Epoch: 57\n",
      "train loss:  161.18627746403217\n",
      "train accuracy:  0.87508\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  250.47545075416565\n",
      "test accuracy:  0.4083\n",
      "\n",
      "Epoch: 58\n",
      "train loss:  161.0221960991621\n",
      "train accuracy:  0.87472\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  238.39048552513123\n",
      "test accuracy:  0.421\n",
      "\n",
      "Epoch: 59\n",
      "train loss:  149.69170567393303\n",
      "train accuracy:  0.88328\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  227.89780449867249\n",
      "test accuracy:  0.4257\n",
      "\n",
      "Epoch: 60\n",
      "train loss:  160.34877417981625\n",
      "train accuracy:  0.87814\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  235.96204924583435\n",
      "test accuracy:  0.4213\n",
      "\n",
      "Epoch: 61\n",
      "train loss:  159.38594564795494\n",
      "train accuracy:  0.87814\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  257.56472611427307\n",
      "test accuracy:  0.4056\n",
      "\n",
      "Epoch: 62\n",
      "train loss:  156.84329643845558\n",
      "train accuracy:  0.87982\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  282.78553104400635\n",
      "test accuracy:  0.3791\n",
      "\n",
      "Epoch: 63\n",
      "train loss:  157.5366922467947\n",
      "train accuracy:  0.8785\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  245.2711923122406\n",
      "test accuracy:  0.392\n",
      "\n",
      "Epoch: 64\n",
      "train loss:  154.13976648449898\n",
      "train accuracy:  0.88184\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  218.7549307346344\n",
      "test accuracy:  0.4387\n",
      "\n",
      "Epoch: 65\n",
      "train loss:  152.59718725085258\n",
      "train accuracy:  0.8836\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  241.38401651382446\n",
      "test accuracy:  0.4253\n",
      "\n",
      "Epoch: 66\n",
      "train loss:  161.65693606436253\n",
      "train accuracy:  0.87508\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  230.5794563293457\n",
      "test accuracy:  0.4272\n",
      "\n",
      "Epoch: 67\n",
      "train loss:  153.92585296928883\n",
      "train accuracy:  0.88256\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  227.07068991661072\n",
      "test accuracy:  0.4374\n",
      "\n",
      "Epoch: 68\n",
      "train loss:  154.9257868230343\n",
      "train accuracy:  0.88122\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  242.48771786689758\n",
      "test accuracy:  0.424\n",
      "\n",
      "Epoch: 69\n",
      "train loss:  163.99315942823887\n",
      "train accuracy:  0.87364\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  238.33010244369507\n",
      "test accuracy:  0.4169\n",
      "\n",
      "Epoch: 70\n",
      "train loss:  154.56552846729755\n",
      "train accuracy:  0.88032\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  244.47140216827393\n",
      "test accuracy:  0.394\n",
      "\n",
      "Epoch: 71\n",
      "train loss:  157.53422716259956\n",
      "train accuracy:  0.87748\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  238.40867638587952\n",
      "test accuracy:  0.4372\n",
      "\n",
      "Epoch: 72\n",
      "train loss:  155.70230086147785\n",
      "train accuracy:  0.88146\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  226.52381336688995\n",
      "test accuracy:  0.4273\n",
      "\n",
      "Epoch: 73\n",
      "train loss:  154.59554363787174\n",
      "train accuracy:  0.8826\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  237.95810103416443\n",
      "test accuracy:  0.4381\n",
      "\n",
      "Epoch: 74\n",
      "train loss:  159.0987561494112\n",
      "train accuracy:  0.87686\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  227.70798563957214\n",
      "test accuracy:  0.4277\n",
      "\n",
      "Epoch: 75\n",
      "train loss:  158.2532939016819\n",
      "train accuracy:  0.87844\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  225.46672224998474\n",
      "test accuracy:  0.4291\n",
      "\n",
      "Epoch: 76\n",
      "train loss:  156.09766560792923\n",
      "train accuracy:  0.88044\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  252.4641990661621\n",
      "test accuracy:  0.4144\n",
      "\n",
      "Epoch: 77\n",
      "train loss:  159.20792663097382\n",
      "train accuracy:  0.87942\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  251.01205611228943\n",
      "test accuracy:  0.4065\n",
      "\n",
      "Epoch: 78\n",
      "train loss:  150.81628903746605\n",
      "train accuracy:  0.88334\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  233.07583498954773\n",
      "test accuracy:  0.4351\n",
      "\n",
      "Epoch: 79\n",
      "train loss:  159.4407375305891\n",
      "train accuracy:  0.87736\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  229.11241602897644\n",
      "test accuracy:  0.4326\n",
      "\n",
      "Epoch: 80\n",
      "train loss:  154.42508395016193\n",
      "train accuracy:  0.88266\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  245.52081322669983\n",
      "test accuracy:  0.4127\n",
      "\n",
      "Epoch: 81\n",
      "train loss:  154.0382798165083\n",
      "train accuracy:  0.8816\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  218.5450222492218\n",
      "test accuracy:  0.4339\n",
      "\n",
      "Epoch: 82\n",
      "train loss:  157.9856783747673\n",
      "train accuracy:  0.8792\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  235.17643761634827\n",
      "test accuracy:  0.4227\n",
      "\n",
      "Epoch: 83\n",
      "train loss:  152.3158988803625\n",
      "train accuracy:  0.88316\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  229.00595998764038\n",
      "test accuracy:  0.4315\n",
      "\n",
      "Epoch: 84\n",
      "train loss:  158.7613503932953\n",
      "train accuracy:  0.87666\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  250.91801381111145\n",
      "test accuracy:  0.3983\n",
      "\n",
      "Epoch: 85\n",
      "train loss:  159.54347988963127\n",
      "train accuracy:  0.87758\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  231.71449327468872\n",
      "test accuracy:  0.4219\n",
      "\n",
      "Epoch: 86\n",
      "train loss:  153.57408794760704\n",
      "train accuracy:  0.8805\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  230.60728931427002\n",
      "test accuracy:  0.4288\n",
      "\n",
      "Epoch: 87\n",
      "train loss:  154.5005936473608\n",
      "train accuracy:  0.8818\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  239.49962282180786\n",
      "test accuracy:  0.4274\n",
      "\n",
      "Epoch: 88\n",
      "train loss:  157.43191200494766\n",
      "train accuracy:  0.87976\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  240.2693133354187\n",
      "test accuracy:  0.4325\n",
      "\n",
      "Epoch: 89\n",
      "train loss:  159.19753643870354\n",
      "train accuracy:  0.87706\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  262.6392254829407\n",
      "test accuracy:  0.4022\n",
      "\n",
      "Epoch: 90\n",
      "train loss:  147.41928000748158\n",
      "train accuracy:  0.88682\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  261.6589574813843\n",
      "test accuracy:  0.3987\n",
      "\n",
      "Epoch: 91\n",
      "train loss:  158.80978944897652\n",
      "train accuracy:  0.87854\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  233.1523356437683\n",
      "test accuracy:  0.4406\n",
      "\n",
      "Epoch: 92\n",
      "train loss:  150.2796148210764\n",
      "train accuracy:  0.88538\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  219.25501799583435\n",
      "test accuracy:  0.4424\n",
      "\n",
      "Epoch: 93\n",
      "train loss:  153.72649917006493\n",
      "train accuracy:  0.8818\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  247.5474977493286\n",
      "test accuracy:  0.4174\n",
      "\n",
      "Epoch: 94\n",
      "train loss:  163.57816264033318\n",
      "train accuracy:  0.8728\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  241.83428597450256\n",
      "test accuracy:  0.4301\n",
      "\n",
      "Epoch: 95\n",
      "train loss:  156.5449643433094\n",
      "train accuracy:  0.87992\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  261.5189905166626\n",
      "test accuracy:  0.4029\n",
      "\n",
      "Epoch: 96\n",
      "train loss:  153.16668978333473\n",
      "train accuracy:  0.88142\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  231.61976385116577\n",
      "test accuracy:  0.4222\n",
      "\n",
      "Epoch: 97\n",
      "train loss:  153.76391077041626\n",
      "train accuracy:  0.88244\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  274.89586329460144\n",
      "test accuracy:  0.3922\n",
      "\n",
      "Epoch: 98\n",
      "train loss:  159.0780380219221\n",
      "train accuracy:  0.87934\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  290.2373812198639\n",
      "test accuracy:  0.3956\n",
      "\n",
      "Epoch: 99\n",
      "train loss:  154.08959494531155\n",
      "train accuracy:  0.88192\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  229.2637584209442\n",
      "test accuracy:  0.4389\n",
      "current learning rate:  0.01\n",
      "\n",
      "Epoch: 100\n",
      "train loss:  72.3873930759728\n",
      "train accuracy:  0.94672\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.2671661376953\n",
      "test accuracy:  0.5738\n",
      "\n",
      "Epoch: 101\n",
      "train loss:  10.145320985466242\n",
      "train accuracy:  0.99822\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.28275299072266\n",
      "test accuracy:  0.5784\n",
      "\n",
      "Epoch: 102\n",
      "train loss:  5.724619660526514\n",
      "train accuracy:  0.99954\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.5980041027069\n",
      "test accuracy:  0.5806\n",
      "\n",
      "Epoch: 103\n",
      "train loss:  4.648144256323576\n",
      "train accuracy:  0.99974\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  140.77542650699615\n",
      "test accuracy:  0.5811\n",
      "\n",
      "Epoch: 104\n",
      "train loss:  4.113895263522863\n",
      "train accuracy:  0.99986\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  139.93467950820923\n",
      "test accuracy:  0.5809\n",
      "\n",
      "Epoch: 105\n",
      "train loss:  3.8110728561878204\n",
      "train accuracy:  0.99992\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  139.08640611171722\n",
      "test accuracy:  0.5807\n",
      "\n",
      "Epoch: 106\n",
      "train loss:  3.635069537907839\n",
      "train accuracy:  0.99994\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  138.28375947475433\n",
      "test accuracy:  0.5812\n",
      "\n",
      "Epoch: 107\n",
      "train loss:  3.535899594426155\n",
      "train accuracy:  0.99994\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  137.54673075675964\n",
      "test accuracy:  0.5824\n",
      "\n",
      "Epoch: 108\n",
      "train loss:  3.4792345501482487\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  136.89119446277618\n",
      "test accuracy:  0.582\n",
      "\n",
      "Epoch: 109\n",
      "train loss:  3.447210308164358\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  136.30811214447021\n",
      "test accuracy:  0.5821\n",
      "\n",
      "Epoch: 110\n",
      "train loss:  3.4310074783861637\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  135.80951595306396\n",
      "test accuracy:  0.5824\n",
      "\n",
      "Epoch: 111\n",
      "train loss:  3.4240611903369427\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  135.39003264904022\n",
      "test accuracy:  0.5831\n",
      "\n",
      "Epoch: 112\n",
      "train loss:  3.422402746975422\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  135.04446029663086\n",
      "test accuracy:  0.5822\n",
      "\n",
      "Epoch: 113\n",
      "train loss:  3.4232940673828125\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  134.77638137340546\n",
      "test accuracy:  0.5824\n",
      "\n",
      "Epoch: 114\n",
      "train loss:  3.4244879819452763\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  134.58136761188507\n",
      "test accuracy:  0.583\n",
      "\n",
      "Epoch: 115\n",
      "train loss:  3.4247677959501743\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  134.45647394657135\n",
      "test accuracy:  0.5826\n",
      "\n",
      "Epoch: 116\n",
      "train loss:  3.4234757870435715\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  134.39830374717712\n",
      "test accuracy:  0.5824\n",
      "\n",
      "Epoch: 117\n",
      "train loss:  3.420379564166069\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  134.402073264122\n",
      "test accuracy:  0.5829\n",
      "\n",
      "Epoch: 118\n",
      "train loss:  3.4151865169405937\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  134.45869183540344\n",
      "test accuracy:  0.5841\n",
      "\n",
      "Epoch: 119\n",
      "train loss:  3.4077158235013485\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  134.57272863388062\n",
      "test accuracy:  0.584\n",
      "\n",
      "Epoch: 120\n",
      "train loss:  3.398590635508299\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  134.73163723945618\n",
      "test accuracy:  0.5842\n",
      "\n",
      "Epoch: 121\n",
      "train loss:  3.3875852562487125\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  134.94232642650604\n",
      "test accuracy:  0.5842\n",
      "\n",
      "Epoch: 122\n",
      "train loss:  3.3752734065055847\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  135.19232547283173\n",
      "test accuracy:  0.5838\n",
      "\n",
      "Epoch: 123\n",
      "train loss:  3.362207032740116\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  135.46892893314362\n",
      "test accuracy:  0.5848\n",
      "\n",
      "Epoch: 124\n",
      "train loss:  3.348635047674179\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  135.77312707901\n",
      "test accuracy:  0.5854\n",
      "\n",
      "Epoch: 125\n",
      "train loss:  3.3353028409183025\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  136.11017632484436\n",
      "test accuracy:  0.5852\n",
      "\n",
      "Epoch: 126\n",
      "train loss:  3.321971792727709\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  136.47042560577393\n",
      "test accuracy:  0.5861\n",
      "\n",
      "Epoch: 127\n",
      "train loss:  3.30875289067626\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  136.83422648906708\n",
      "test accuracy:  0.5853\n",
      "\n",
      "Epoch: 128\n",
      "train loss:  3.296284258365631\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  137.2125767469406\n",
      "test accuracy:  0.585\n",
      "\n",
      "Epoch: 129\n",
      "train loss:  3.284418448805809\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  137.5980008840561\n",
      "test accuracy:  0.5851\n",
      "\n",
      "Epoch: 130\n",
      "train loss:  3.2735808938741684\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  137.98120987415314\n",
      "test accuracy:  0.5853\n",
      "\n",
      "Epoch: 131\n",
      "train loss:  3.2635382264852524\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  138.3714964389801\n",
      "test accuracy:  0.5858\n",
      "\n",
      "Epoch: 132\n",
      "train loss:  3.254338439553976\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  138.753915309906\n",
      "test accuracy:  0.5859\n",
      "\n",
      "Epoch: 133\n",
      "train loss:  3.2461994029581547\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  139.1311365365982\n",
      "test accuracy:  0.5861\n",
      "\n",
      "Epoch: 134\n",
      "train loss:  3.2385522685945034\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  139.4929642677307\n",
      "test accuracy:  0.5858\n",
      "\n",
      "Epoch: 135\n",
      "train loss:  3.2581643983721733\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  139.8741295337677\n",
      "test accuracy:  0.5861\n",
      "\n",
      "Epoch: 136\n",
      "train loss:  3.3430472537875175\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  140.14191567897797\n",
      "test accuracy:  0.5852\n",
      "\n",
      "Epoch: 137\n",
      "train loss:  3.2924509085714817\n",
      "train accuracy:  0.99996\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  140.4350471496582\n",
      "test accuracy:  0.5856\n",
      "\n",
      "Epoch: 138\n",
      "train loss:  3.2153575383126736\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  140.8120001554489\n",
      "test accuracy:  0.5863\n",
      "\n",
      "Epoch: 139\n",
      "train loss:  3.2026566192507744\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.13450276851654\n",
      "test accuracy:  0.5867\n",
      "\n",
      "Epoch: 140\n",
      "train loss:  3.1939489766955376\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.44437289237976\n",
      "test accuracy:  0.5863\n",
      "\n",
      "Epoch: 141\n",
      "train loss:  3.185529489070177\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.7320272922516\n",
      "test accuracy:  0.5867\n",
      "\n",
      "Epoch: 142\n",
      "train loss:  3.176817398518324\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.0136936903\n",
      "test accuracy:  0.5873\n",
      "\n",
      "Epoch: 143\n",
      "train loss:  3.1676474064588547\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.28322565555573\n",
      "test accuracy:  0.5873\n",
      "\n",
      "Epoch: 144\n",
      "train loss:  3.157404586672783\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.5437136888504\n",
      "test accuracy:  0.5873\n",
      "\n",
      "Epoch: 145\n",
      "train loss:  3.1459410153329372\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.7972869873047\n",
      "test accuracy:  0.588\n",
      "\n",
      "Epoch: 146\n",
      "train loss:  3.133609563112259\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.0395438671112\n",
      "test accuracy:  0.5879\n",
      "\n",
      "Epoch: 147\n",
      "train loss:  3.120854552835226\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.29242360591888\n",
      "test accuracy:  0.5882\n",
      "\n",
      "Epoch: 148\n",
      "train loss:  3.107387512922287\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.5323907136917\n",
      "test accuracy:  0.5884\n",
      "\n",
      "Epoch: 149\n",
      "train loss:  3.0932597219944\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.77819430828094\n",
      "test accuracy:  0.5884\n",
      "current learning rate:  0.001\n",
      "\n",
      "Epoch: 150\n",
      "train loss:  3.0022614635527134\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.83606708049774\n",
      "test accuracy:  0.5875\n",
      "\n",
      "Epoch: 151\n",
      "train loss:  2.989316903054714\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.85145843029022\n",
      "test accuracy:  0.588\n",
      "\n",
      "Epoch: 152\n",
      "train loss:  2.9866022542119026\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.88223695755005\n",
      "test accuracy:  0.5882\n",
      "\n",
      "Epoch: 153\n",
      "train loss:  2.9858764819800854\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.91616642475128\n",
      "test accuracy:  0.5883\n",
      "\n",
      "Epoch: 154\n",
      "train loss:  2.985791526734829\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.95086812973022\n",
      "test accuracy:  0.5884\n",
      "\n",
      "Epoch: 155\n",
      "train loss:  2.985960930585861\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.98522531986237\n",
      "test accuracy:  0.5887\n",
      "\n",
      "Epoch: 156\n",
      "train loss:  2.986261110752821\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.0181155204773\n",
      "test accuracy:  0.5885\n",
      "\n",
      "Epoch: 157\n",
      "train loss:  2.986629355698824\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.0502667427063\n",
      "test accuracy:  0.5884\n",
      "\n",
      "Epoch: 158\n",
      "train loss:  2.9870186299085617\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.08086037635803\n",
      "test accuracy:  0.5884\n",
      "\n",
      "Epoch: 159\n",
      "train loss:  2.9874098040163517\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.11063182353973\n",
      "test accuracy:  0.5883\n",
      "\n",
      "Epoch: 160\n",
      "train loss:  2.9877752140164375\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.14032411575317\n",
      "test accuracy:  0.5882\n",
      "\n",
      "Epoch: 161\n",
      "train loss:  2.9881173446774483\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.16837358474731\n",
      "test accuracy:  0.5882\n",
      "\n",
      "Epoch: 162\n",
      "train loss:  2.9884160943329334\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.19642806053162\n",
      "test accuracy:  0.5883\n",
      "\n",
      "Epoch: 163\n",
      "train loss:  2.988673023879528\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.2239283323288\n",
      "test accuracy:  0.5884\n",
      "\n",
      "Epoch: 164\n",
      "train loss:  2.9889000803232193\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.251185297966\n",
      "test accuracy:  0.5884\n",
      "\n",
      "Epoch: 165\n",
      "train loss:  2.98909130692482\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.27860617637634\n",
      "test accuracy:  0.5884\n",
      "\n",
      "Epoch: 166\n",
      "train loss:  2.989232014864683\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.30537176132202\n",
      "test accuracy:  0.5885\n",
      "\n",
      "Epoch: 167\n",
      "train loss:  2.9893325679004192\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.3318237066269\n",
      "test accuracy:  0.5885\n",
      "\n",
      "Epoch: 168\n",
      "train loss:  2.9893948771059513\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.35910654067993\n",
      "test accuracy:  0.5887\n",
      "\n",
      "Epoch: 169\n",
      "train loss:  2.9894087985157967\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.38603329658508\n",
      "test accuracy:  0.5886\n",
      "\n",
      "Epoch: 170\n",
      "train loss:  2.9893815144896507\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.4128270149231\n",
      "test accuracy:  0.5885\n",
      "\n",
      "Epoch: 171\n",
      "train loss:  2.9893214106559753\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.44000160694122\n",
      "test accuracy:  0.5883\n",
      "\n",
      "Epoch: 172\n",
      "train loss:  2.9892162419855595\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.46657192707062\n",
      "test accuracy:  0.5883\n",
      "\n",
      "Epoch: 173\n",
      "train loss:  2.989067278802395\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.49301743507385\n",
      "test accuracy:  0.5881\n",
      "\n",
      "Epoch: 174\n",
      "train loss:  2.988870296627283\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.5194629430771\n",
      "test accuracy:  0.588\n",
      "\n",
      "Epoch: 175\n",
      "train loss:  2.9886185191571712\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.54559338092804\n",
      "test accuracy:  0.588\n",
      "\n",
      "Epoch: 176\n",
      "train loss:  2.9883139207959175\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.57225286960602\n",
      "test accuracy:  0.5882\n",
      "\n",
      "Epoch: 177\n",
      "train loss:  2.987971056252718\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.59864211082458\n",
      "test accuracy:  0.5882\n",
      "\n",
      "Epoch: 178\n",
      "train loss:  2.987594209611416\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.62515425682068\n",
      "test accuracy:  0.5881\n",
      "\n",
      "Epoch: 179\n",
      "train loss:  2.987165194004774\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.6518154144287\n",
      "test accuracy:  0.588\n",
      "\n",
      "Epoch: 180\n",
      "train loss:  2.986690189689398\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.67843616008759\n",
      "test accuracy:  0.5877\n",
      "\n",
      "Epoch: 181\n",
      "train loss:  2.9861889854073524\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.7048728466034\n",
      "test accuracy:  0.5877\n",
      "\n",
      "Epoch: 182\n",
      "train loss:  2.985644292086363\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.73179960250854\n",
      "test accuracy:  0.5876\n",
      "\n",
      "Epoch: 183\n",
      "train loss:  2.9850540794432163\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.75833404064178\n",
      "test accuracy:  0.5875\n",
      "\n",
      "Epoch: 184\n",
      "train loss:  2.9844236969947815\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.7850240468979\n",
      "test accuracy:  0.5875\n",
      "\n",
      "Epoch: 185\n",
      "train loss:  2.9837600141763687\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.81081652641296\n",
      "test accuracy:  0.5872\n",
      "\n",
      "Epoch: 186\n",
      "train loss:  2.9830606393516064\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.83694696426392\n",
      "test accuracy:  0.5868\n",
      "\n",
      "Epoch: 187\n",
      "train loss:  2.982325002551079\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.86266028881073\n",
      "test accuracy:  0.5869\n",
      "\n",
      "Epoch: 188\n",
      "train loss:  2.981546249240637\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.88834500312805\n",
      "test accuracy:  0.5872\n",
      "\n",
      "Epoch: 189\n",
      "train loss:  2.980734072625637\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.9141345024109\n",
      "test accuracy:  0.5872\n",
      "\n",
      "Epoch: 190\n",
      "train loss:  2.979885444045067\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.94006872177124\n",
      "test accuracy:  0.5871\n",
      "\n",
      "Epoch: 191\n",
      "train loss:  2.9790170677006245\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.9660506248474\n",
      "test accuracy:  0.5872\n",
      "\n",
      "Epoch: 192\n",
      "train loss:  2.9781120344996452\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  144.991357088089\n",
      "test accuracy:  0.587\n",
      "\n",
      "Epoch: 193\n",
      "train loss:  2.97718084231019\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  145.01775908470154\n",
      "test accuracy:  0.587\n",
      "\n",
      "Epoch: 194\n",
      "train loss:  2.976221974939108\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  145.0438950061798\n",
      "test accuracy:  0.5869\n",
      "\n",
      "Epoch: 195\n",
      "train loss:  2.975238174200058\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  145.06918394565582\n",
      "test accuracy:  0.5872\n",
      "\n",
      "Epoch: 196\n",
      "train loss:  2.9742268472909927\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  145.09473276138306\n",
      "test accuracy:  0.5875\n",
      "\n",
      "Epoch: 197\n",
      "train loss:  2.973177570849657\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  145.12020027637482\n",
      "test accuracy:  0.5876\n",
      "\n",
      "Epoch: 198\n",
      "train loss:  2.9721126966178417\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  145.1458500623703\n",
      "test accuracy:  0.5876\n",
      "\n",
      "Epoch: 199\n",
      "train loss:  2.971014093607664\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  145.17129373550415\n",
      "test accuracy:  0.5876\n"
     ]
    }
   ],
   "source": [
    "train_all_CIFAR100()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  145.17129373550415\n",
      "test accuracy:  0.5876\n"
     ]
    }
   ],
   "source": [
    "##### if you already have a trained model ##############\n",
    "CIFAR100_PATH = 'weights/CIFAR100_resnet18_SGD.pth'\n",
    "CIFAR100_model = ResNet18(num_classes=100).to(device)\n",
    "print(\"loading model from: {}\".format(CIFAR100_PATH))\n",
    "CIFAR100_model.load_state_dict(torch.load(CIFAR100_PATH))#, map_location=torch.device('cpu')))\n",
    "#test the model\n",
    "test(CIFAR100_model, 0, CIFAR100_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 512 inputs to linear layer with m: 100 classes\n",
      "Batch: 0/391\n",
      "Batch: 1/391\n",
      "Batch: 2/391\n",
      "Batch: 3/391\n",
      "Batch: 4/391\n",
      "Batch: 5/391\n",
      "Batch: 6/391\n",
      "Batch: 7/391\n",
      "Batch: 8/391\n",
      "Batch: 9/391\n",
      "Batch: 10/391\n",
      "Batch: 11/391\n",
      "Batch: 12/391\n",
      "Batch: 13/391\n",
      "Batch: 14/391\n",
      "Batch: 15/391\n",
      "Batch: 16/391\n",
      "Batch: 17/391\n",
      "Batch: 18/391\n",
      "Batch: 19/391\n",
      "Batch: 20/391\n",
      "Batch: 21/391\n",
      "Batch: 22/391\n",
      "Batch: 23/391\n",
      "Batch: 24/391\n",
      "Batch: 25/391\n",
      "Batch: 26/391\n",
      "Batch: 27/391\n",
      "Batch: 28/391\n",
      "Batch: 29/391\n",
      "Batch: 30/391\n",
      "Batch: 31/391\n",
      "Batch: 32/391\n",
      "Batch: 33/391\n",
      "Batch: 34/391\n",
      "Batch: 35/391\n",
      "Batch: 36/391\n",
      "Batch: 37/391\n",
      "Batch: 38/391\n",
      "Batch: 39/391\n",
      "Batch: 40/391\n",
      "Batch: 41/391\n",
      "Batch: 42/391\n",
      "Batch: 43/391\n",
      "Batch: 44/391\n",
      "Batch: 45/391\n",
      "Batch: 46/391\n",
      "Batch: 47/391\n",
      "Batch: 48/391\n",
      "Batch: 49/391\n",
      "Batch: 50/391\n",
      "Batch: 51/391\n",
      "Batch: 52/391\n",
      "Batch: 53/391\n",
      "Batch: 54/391\n",
      "Batch: 55/391\n",
      "Batch: 56/391\n",
      "Batch: 57/391\n",
      "Batch: 58/391\n",
      "Batch: 59/391\n",
      "Batch: 60/391\n",
      "Batch: 61/391\n",
      "Batch: 62/391\n",
      "Batch: 63/391\n",
      "Batch: 64/391\n",
      "Batch: 65/391\n",
      "Batch: 66/391\n",
      "Batch: 67/391\n",
      "Batch: 68/391\n",
      "Batch: 69/391\n",
      "Batch: 70/391\n",
      "Batch: 71/391\n",
      "Batch: 72/391\n",
      "Batch: 73/391\n",
      "Batch: 74/391\n",
      "Batch: 75/391\n",
      "Batch: 76/391\n",
      "Batch: 77/391\n",
      "Batch: 78/391\n",
      "Batch: 79/391\n",
      "Batch: 80/391\n",
      "Batch: 81/391\n",
      "Batch: 82/391\n",
      "Batch: 83/391\n",
      "Batch: 84/391\n",
      "Batch: 85/391\n",
      "Batch: 86/391\n",
      "Batch: 87/391\n",
      "Batch: 88/391\n",
      "Batch: 89/391\n",
      "Batch: 90/391\n",
      "Batch: 91/391\n",
      "Batch: 92/391\n",
      "Batch: 93/391\n",
      "Batch: 94/391\n",
      "Batch: 95/391\n",
      "Batch: 96/391\n",
      "Batch: 97/391\n",
      "Batch: 98/391\n",
      "Batch: 99/391\n",
      "Batch: 100/391\n",
      "Batch: 101/391\n",
      "Batch: 102/391\n",
      "Batch: 103/391\n",
      "Batch: 104/391\n",
      "Batch: 105/391\n",
      "Batch: 106/391\n",
      "Batch: 107/391\n",
      "Batch: 108/391\n",
      "Batch: 109/391\n",
      "Batch: 110/391\n",
      "Batch: 111/391\n",
      "Batch: 112/391\n",
      "Batch: 113/391\n",
      "Batch: 114/391\n",
      "Batch: 115/391\n",
      "Batch: 116/391\n",
      "Batch: 117/391\n",
      "Batch: 118/391\n",
      "Batch: 119/391\n",
      "Batch: 120/391\n",
      "Batch: 121/391\n",
      "Batch: 122/391\n",
      "Batch: 123/391\n",
      "Batch: 124/391\n",
      "Batch: 125/391\n",
      "Batch: 126/391\n",
      "Batch: 127/391\n",
      "Batch: 128/391\n",
      "Batch: 129/391\n",
      "Batch: 130/391\n",
      "Batch: 131/391\n",
      "Batch: 132/391\n",
      "Batch: 133/391\n",
      "Batch: 134/391\n",
      "Batch: 135/391\n",
      "Batch: 136/391\n",
      "Batch: 137/391\n",
      "Batch: 138/391\n",
      "Batch: 139/391\n",
      "Batch: 140/391\n",
      "Batch: 141/391\n",
      "Batch: 142/391\n",
      "Batch: 143/391\n",
      "Batch: 144/391\n",
      "Batch: 145/391\n",
      "Batch: 146/391\n",
      "Batch: 147/391\n",
      "Batch: 148/391\n",
      "Batch: 149/391\n",
      "Batch: 150/391\n",
      "Batch: 151/391\n",
      "Batch: 152/391\n",
      "Batch: 153/391\n",
      "Batch: 154/391\n",
      "Batch: 155/391\n",
      "Batch: 156/391\n",
      "Batch: 157/391\n",
      "Batch: 158/391\n",
      "Batch: 159/391\n",
      "Batch: 160/391\n",
      "Batch: 161/391\n",
      "Batch: 162/391\n",
      "Batch: 163/391\n",
      "Batch: 164/391\n",
      "Batch: 165/391\n",
      "Batch: 166/391\n",
      "Batch: 167/391\n",
      "Batch: 168/391\n",
      "Batch: 169/391\n",
      "Batch: 170/391\n",
      "Batch: 171/391\n",
      "Batch: 172/391\n",
      "Batch: 173/391\n",
      "Batch: 174/391\n",
      "Batch: 175/391\n",
      "Batch: 176/391\n",
      "Batch: 177/391\n",
      "Batch: 178/391\n",
      "Batch: 179/391\n",
      "Batch: 180/391\n",
      "Batch: 181/391\n",
      "Batch: 182/391\n",
      "Batch: 183/391\n",
      "Batch: 184/391\n",
      "Batch: 185/391\n",
      "Batch: 186/391\n",
      "Batch: 187/391\n",
      "Batch: 188/391\n",
      "Batch: 189/391\n",
      "Batch: 190/391\n",
      "Batch: 191/391\n",
      "Batch: 192/391\n",
      "Batch: 193/391\n",
      "Batch: 194/391\n",
      "Batch: 195/391\n",
      "Batch: 196/391\n",
      "Batch: 197/391\n",
      "Batch: 198/391\n",
      "Batch: 199/391\n",
      "Batch: 200/391\n",
      "Batch: 201/391\n",
      "Batch: 202/391\n",
      "Batch: 203/391\n",
      "Batch: 204/391\n",
      "Batch: 205/391\n",
      "Batch: 206/391\n",
      "Batch: 207/391\n",
      "Batch: 208/391\n",
      "Batch: 209/391\n",
      "Batch: 210/391\n",
      "Batch: 211/391\n",
      "Batch: 212/391\n",
      "Batch: 213/391\n",
      "Batch: 214/391\n",
      "Batch: 215/391\n",
      "Batch: 216/391\n",
      "Batch: 217/391\n",
      "Batch: 218/391\n",
      "Batch: 219/391\n",
      "Batch: 220/391\n",
      "Batch: 221/391\n",
      "Batch: 222/391\n",
      "Batch: 223/391\n",
      "Batch: 224/391\n",
      "Batch: 225/391\n",
      "Batch: 226/391\n",
      "Batch: 227/391\n",
      "Batch: 228/391\n",
      "Batch: 229/391\n",
      "Batch: 230/391\n",
      "Batch: 231/391\n",
      "Batch: 232/391\n",
      "Batch: 233/391\n",
      "Batch: 234/391\n",
      "Batch: 235/391\n",
      "Batch: 236/391\n",
      "Batch: 237/391\n",
      "Batch: 238/391\n",
      "Batch: 239/391\n",
      "Batch: 240/391\n",
      "Batch: 241/391\n",
      "Batch: 242/391\n",
      "Batch: 243/391\n",
      "Batch: 244/391\n",
      "Batch: 245/391\n",
      "Batch: 246/391\n",
      "Batch: 247/391\n",
      "Batch: 248/391\n",
      "Batch: 249/391\n",
      "Batch: 250/391\n",
      "Batch: 251/391\n",
      "Batch: 252/391\n",
      "Batch: 253/391\n",
      "Batch: 254/391\n",
      "Batch: 255/391\n",
      "Batch: 256/391\n",
      "Batch: 257/391\n",
      "Batch: 258/391\n",
      "Batch: 259/391\n",
      "Batch: 260/391\n",
      "Batch: 261/391\n",
      "Batch: 262/391\n",
      "Batch: 263/391\n",
      "Batch: 264/391\n",
      "Batch: 265/391\n",
      "Batch: 266/391\n",
      "Batch: 267/391\n",
      "Batch: 268/391\n",
      "Batch: 269/391\n",
      "Batch: 270/391\n",
      "Batch: 271/391\n",
      "Batch: 272/391\n",
      "Batch: 273/391\n",
      "Batch: 274/391\n",
      "Batch: 275/391\n",
      "Batch: 276/391\n",
      "Batch: 277/391\n",
      "Batch: 278/391\n",
      "Batch: 279/391\n",
      "Batch: 280/391\n",
      "Batch: 281/391\n",
      "Batch: 282/391\n",
      "Batch: 283/391\n",
      "Batch: 284/391\n",
      "Batch: 285/391\n",
      "Batch: 286/391\n",
      "Batch: 287/391\n",
      "Batch: 288/391\n",
      "Batch: 289/391\n",
      "Batch: 290/391\n",
      "Batch: 291/391\n",
      "Batch: 292/391\n",
      "Batch: 293/391\n",
      "Batch: 294/391\n",
      "Batch: 295/391\n",
      "Batch: 296/391\n",
      "Batch: 297/391\n",
      "Batch: 298/391\n",
      "Batch: 299/391\n",
      "Batch: 300/391\n",
      "Batch: 301/391\n",
      "Batch: 302/391\n",
      "Batch: 303/391\n",
      "Batch: 304/391\n",
      "Batch: 305/391\n",
      "Batch: 306/391\n",
      "Batch: 307/391\n",
      "Batch: 308/391\n",
      "Batch: 309/391\n",
      "Batch: 310/391\n",
      "Batch: 311/391\n",
      "Batch: 312/391\n",
      "Batch: 313/391\n",
      "Batch: 314/391\n",
      "Batch: 315/391\n",
      "Batch: 316/391\n",
      "Batch: 317/391\n",
      "Batch: 318/391\n",
      "Batch: 319/391\n",
      "Batch: 320/391\n",
      "Batch: 321/391\n",
      "Batch: 322/391\n",
      "Batch: 323/391\n",
      "Batch: 324/391\n",
      "Batch: 325/391\n",
      "Batch: 326/391\n",
      "Batch: 327/391\n",
      "Batch: 328/391\n",
      "Batch: 329/391\n",
      "Batch: 330/391\n",
      "Batch: 331/391\n",
      "Batch: 332/391\n",
      "Batch: 333/391\n",
      "Batch: 334/391\n",
      "Batch: 335/391\n",
      "Batch: 336/391\n",
      "Batch: 337/391\n",
      "Batch: 338/391\n",
      "Batch: 339/391\n",
      "Batch: 340/391\n",
      "Batch: 341/391\n",
      "Batch: 342/391\n",
      "Batch: 343/391\n",
      "Batch: 344/391\n",
      "Batch: 345/391\n",
      "Batch: 346/391\n",
      "Batch: 347/391\n",
      "Batch: 348/391\n",
      "Batch: 349/391\n",
      "Batch: 350/391\n",
      "Batch: 351/391\n",
      "Batch: 352/391\n",
      "Batch: 353/391\n",
      "Batch: 354/391\n",
      "Batch: 355/391\n",
      "Batch: 356/391\n",
      "Batch: 357/391\n",
      "Batch: 358/391\n",
      "Batch: 359/391\n",
      "Batch: 360/391\n",
      "Batch: 361/391\n",
      "Batch: 362/391\n",
      "Batch: 363/391\n",
      "Batch: 364/391\n",
      "Batch: 365/391\n",
      "Batch: 366/391\n",
      "Batch: 367/391\n",
      "Batch: 368/391\n",
      "Batch: 369/391\n",
      "Batch: 370/391\n",
      "Batch: 371/391\n",
      "Batch: 372/391\n",
      "Batch: 373/391\n",
      "Batch: 374/391\n",
      "Batch: 375/391\n",
      "Batch: 376/391\n",
      "Batch: 377/391\n",
      "Batch: 378/391\n",
      "Batch: 379/391\n",
      "Batch: 380/391\n",
      "Batch: 381/391\n",
      "Batch: 382/391\n",
      "Batch: 383/391\n",
      "Batch: 384/391\n",
      "Batch: 385/391\n",
      "Batch: 386/391\n",
      "Batch: 387/391\n",
      "Batch: 388/391\n",
      "Batch: 389/391\n",
      "Batch: 390/391\n",
      "391\n",
      "M_W_post size:  torch.Size([512, 100])\n",
      "M_b_post size:  torch.Size([100])\n",
      "C_W_post size:  torch.Size([100, 512])\n",
      "C_b_post size:  torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "M_W_post_D_CIFAR100, M_b_post_D_CIFAR100, C_W_post_D_CIFAR100, C_b_post_D_CIFAR100 = Diag_second_order(model=CIFAR100_model,\n",
    "                                                               train_loader=CIFAR100_train_loader,\n",
    "                                                               var0 = 75,\n",
    "                                                               device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP estimate for CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR100_test_in_MAP = predict_MAP(CIFAR100_model, CIFAR100_test_loader, cuda=True).cpu().numpy()\n",
    "CIFAR100_test_out_CIFAR10_MAP = predict_MAP(CIFAR100_model, testloader, cuda=True).cpu().numpy()\n",
    "CIFAR100_test_out_SVHN_MAP = predict_MAP(CIFAR100_model, test_loader_SVHN, cuda=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP = get_in_dist_values(CIFAR100_test_in_MAP, targets_CIFAR100)\n",
    "acc_out_CIFAR10_MAP, prob_correct_out_CIFAR10_MAP, ent_out_CIFAR10, MMC_out_CIFAR10_MAP, auroc_out_CIFAR10_MAP = get_out_dist_values(CIFAR100_test_in_MAP, CIFAR100_test_out_CIFAR10_MAP, targets_CIFAR10)\n",
    "acc_out_SVHN_MAP, prob_correct_out_SVHN_MAP, ent_out_SVHN_MAP, MMC_out_SVHN_MAP, auroc_out_SVHN_MAP = get_out_dist_values(CIFAR100_test_in_MAP, CIFAR100_test_out_SVHN_MAP, targets_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, MAP, CIFAR100] Accuracy: 0.588; average entropy: 2.154;     MMC: 0.556; Prob @ correct: 0.010\n",
      "[Out-MAP, KFAC, CIFAR10] Accuracy: 0.008; Average entropy: 3.346;    MMC: 0.300; AUROC: 0.704; Prob @ correct: 0.010\n",
      "[Out-MAP, KFAC, SVHN] Accuracy: 0.003; Average entropy: 2.970;    MMC: 0.394; AUROC: 0.632; Prob @ correct: 0.010\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP, 'CIFAR100', 'MAP')\n",
    "print_out_dist_values(acc_out_CIFAR10_MAP, prob_correct_out_CIFAR10_MAP, ent_out_CIFAR10, MMC_out_CIFAR10_MAP, auroc_out_CIFAR10_MAP, 'CIFAR10', 'MAP')\n",
    "print_out_dist_values(acc_out_SVHN_MAP, prob_correct_out_SVHN_MAP, ent_out_SVHN_MAP, MMC_out_SVHN_MAP, auroc_out_SVHN_MAP, 'SVHN', 'MAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.592 with std 0.006\n",
      "MMC in: 0.564 with std 0.018\n",
      "MMC out CIFAR10: 0.298 with std 0.004\n",
      "MMC out SVHN: 0.372 with std 0.015\n",
      "AUROC out CIFAR10: 0.706 with std 0.003\n",
      "AUROC out SVHN: 0.649 with std 0.012\n"
     ]
    }
   ],
   "source": [
    "#MAP estimate\n",
    "#seeds are 123,124,125,126,127\n",
    "acc_in = [0.589, 0.585, 0.599, 0.599, 0.588]\n",
    "mmc_in = [0.552, 0.552, 0.599, 0.560, 0.556]\n",
    "mmc_out_CIFAR10 = [0.294, 0.296, 0.293, 0.305, 0.300]\n",
    "mmc_out_SVHN = [0.386, 0.355, 0.359, 0.368, 0.394]\n",
    "\n",
    "auroc_out_CIFAR10 = [0.705, 0.706, 0.713, 0.704, 0.704]\n",
    "auroc_out_SVHN = [0.637, 0.656, 0.660, 0.658, 0.632]\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR10), np.std(mmc_out_CIFAR10)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR10), np.std(auroc_out_CIFAR10)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diag sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used for sampling with 1000 samples: 6.7309911251068115\n",
      "time used for sampling with 1000 samples: 6.638373136520386\n",
      "time used for sampling with 1000 samples: 17.25725769996643\n"
     ]
    }
   ],
   "source": [
    "CIFAR100_test_in_D = predict_diagonal_sampling(CIFAR100_model, CIFAR100_test_loader, M_W_post_D_CIFAR100, M_b_post_D_CIFAR100, C_W_post_D_CIFAR100, C_b_post_D_CIFAR100, n_samples=1000, cuda=True, timing=True).cpu().numpy()\n",
    "CIFAR100_test_out_CIFAR10_D = predict_diagonal_sampling(CIFAR100_model, testloader, M_W_post_D_CIFAR100, M_b_post_D_CIFAR100, C_W_post_D_CIFAR100, C_b_post_D_CIFAR100, n_samples=1000, cuda=True, timing=True).cpu().numpy()\n",
    "CIFAR100_test_out_SVHN_D = predict_diagonal_sampling(CIFAR100_model, test_loader_SVHN, M_W_post_D_CIFAR100, M_b_post_D_CIFAR100, C_W_post_D_CIFAR100, C_b_post_D_CIFAR100, n_samples=1000, cuda=True, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marius/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D = get_in_dist_values(CIFAR100_test_in_D, targets_CIFAR100)\n",
    "acc_out_CIFAR10_D, prob_correct_out_CIFAR10_D, ent_out_CIFAR10_D, MMC_out_CIFAR10_D, auroc_out_CIFAR10_D = get_out_dist_values(CIFAR100_test_in_D, CIFAR100_test_out_CIFAR10_D, targets_CIFAR10)\n",
    "acc_out_SVHN_D, prob_correct_out_SVHN_D, ent_out_SVHN_D, MMC_out_SVHN_D, auroc_out_SVHN_D = get_out_dist_values(CIFAR100_test_in_D, CIFAR100_test_out_SVHN_D, targets_CIFAR100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, Diag, CIFAR100] Accuracy: 0.587; average entropy: 2.292;     MMC: 0.527; Prob @ correct: 0.010\n",
      "[Out-Diag, KFAC, CIFAR10] Accuracy: 0.008; Average entropy: 3.442;    MMC: 0.278; AUROC: 0.705; Prob @ correct: 0.010\n",
      "[Out-Diag, KFAC, SVHN] Accuracy: 0.000; Average entropy: 3.100;    MMC: 0.368; AUROC: 0.630; Prob @ correct: 0.010\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D, 'CIFAR100', 'Diag')\n",
    "print_out_dist_values(acc_out_CIFAR10_D, prob_correct_out_CIFAR10_D, ent_out_CIFAR10_D, MMC_out_CIFAR10_D, auroc_out_CIFAR10_D, 'CIFAR10', 'Diag')\n",
    "print_out_dist_values(acc_out_SVHN_D, prob_correct_out_SVHN_D, ent_out_SVHN_D, MMC_out_SVHN_D, auroc_out_SVHN_D, 'SVHN', 'Diag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Bridge time in: 6.680 with std 0.042\n",
      "Sampling Bridge time out CIFAR10: 6.672 with std 0.075\n",
      "Sampling Bridge time out SVHN: 17.160 with std 0.147\n",
      "accuracy: 0.591 with std 0.005\n",
      "MMC in: 0.527 with std 0.004\n",
      "MMC out CIFAR10: 0.276 with std 0.004\n",
      "MMC out SVHN: 0.349 with std 0.014\n",
      "AUROC out CIFAR10: 0.707 with std 0.004\n",
      "AUROC out SVHN: 0.647 with std 0.011\n"
     ]
    }
   ],
   "source": [
    "#Diag Sampling\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [6.612371921539307, 6.715473651885986,6.670197486877441, 6.670319318771362, 6.7309911251068115]\n",
    "time_lpb_out_CIFAR10 = [6.698111295700073, 6.796610593795776, 6.656818866729736, 6.569646596908569, 6.638373136520386]\n",
    "time_lpb_out_SVHN = [17.256507873535156,17.233936071395874, 17.18303084373474, 16.87152647972107, 17.25725769996643]\n",
    "\n",
    "acc_in = [0.588, 0.586, 0.598, 0.598, 0.587]\n",
    "mmc_in = [0.523, 0.524, 0.531, 0.532, 0.527]\n",
    "mmc_out_CIFAR10 = [0.273, 0.274, 0.271, 0.283, 0.278]\n",
    "mmc_out_SVHN = [0.362, 0.332, 0.335, 0.346, 0.368]\n",
    "\n",
    "auroc_out_CIFAR10 = [0.706, 0.706, 0.714, 0.704, 0.705]\n",
    "auroc_out_SVHN = [0.636, 0.654, 0.658, 0.655, 0.630]\n",
    "\n",
    "print(\"Sampling Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Sampling Bridge time out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR10), np.std(time_lpb_out_CIFAR10)))\n",
    "print(\"Sampling Bridge time out SVHN: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_SVHN), np.std(time_lpb_out_SVHN)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR10), np.std(mmc_out_CIFAR10)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR10), np.std(auroc_out_CIFAR10)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplace Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used for transform: 0.01648\n",
      "total time used for transform: 0.01797\n",
      "total time used for transform: 0.04194\n"
     ]
    }
   ],
   "source": [
    "CIFAR100_test_in_DIR_LPA = predict_DIR_LPA(CIFAR100_model, CIFAR100_test_loader, M_W_post_D_CIFAR100, M_b_post_D_CIFAR100, C_W_post_D_CIFAR100, C_b_post_D_CIFAR100, cuda=True, timing=True).cpu().numpy()\n",
    "CIFAR100_test_out_CIFAR10_DIR_LPA = predict_DIR_LPA(CIFAR100_model, testloader, M_W_post_D_CIFAR100, M_b_post_D_CIFAR100, C_W_post_D_CIFAR100, C_b_post_D_CIFAR100, cuda=True, timing=True).cpu().numpy()\n",
    "CIFAR100_test_out_SVHN_DIR_LPA = predict_DIR_LPA(CIFAR100_model, test_loader_SVHN, M_W_post_D_CIFAR100, M_b_post_D_CIFAR100, C_W_post_D_CIFAR100, C_b_post_D_CIFAR100, cuda=True, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize to get the MAP estimate (which is the mode) of the Dirichlet\n",
    "CIFAR100_test_in_DIR_LPAn = CIFAR100_test_in_DIR_LPA/CIFAR100_test_in_DIR_LPA.sum(1).reshape(-1,1)\n",
    "CIFAR100_test_out_CIFAR10_DIR_LPAn = CIFAR100_test_out_CIFAR10_DIR_LPA/CIFAR100_test_out_CIFAR10_DIR_LPA.sum(1).reshape(-1,1)\n",
    "CIFAR100_test_out_SVHN_DIR_LPAn = CIFAR100_test_out_SVHN_DIR_LPA/CIFAR100_test_out_SVHN_DIR_LPA.sum(1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_DIR_LPA, prob_correct_in_DIR_LPA, ent_in_DIR_LPA, MMC_in_DIR_LPA = get_in_dist_values(CIFAR100_test_in_DIR_LPAn, targets_CIFAR100)\n",
    "acc_out_CIFAR10_DIR_LPA, prob_correct_out_CIFAR10_DIR_LPA, ent_out_CIFAR10_DIR_LPA, MMC_out_CIFAR10_DIR_LPA, auroc_out_CIFAR10_DIR_LPA = get_out_dist_values(CIFAR100_test_in_DIR_LPAn, CIFAR100_test_out_CIFAR10_DIR_LPAn, targets_CIFAR10)\n",
    "acc_out_SVHN_DIR_LPA, prob_correct_out_SVHN_DIR_LPA, ent_out_SVHN_DIR_LPA, MMC_out_SVHN_DIR_LPA, auroc_out_SVHN_DIR_LPA = get_out_dist_values(CIFAR100_test_in_DIR_LPAn, CIFAR100_test_out_SVHN_DIR_LPAn, targets_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, DIR_LPA, CIFAR100] Accuracy: 0.587; average entropy: 3.577;     MMC: 0.265; Prob @ correct: 0.010\n",
      "[Out-DIR_LPA, KFAC, CIFAR10] Accuracy: 0.008; Average entropy: 4.394;    MMC: 0.070; AUROC: 0.701; Prob @ correct: 0.010\n",
      "[Out-DIR_LPA, KFAC, SVHN] Accuracy: 0.003; Average entropy: 4.413;    MMC: 0.074; AUROC: 0.643; Prob @ correct: 0.010\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_DIR_LPA, prob_correct_in_DIR_LPA, ent_in_DIR_LPA, MMC_in_DIR_LPA, 'CIFAR100', 'DIR_LPA')\n",
    "print_out_dist_values(acc_out_CIFAR10_DIR_LPA, prob_correct_out_CIFAR10_DIR_LPA, ent_out_CIFAR10_DIR_LPA, MMC_out_CIFAR10_DIR_LPA, auroc_out_CIFAR10_DIR_LPA, 'CIFAR10', 'DIR_LPA')\n",
    "print_out_dist_values(acc_out_SVHN_DIR_LPA, prob_correct_out_SVHN_DIR_LPA, ent_out_SVHN_DIR_LPA, MMC_out_SVHN_DIR_LPA, auroc_out_SVHN_DIR_LPA, 'SVHN', 'DIR_LPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplace Bridge time in: 0.017 with std 0.002\n",
      "Laplace Bridge time out CIFAR10: 0.018 with std 0.000\n",
      "Laplace Bridge time out SVHN: 0.042 with std 0.000\n",
      "accuracy: 0.592 with std 0.006\n",
      "MMC in: 0.263 with std 0.003\n",
      "MMC out CIFAR10: 0.068 with std 0.003\n",
      "MMC out SVHN: 0.074 with std 0.012\n",
      "AUROC out CIFAR10: 0.703 with std 0.003\n",
      "AUROC out SVHN: 0.661 with std 0.013\n"
     ]
    }
   ],
   "source": [
    "#Laplace Bridge\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [0.02161,0.01674, 0.01601, 0.01607, 0.01648]\n",
    "time_lpb_out_CIFAR10 = [0.01830, 0.01804, 0.01745, 0.01724, 0.01797]\n",
    "time_lpb_out_SVHN = [0.04126, 0.04220, 0.04133, 0.04108, 0.04194]\n",
    "\n",
    "\n",
    "acc_in = [0.590, 0.585, 0.600, 0.598, 0.587]\n",
    "mmc_in = [0.259, 0.260, 0.266, 0.263, 0.265]\n",
    "mmc_out_CIFAR10 = [0.067, 0.067, 0.063, 0.073, 0.070]\n",
    "mmc_out_SVHN = [0.096, 0.063, 0.063, 0.072, 0.074]\n",
    "\n",
    "auroc_out_CIFAR10 = [0.702, 0.703, 0.709, 0.700, 0.701]\n",
    "auroc_out_SVHN = [0.648, 0.668, 0.671, 0.673, 0.643]\n",
    "\n",
    "\n",
    "print(\"Laplace Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Laplace Bridge time out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR10), np.std(time_lpb_out_CIFAR10)))\n",
    "print(\"Laplace Bridge time out SVHN: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_SVHN), np.std(time_lpb_out_SVHN)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR10), np.std(mmc_out_CIFAR10)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR10), np.std(auroc_out_CIFAR10)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
