import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torch.backends.cudnn as cudnn

import torchvision
import torchvision.transforms as transforms

import os

######## load data

BATCH_SIZE_TRAIN_CIFAR10 = 5 #128
BATCH_SIZE_TEST_CIFAR10 = 128

transform_base = [transforms.ToTensor()]

transform_train = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),
    ] + transform_base)

transform_test = transforms.Compose(transform_base)
transform_train = transforms.RandomChoice([transform_train, transform_test])

#~/data/cifar10
CIFAR10_trainset = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=True, download=True, transform=transform_train)
CIFAR10_train_loader = torch.utils.data.DataLoader(CIFAR10_trainset, batch_size=BATCH_SIZE_TRAIN_CIFAR10, shuffle=True, num_workers=2)

#~/data/cifar10
CIFAR10_testset = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=False, download=True, transform=transform_test)
CIFAR10_test_loader = torch.utils.data.DataLoader(CIFAR10_testset, batch_size=BATCH_SIZE_TEST_CIFAR10, shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')



# Minimal example in the "classic" (non-sequential) fashion
class MiniNet(nn.Module):
    def __init__(self, input_size=32*32, num_classes=10, color_channels=3):
        super(MiniNet, self).__init__()
        self.input_size = input_size
        self.color_channels = color_channels

        self.linear1 = nn.Linear(input_size * color_channels, 32) 
        self.linear2 = nn.Linear(32, input_size * color_channels)
        
        self.skip = nn.Sequential()
        self.linear3 = nn.Linear(input_size * color_channels, num_classes) 

    def forward(self, x):
        flat_inp = x.view(-1, self.input_size*self.color_channels)
        out = self.linear1(flat_inp)
        out = F.relu(out)
        out = self.linear2(out)
        
        out += self.skip(flat_inp) #this is the residual/skip/shortcut connection
        
        out = F.relu(out)
        out = self.linear3(out)
        
        return(out)

# Test it
MiniNet = MiniNet()
test_X, _ = next(iter(CIFAR10_train_loader))
MiniNet_out = MiniNet(test_X)
print("shape of MiniNet_out: ", MiniNet_out.size())


# define the Mini Resnet as a sequential
def get_outputs_(x):
        return(None)  #<- I have tried to work around with forward and backward hooks
                      # but that does not seem to work so far

class Residual(nn.Module):
    def __init__(self, skip):
        super().__init__()
        self.skip = skip
        
    def forward(self, input):
        '''
        Adds the residual to the normal stream
        '''
        out_skip = get_outputs_(self.skip) #<- this is where the magic needs to happen
        out = input + out_skip
        return(out)

def MiniNetSeq(input_size=32*32, num_classes=10, color_channels=3):
    
    skip = nn.Sequential()
    
    mini_net = nn.Sequential(
        nn.Flatten(),
        nn.Linear(input_size*color_channels, 32),
        nn.ReLU(),
        nn.Linear(32, input_size*color_channels),
        Residual(skip),
        nn.ReLU(),
        nn.Linear(input_size, num_classes)
    )
    
    return(mini_net)

# test it
MiniNetSeq = MiniNetSeq(num_classes=10)
MiniNetSeq(test_X)
