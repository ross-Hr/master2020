{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version:  1.3.1\n",
      "cuda available:  True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import numpy as np\n",
    "#import input_data\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "from math import *\n",
    "from backpack import backpack, extend\n",
    "from backpack.extensions import KFAC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy\n",
    "from tqdm import tqdm, trange\n",
    "import pytest\n",
    "import matplotlib.pyplot as plt\n",
    "from DirLPA_utils import * \n",
    "\n",
    "print(\"pytorch version: \", torch.__version__)\n",
    "print(\"cuda available: \", torch.cuda.is_available())\n",
    "\n",
    "s = 126\n",
    "np.random.seed(s)\n",
    "torch.manual_seed(s)\n",
    "torch.cuda.manual_seed(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Cifar10 on Resnet32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TRAIN_CIFAR10 = 128\n",
    "BATCH_SIZE_TEST_CIFAR10 = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(output, targets):\n",
    "    \"\"\"Helper function to print the accuracy\"\"\"\n",
    "    predictions = output.argmax(dim=1, keepdim=True).view_as(targets)\n",
    "    return predictions.eq(targets).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "\n",
    "train_size = int(0.9 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "CIFAR10_train_dataset, CIFAR10_val_dataset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
    "\n",
    "CIFAR10_train_loader = torch.utils.data.DataLoader(CIFAR10_train_dataset, batch_size=BATCH_SIZE_TRAIN_CIFAR10,\n",
    "                                          shuffle=False)\n",
    "\n",
    "CIFAR10_val_loader = torch.utils.data.DataLoader(CIFAR10_val_dataset, batch_size=BATCH_SIZE_TRAIN_CIFAR10,\n",
    "                                          shuffle=False)\n",
    "\n",
    "CIFAR10_test = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "CIFAR10_test_loader = torch.utils.data.DataLoader(CIFAR10_test, batch_size=BATCH_SIZE_TEST_CIFAR10,\n",
    "                                         shuffle=False)\n",
    "\n",
    "CIFAR10_classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(CIFAR10_train_loader)\n",
    "images, labels = dataiter.next()\n",
    "nrow = int(BATCH_SIZE_TRAIN_CIFAR10/4)\n",
    "imshow(torchvision.utils.make_grid(images, nrow=nrow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#load in CIFAR100\n",
    "BATCH_SIZE_TRAIN_CIFAR100 = 128\n",
    "BATCH_SIZE_TEST_CIFAR100 = 128\n",
    "\n",
    "CIFAR100_train = torchvision.datasets.CIFAR100(root='~/data/cifar100', train=True,\n",
    "                                       download=True, transform=transform_test)\n",
    "CIFAR100_train_loader = torch.utils.data.DataLoader(CIFAR100_train, batch_size=BATCH_SIZE_TRAIN_CIFAR100,\n",
    "                                         shuffle=False)\n",
    "\n",
    "CIFAR100_test = torchvision.datasets.CIFAR100(root='~/data/cifar100', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "CIFAR100_test_loader = torch.utils.data.DataLoader(CIFAR100_test, batch_size=BATCH_SIZE_TEST_CIFAR100,\n",
    "                                         shuffle=False)\n",
    "\n",
    "CIFAR100_classes = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "    'worm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/marius/data/SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: /home/marius/data/SVHN/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "# load SVHN\n",
    "BATCH_SIZE_TRAIN_SVHN = 128\n",
    "BATCH_SIZE_TEST_SVHN = 128\n",
    "\n",
    "train_data_SVHN = torchvision.datasets.SVHN('~/data/SVHN', split='train',\n",
    "                             download=True, transform=transform_train)\n",
    "\n",
    "test_data_SVHN = torchvision.datasets.SVHN('~/data/SVHN', split='test',\n",
    "                             download=True, transform=transform_test)\n",
    "\n",
    "train_loader_SVHN = torch.utils.data.DataLoader(test_data_SVHN, batch_size=BATCH_SIZE_TRAIN_SVHN)\n",
    "test_loader_SVHN = torch.utils.data.DataLoader(test_data_SVHN, batch_size=BATCH_SIZE_TEST_SVHN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CIFAR10 on ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE_TRAIN_CIFAR10, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE_TEST_CIFAR10, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(CIFAR10_train_loader)\n",
    "images, labels = dataiter.next()\n",
    "nrow = int(BATCH_SIZE_TRAIN_CIFAR10/4)\n",
    "imshow(torchvision.utils.make_grid(images, nrow=nrow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.fc = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def phi(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.phi(x)\n",
    "        out = self.fc(out)\n",
    "        return(out)\n",
    "\n",
    "\n",
    "def ResNet18(num_classes=10):\n",
    "    return ResNet(BasicBlock, [2,2,2,2], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "CIFAR10_model = ResNet18().to(device)\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(CIFAR10_model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(net, epoch, optimizer, trainloader, filename):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    \n",
    "    print(\"train loss: \", train_loss)\n",
    "    print(\"train accuracy: \", correct/total)\n",
    "    print(\"saving model at: {}\".format(filename))\n",
    "    torch.save(net.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, epoch, testloader):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "        print(\"test loss: \", test_loss)\n",
    "        print(\"test accuracy: \", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all():\n",
    "    CIFAR10_path = 'weights/cifar10_resnet18_SGD.pth'\n",
    "    lr = 0.1\n",
    "    epoch = 0\n",
    "    for e in [100, 50, 50]:\n",
    "        print(\"current learning rate: \", lr)\n",
    "        for _ in range(e):\n",
    "            optimizer = optim.SGD(CIFAR10_model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "            train(CIFAR10_model, epoch, optimizer, trainloader, CIFAR10_path)\n",
    "            test(CIFAR10_model, epoch, testloader)\n",
    "            epoch += 1\n",
    "        lr /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current learning rate:  0.1\n",
      "\n",
      "Epoch: 0\n",
      "train loss:  787.8048022985458\n",
      "train accuracy:  0.29138\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  130.1247147321701\n",
      "test accuracy:  0.3878\n",
      "\n",
      "Epoch: 1\n",
      "train loss:  604.6919292211533\n",
      "train accuracy:  0.42902\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  114.41172480583191\n",
      "test accuracy:  0.4638\n",
      "\n",
      "Epoch: 2\n",
      "train loss:  529.2565062046051\n",
      "train accuracy:  0.50436\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  99.33933591842651\n",
      "test accuracy:  0.5441\n",
      "\n",
      "Epoch: 3\n",
      "train loss:  440.69397270679474\n",
      "train accuracy:  0.59708\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  85.9754581451416\n",
      "test accuracy:  0.6116\n",
      "\n",
      "Epoch: 4\n",
      "train loss:  369.4627437591553\n",
      "train accuracy:  0.66576\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  90.12607306241989\n",
      "test accuracy:  0.6124\n",
      "\n",
      "Epoch: 5\n",
      "train loss:  308.3439773321152\n",
      "train accuracy:  0.72194\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  60.92102915048599\n",
      "test accuracy:  0.7282\n",
      "\n",
      "Epoch: 6\n",
      "train loss:  261.9367733001709\n",
      "train accuracy:  0.76614\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  57.61436504125595\n",
      "test accuracy:  0.7481\n",
      "\n",
      "Epoch: 7\n",
      "train loss:  236.29320845007896\n",
      "train accuracy:  0.79078\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  51.348432779312134\n",
      "test accuracy:  0.7826\n",
      "\n",
      "Epoch: 8\n",
      "train loss:  219.47826477885246\n",
      "train accuracy:  0.80838\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  49.732062578201294\n",
      "test accuracy:  0.7832\n",
      "\n",
      "Epoch: 9\n",
      "train loss:  206.5850972533226\n",
      "train accuracy:  0.81694\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  64.62383908033371\n",
      "test accuracy:  0.7382\n",
      "\n",
      "Epoch: 10\n",
      "train loss:  199.19177690148354\n",
      "train accuracy:  0.82478\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  76.88977038860321\n",
      "test accuracy:  0.699\n",
      "\n",
      "Epoch: 11\n",
      "train loss:  189.2608264386654\n",
      "train accuracy:  0.83142\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  52.415239453315735\n",
      "test accuracy:  0.7847\n",
      "\n",
      "Epoch: 12\n",
      "train loss:  183.89748772978783\n",
      "train accuracy:  0.8384\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  49.09725892543793\n",
      "test accuracy:  0.787\n",
      "\n",
      "Epoch: 13\n",
      "train loss:  177.3229728192091\n",
      "train accuracy:  0.84488\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  38.07630255818367\n",
      "test accuracy:  0.8306\n",
      "\n",
      "Epoch: 14\n",
      "train loss:  173.70738649368286\n",
      "train accuracy:  0.84628\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  45.69077554345131\n",
      "test accuracy:  0.8046\n",
      "\n",
      "Epoch: 15\n",
      "train loss:  168.01999752223492\n",
      "train accuracy:  0.85272\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  46.51071083545685\n",
      "test accuracy:  0.805\n",
      "\n",
      "Epoch: 16\n",
      "train loss:  165.75895936787128\n",
      "train accuracy:  0.85656\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  41.06046572327614\n",
      "test accuracy:  0.8247\n",
      "\n",
      "Epoch: 17\n",
      "train loss:  163.48671290278435\n",
      "train accuracy:  0.857\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  40.986295223236084\n",
      "test accuracy:  0.8326\n",
      "\n",
      "Epoch: 18\n",
      "train loss:  159.812156483531\n",
      "train accuracy:  0.85964\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  46.25861841440201\n",
      "test accuracy:  0.8057\n",
      "\n",
      "Epoch: 19\n",
      "train loss:  159.5383025854826\n",
      "train accuracy:  0.86\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  51.76554621756077\n",
      "test accuracy:  0.7877\n",
      "\n",
      "Epoch: 20\n",
      "train loss:  153.7811364531517\n",
      "train accuracy:  0.86596\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  48.07354983687401\n",
      "test accuracy:  0.7992\n",
      "\n",
      "Epoch: 21\n",
      "train loss:  150.4982472360134\n",
      "train accuracy:  0.86816\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  43.81681281328201\n",
      "test accuracy:  0.8175\n",
      "\n",
      "Epoch: 22\n",
      "train loss:  149.90224146842957\n",
      "train accuracy:  0.8692\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  44.10641819238663\n",
      "test accuracy:  0.8168\n",
      "\n",
      "Epoch: 23\n",
      "train loss:  149.67552609741688\n",
      "train accuracy:  0.86944\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  47.54828670620918\n",
      "test accuracy:  0.7994\n",
      "\n",
      "Epoch: 24\n",
      "train loss:  146.7912611812353\n",
      "train accuracy:  0.87064\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  41.79015240073204\n",
      "test accuracy:  0.8274\n",
      "\n",
      "Epoch: 25\n",
      "train loss:  146.82145936787128\n",
      "train accuracy:  0.87196\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  48.61456689238548\n",
      "test accuracy:  0.8069\n",
      "\n",
      "Epoch: 26\n",
      "train loss:  145.76781858503819\n",
      "train accuracy:  0.87372\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  54.78716084361076\n",
      "test accuracy:  0.7762\n",
      "\n",
      "Epoch: 27\n",
      "train loss:  143.45703640580177\n",
      "train accuracy:  0.87564\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  42.297853887081146\n",
      "test accuracy:  0.8292\n",
      "\n",
      "Epoch: 28\n",
      "train loss:  140.66675858199596\n",
      "train accuracy:  0.87706\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  38.46540558338165\n",
      "test accuracy:  0.8377\n",
      "\n",
      "Epoch: 29\n",
      "train loss:  143.30562771856785\n",
      "train accuracy:  0.87534\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  46.48332333564758\n",
      "test accuracy:  0.8067\n",
      "\n",
      "Epoch: 30\n",
      "train loss:  139.94737988710403\n",
      "train accuracy:  0.8772\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  48.8103643655777\n",
      "test accuracy:  0.804\n",
      "\n",
      "Epoch: 31\n",
      "train loss:  137.77778884768486\n",
      "train accuracy:  0.88016\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  51.755557745695114\n",
      "test accuracy:  0.7925\n",
      "\n",
      "Epoch: 32\n",
      "train loss:  137.02357263863087\n",
      "train accuracy:  0.8806\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  34.60336159169674\n",
      "test accuracy:  0.85\n",
      "\n",
      "Epoch: 33\n",
      "train loss:  138.8521730452776\n",
      "train accuracy:  0.8788\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  42.32996419072151\n",
      "test accuracy:  0.8289\n",
      "\n",
      "Epoch: 34\n",
      "train loss:  135.55952687561512\n",
      "train accuracy:  0.88074\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  43.73508007824421\n",
      "test accuracy:  0.8251\n",
      "\n",
      "Epoch: 35\n",
      "train loss:  134.27890560030937\n",
      "train accuracy:  0.88238\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  56.88078397512436\n",
      "test accuracy:  0.7689\n",
      "\n",
      "Epoch: 36\n",
      "train loss:  133.1888953447342\n",
      "train accuracy:  0.88338\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  36.468804597854614\n",
      "test accuracy:  0.8502\n",
      "\n",
      "Epoch: 37\n",
      "train loss:  136.49814622104168\n",
      "train accuracy:  0.8804\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  35.76718044281006\n",
      "test accuracy:  0.847\n",
      "\n",
      "Epoch: 38\n",
      "train loss:  133.2610513716936\n",
      "train accuracy:  0.88286\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  61.576141983270645\n",
      "test accuracy:  0.7528\n",
      "\n",
      "Epoch: 39\n",
      "train loss:  134.27334716916084\n",
      "train accuracy:  0.88352\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  45.87574437260628\n",
      "test accuracy:  0.8143\n",
      "\n",
      "Epoch: 40\n",
      "train loss:  131.67202518880367\n",
      "train accuracy:  0.88518\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  34.25380681455135\n",
      "test accuracy:  0.8569\n",
      "\n",
      "Epoch: 41\n",
      "train loss:  131.53371426463127\n",
      "train accuracy:  0.8857\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  41.15126720070839\n",
      "test accuracy:  0.8285\n",
      "\n",
      "Epoch: 42\n",
      "train loss:  131.42107945680618\n",
      "train accuracy:  0.88602\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  46.971375197172165\n",
      "test accuracy:  0.7975\n",
      "\n",
      "Epoch: 43\n",
      "train loss:  132.7147294729948\n",
      "train accuracy:  0.88608\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  35.23686099052429\n",
      "test accuracy:  0.8503\n",
      "\n",
      "Epoch: 44\n",
      "train loss:  132.22378769516945\n",
      "train accuracy:  0.88394\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  37.036693543195724\n",
      "test accuracy:  0.8436\n",
      "\n",
      "Epoch: 45\n",
      "train loss:  130.3103125691414\n",
      "train accuracy:  0.88496\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  43.56609934568405\n",
      "test accuracy:  0.8209\n",
      "\n",
      "Epoch: 46\n",
      "train loss:  130.1994640827179\n",
      "train accuracy:  0.8868\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  39.32745537161827\n",
      "test accuracy:  0.8413\n",
      "\n",
      "Epoch: 47\n",
      "train loss:  130.0313138589263\n",
      "train accuracy:  0.88752\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  36.875759571790695\n",
      "test accuracy:  0.8455\n",
      "\n",
      "Epoch: 48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  130.760771676898\n",
      "train accuracy:  0.8856\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  42.70304638147354\n",
      "test accuracy:  0.8203\n",
      "\n",
      "Epoch: 49\n",
      "train loss:  129.09588414430618\n",
      "train accuracy:  0.88894\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  38.20109987258911\n",
      "test accuracy:  0.844\n",
      "\n",
      "Epoch: 50\n",
      "train loss:  129.41893269121647\n",
      "train accuracy:  0.88742\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  37.517845779657364\n",
      "test accuracy:  0.8477\n",
      "\n",
      "Epoch: 51\n",
      "train loss:  129.9248482733965\n",
      "train accuracy:  0.8858\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  33.73064462840557\n",
      "test accuracy:  0.86\n",
      "\n",
      "Epoch: 52\n",
      "train loss:  129.84284448623657\n",
      "train accuracy:  0.88662\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  47.71906867623329\n",
      "test accuracy:  0.7999\n",
      "\n",
      "Epoch: 53\n",
      "train loss:  126.89834266901016\n",
      "train accuracy:  0.89076\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  57.42096948623657\n",
      "test accuracy:  0.7755\n",
      "\n",
      "Epoch: 54\n",
      "train loss:  130.0578721910715\n",
      "train accuracy:  0.88712\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  44.60909269750118\n",
      "test accuracy:  0.821\n",
      "\n",
      "Epoch: 55\n",
      "train loss:  126.45297014713287\n",
      "train accuracy:  0.89072\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  34.806919157505035\n",
      "test accuracy:  0.8552\n",
      "\n",
      "Epoch: 56\n",
      "train loss:  126.85319538414478\n",
      "train accuracy:  0.88906\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  41.096443593502045\n",
      "test accuracy:  0.8259\n",
      "\n",
      "Epoch: 57\n",
      "train loss:  127.78610374033451\n",
      "train accuracy:  0.88836\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  39.489246159791946\n",
      "test accuracy:  0.8372\n",
      "\n",
      "Epoch: 58\n",
      "train loss:  126.23123402893543\n",
      "train accuracy:  0.89084\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  38.73081175982952\n",
      "test accuracy:  0.846\n",
      "\n",
      "Epoch: 59\n",
      "train loss:  128.36184468865395\n",
      "train accuracy:  0.88716\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  43.420711517333984\n",
      "test accuracy:  0.827\n",
      "\n",
      "Epoch: 60\n",
      "train loss:  124.93685905635357\n",
      "train accuracy:  0.89108\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  43.73149383068085\n",
      "test accuracy:  0.8268\n",
      "\n",
      "Epoch: 61\n",
      "train loss:  126.17272664606571\n",
      "train accuracy:  0.89002\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  32.32962064445019\n",
      "test accuracy:  0.8642\n",
      "\n",
      "Epoch: 62\n",
      "train loss:  126.47238899767399\n",
      "train accuracy:  0.89136\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  35.82026106119156\n",
      "test accuracy:  0.8547\n",
      "\n",
      "Epoch: 63\n",
      "train loss:  125.07732212543488\n",
      "train accuracy:  0.89116\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  38.726307302713394\n",
      "test accuracy:  0.833\n",
      "\n",
      "Epoch: 64\n",
      "train loss:  125.83635921776295\n",
      "train accuracy:  0.88986\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  38.974684953689575\n",
      "test accuracy:  0.8451\n",
      "\n",
      "Epoch: 65\n",
      "train loss:  125.99080273509026\n",
      "train accuracy:  0.88972\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  37.457386031746864\n",
      "test accuracy:  0.8494\n",
      "\n",
      "Epoch: 66\n",
      "train loss:  124.47917602956295\n",
      "train accuracy:  0.89022\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  35.424187079072\n",
      "test accuracy:  0.8489\n",
      "\n",
      "Epoch: 67\n",
      "train loss:  125.72045427560806\n",
      "train accuracy:  0.89018\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  45.50035199522972\n",
      "test accuracy:  0.8161\n",
      "\n",
      "Epoch: 68\n",
      "train loss:  126.50707717239857\n",
      "train accuracy:  0.88966\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  44.36964252591133\n",
      "test accuracy:  0.8199\n",
      "\n",
      "Epoch: 69\n",
      "train loss:  126.22545765340328\n",
      "train accuracy:  0.89014\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  46.323469772934914\n",
      "test accuracy:  0.8153\n",
      "\n",
      "Epoch: 70\n",
      "train loss:  123.0739204287529\n",
      "train accuracy:  0.89132\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  36.6477605253458\n",
      "test accuracy:  0.8454\n",
      "\n",
      "Epoch: 71\n",
      "train loss:  124.54914200305939\n",
      "train accuracy:  0.89162\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  32.96223966777325\n",
      "test accuracy:  0.8628\n",
      "\n",
      "Epoch: 72\n",
      "train loss:  125.32269012928009\n",
      "train accuracy:  0.89014\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  39.679693043231964\n",
      "test accuracy:  0.8342\n",
      "\n",
      "Epoch: 73\n",
      "train loss:  122.54709242284298\n",
      "train accuracy:  0.89284\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  41.11251623928547\n",
      "test accuracy:  0.833\n",
      "\n",
      "Epoch: 74\n",
      "train loss:  123.44721339643002\n",
      "train accuracy:  0.89264\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  51.55568253993988\n",
      "test accuracy:  0.795\n",
      "\n",
      "Epoch: 75\n",
      "train loss:  122.11470399796963\n",
      "train accuracy:  0.89532\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  34.18717010319233\n",
      "test accuracy:  0.8589\n",
      "\n",
      "Epoch: 76\n",
      "train loss:  124.3127896040678\n",
      "train accuracy:  0.89074\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  38.41443428397179\n",
      "test accuracy:  0.8486\n",
      "\n",
      "Epoch: 77\n",
      "train loss:  123.73439612984657\n",
      "train accuracy:  0.89322\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  47.65768218040466\n",
      "test accuracy:  0.8119\n",
      "\n",
      "Epoch: 78\n",
      "train loss:  124.70093896985054\n",
      "train accuracy:  0.89296\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  33.44276091456413\n",
      "test accuracy:  0.8606\n",
      "\n",
      "Epoch: 79\n",
      "train loss:  123.51611234247684\n",
      "train accuracy:  0.89284\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  33.865646585822105\n",
      "test accuracy:  0.8614\n",
      "\n",
      "Epoch: 80\n",
      "train loss:  123.34372460842133\n",
      "train accuracy:  0.89232\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  32.96172861754894\n",
      "test accuracy:  0.8621\n",
      "\n",
      "Epoch: 81\n",
      "train loss:  123.14206792414188\n",
      "train accuracy:  0.89218\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  37.05760796368122\n",
      "test accuracy:  0.8478\n",
      "\n",
      "Epoch: 82\n",
      "train loss:  123.23704624176025\n",
      "train accuracy:  0.89362\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  34.56888383626938\n",
      "test accuracy:  0.8583\n",
      "\n",
      "Epoch: 83\n",
      "train loss:  120.30962146818638\n",
      "train accuracy:  0.89514\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  38.92856612801552\n",
      "test accuracy:  0.8444\n",
      "\n",
      "Epoch: 84\n",
      "train loss:  121.38914363086224\n",
      "train accuracy:  0.89372\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  42.21257546544075\n",
      "test accuracy:  0.827\n",
      "\n",
      "Epoch: 85\n",
      "train loss:  124.09156781435013\n",
      "train accuracy:  0.89134\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  48.1381661593914\n",
      "test accuracy:  0.805\n",
      "\n",
      "Epoch: 86\n",
      "train loss:  121.38891267776489\n",
      "train accuracy:  0.89384\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  34.41749259829521\n",
      "test accuracy:  0.8517\n",
      "\n",
      "Epoch: 87\n",
      "train loss:  122.51606731116772\n",
      "train accuracy:  0.89402\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  39.64670595526695\n",
      "test accuracy:  0.834\n",
      "\n",
      "Epoch: 88\n",
      "train loss:  122.28628487884998\n",
      "train accuracy:  0.89328\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  35.82737398147583\n",
      "test accuracy:  0.8508\n",
      "\n",
      "Epoch: 89\n",
      "train loss:  121.77689197659492\n",
      "train accuracy:  0.8952\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  38.2955267727375\n",
      "test accuracy:  0.8359\n",
      "\n",
      "Epoch: 90\n",
      "train loss:  120.12506780028343\n",
      "train accuracy:  0.8957\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  41.57454112172127\n",
      "test accuracy:  0.838\n",
      "\n",
      "Epoch: 91\n",
      "train loss:  122.55477172136307\n",
      "train accuracy:  0.89186\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  48.07887741923332\n",
      "test accuracy:  0.8141\n",
      "\n",
      "Epoch: 92\n",
      "train loss:  123.19330462813377\n",
      "train accuracy:  0.8939\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  42.45193690061569\n",
      "test accuracy:  0.8239\n",
      "\n",
      "Epoch: 93\n",
      "train loss:  123.20244079083204\n",
      "train accuracy:  0.89228\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  57.01005759835243\n",
      "test accuracy:  0.7811\n",
      "\n",
      "Epoch: 94\n",
      "train loss:  120.80902194976807\n",
      "train accuracy:  0.89548\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  40.297576516866684\n",
      "test accuracy:  0.835\n",
      "\n",
      "Epoch: 95\n",
      "train loss:  122.37805946171284\n",
      "train accuracy:  0.8947\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  42.730422645807266\n",
      "test accuracy:  0.8403\n",
      "\n",
      "Epoch: 96\n",
      "train loss:  121.75622913241386\n",
      "train accuracy:  0.89418\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  35.229883909225464\n",
      "test accuracy:  0.8535\n",
      "\n",
      "Epoch: 97\n",
      "train loss:  120.1807487308979\n",
      "train accuracy:  0.89562\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  41.69107377529144\n",
      "test accuracy:  0.827\n",
      "\n",
      "Epoch: 98\n",
      "train loss:  120.14776457846165\n",
      "train accuracy:  0.89784\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  39.91659200191498\n",
      "test accuracy:  0.8403\n",
      "\n",
      "Epoch: 99\n",
      "train loss:  120.82390210032463\n",
      "train accuracy:  0.89606\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  32.494914054870605\n",
      "test accuracy:  0.8635\n",
      "current learning rate:  0.01\n",
      "\n",
      "Epoch: 100\n",
      "train loss:  61.349334325641394\n",
      "train accuracy:  0.94848\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.10549698024988\n",
      "test accuracy:  0.93\n",
      "\n",
      "Epoch: 101\n",
      "train loss:  44.32848037406802\n",
      "train accuracy:  0.96228\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.5003766939044\n",
      "test accuracy:  0.9343\n",
      "\n",
      "Epoch: 102\n",
      "train loss:  37.16154409572482\n",
      "train accuracy:  0.96808\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.071507774293423\n",
      "test accuracy:  0.9367\n",
      "\n",
      "Epoch: 103\n",
      "train loss:  33.534561133012176\n",
      "train accuracy:  0.9718\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.846535362303257\n",
      "test accuracy:  0.9371\n",
      "\n",
      "Epoch: 104\n",
      "train loss:  28.783265873789787\n",
      "train accuracy:  0.9755\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.972283259034157\n",
      "test accuracy:  0.9385\n",
      "\n",
      "Epoch: 105\n",
      "train loss:  25.213726734742522\n",
      "train accuracy:  0.97902\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.553701467812061\n",
      "test accuracy:  0.9382\n",
      "\n",
      "Epoch: 106\n",
      "train loss:  23.664048947393894\n",
      "train accuracy:  0.9804\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.614194419234991\n",
      "test accuracy:  0.9382\n",
      "\n",
      "Epoch: 107\n",
      "train loss:  20.94520557485521\n",
      "train accuracy:  0.98228\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.747869715094566\n",
      "test accuracy:  0.941\n",
      "\n",
      "Epoch: 108\n",
      "train loss:  18.586187476292253\n",
      "train accuracy:  0.98446\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.069321781396866\n",
      "test accuracy:  0.9412\n",
      "\n",
      "Epoch: 109\n",
      "train loss:  16.754956940189004\n",
      "train accuracy:  0.98668\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.606020897626877\n",
      "test accuracy:  0.9396\n",
      "\n",
      "Epoch: 110\n",
      "train loss:  15.097813226282597\n",
      "train accuracy:  0.9876\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.991343148052692\n",
      "test accuracy:  0.9394\n",
      "\n",
      "Epoch: 111\n",
      "train loss:  14.273585246875882\n",
      "train accuracy:  0.98838\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.387723356485367\n",
      "test accuracy:  0.9384\n",
      "\n",
      "Epoch: 112\n",
      "train loss:  13.524568466469646\n",
      "train accuracy:  0.98876\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.361480813473463\n",
      "test accuracy:  0.9393\n",
      "\n",
      "Epoch: 113\n",
      "train loss:  13.323612380772829\n",
      "train accuracy:  0.98916\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.913666643202305\n",
      "test accuracy:  0.9379\n",
      "\n",
      "Epoch: 114\n",
      "train loss:  12.709349062293768\n",
      "train accuracy:  0.98982\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.769863311201334\n",
      "test accuracy:  0.9416\n",
      "\n",
      "Epoch: 115\n",
      "train loss:  12.078413894865662\n",
      "train accuracy:  0.99074\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.625911064445972\n",
      "test accuracy:  0.9422\n",
      "\n",
      "Epoch: 116\n",
      "train loss:  11.17544017918408\n",
      "train accuracy:  0.99128\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.014662254601717\n",
      "test accuracy:  0.9428\n",
      "\n",
      "Epoch: 117\n",
      "train loss:  11.525497451424599\n",
      "train accuracy:  0.99022\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.879473716020584\n",
      "test accuracy:  0.9382\n",
      "\n",
      "Epoch: 118\n",
      "train loss:  10.941809835843742\n",
      "train accuracy:  0.99098\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  17.50831238925457\n",
      "test accuracy:  0.9374\n",
      "\n",
      "Epoch: 119\n",
      "train loss:  11.665975792333484\n",
      "train accuracy:  0.99006\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  17.687326174229383\n",
      "test accuracy:  0.937\n",
      "\n",
      "Epoch: 120\n",
      "train loss:  11.440286312252283\n",
      "train accuracy:  0.99074\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  16.630833350121975\n",
      "test accuracy:  0.9397\n",
      "\n",
      "Epoch: 121\n",
      "train loss:  10.910836528521031\n",
      "train accuracy:  0.99124\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  17.42519834637642\n",
      "test accuracy:  0.9348\n",
      "\n",
      "Epoch: 122\n",
      "train loss:  11.034604473039508\n",
      "train accuracy:  0.99138\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  17.680683985352516\n",
      "test accuracy:  0.9366\n",
      "\n",
      "Epoch: 123\n",
      "train loss:  10.973135698586702\n",
      "train accuracy:  0.99116\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  19.317936204373837\n",
      "test accuracy:  0.9335\n",
      "\n",
      "Epoch: 124\n",
      "train loss:  11.952809168025851\n",
      "train accuracy:  0.99066\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  17.668788366019726\n",
      "test accuracy:  0.936\n",
      "\n",
      "Epoch: 125\n",
      "train loss:  12.201952630653977\n",
      "train accuracy:  0.99002\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  17.64321655035019\n",
      "test accuracy:  0.9387\n",
      "\n",
      "Epoch: 126\n",
      "train loss:  11.773167433217168\n",
      "train accuracy:  0.99054\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  17.229718551039696\n",
      "test accuracy:  0.939\n",
      "\n",
      "Epoch: 127\n",
      "train loss:  13.039770619943738\n",
      "train accuracy:  0.98926\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.04798435419798\n",
      "test accuracy:  0.9355\n",
      "\n",
      "Epoch: 128\n",
      "train loss:  13.257035195827484\n",
      "train accuracy:  0.98888\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.35753270238638\n",
      "test accuracy:  0.9335\n",
      "\n",
      "Epoch: 129\n",
      "train loss:  12.705395004712045\n",
      "train accuracy:  0.98962\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  19.055307872593403\n",
      "test accuracy:  0.9329\n",
      "\n",
      "Epoch: 130\n",
      "train loss:  13.875165792182088\n",
      "train accuracy:  0.9886\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  20.791426330804825\n",
      "test accuracy:  0.9265\n",
      "\n",
      "Epoch: 131\n",
      "train loss:  14.064900262281299\n",
      "train accuracy:  0.98814\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.90718848258257\n",
      "test accuracy:  0.9344\n",
      "\n",
      "Epoch: 132\n",
      "train loss:  13.726078379899263\n",
      "train accuracy:  0.9887\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.28759916126728\n",
      "test accuracy:  0.934\n",
      "\n",
      "Epoch: 133\n",
      "train loss:  14.9255265686661\n",
      "train accuracy:  0.98814\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  19.12991762906313\n",
      "test accuracy:  0.933\n",
      "\n",
      "Epoch: 134\n",
      "train loss:  15.226374954916537\n",
      "train accuracy:  0.98764\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.12367895618081\n",
      "test accuracy:  0.9336\n",
      "\n",
      "Epoch: 135\n",
      "train loss:  15.411056969314814\n",
      "train accuracy:  0.98764\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  18.421259358525276\n",
      "test accuracy:  0.9336\n",
      "\n",
      "Epoch: 136\n",
      "train loss:  14.091615611687303\n",
      "train accuracy:  0.98822\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  19.701183527708054\n",
      "test accuracy:  0.9308\n",
      "\n",
      "Epoch: 137\n",
      "train loss:  14.39684684202075\n",
      "train accuracy:  0.98792\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  21.733436804264784\n",
      "test accuracy:  0.9246\n",
      "\n",
      "Epoch: 138\n",
      "train loss:  15.736638898029923\n",
      "train accuracy:  0.98658\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  21.140920594334602\n",
      "test accuracy:  0.926\n",
      "\n",
      "Epoch: 139\n",
      "train loss:  17.742181490175426\n",
      "train accuracy:  0.98486\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  20.893936417996883\n",
      "test accuracy:  0.9284\n",
      "\n",
      "Epoch: 140\n",
      "train loss:  17.07925470918417\n",
      "train accuracy:  0.98576\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  21.599358320236206\n",
      "test accuracy:  0.924\n",
      "\n",
      "Epoch: 141\n",
      "train loss:  16.533917035907507\n",
      "train accuracy:  0.98612\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  19.54582829028368\n",
      "test accuracy:  0.9302\n",
      "\n",
      "Epoch: 142\n",
      "train loss:  16.50765102915466\n",
      "train accuracy:  0.98614\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  22.48725739121437\n",
      "test accuracy:  0.9226\n",
      "\n",
      "Epoch: 143\n",
      "train loss:  17.018218003213406\n",
      "train accuracy:  0.98548\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  21.049215264618397\n",
      "test accuracy:  0.9288\n",
      "\n",
      "Epoch: 144\n",
      "train loss:  16.307280756998807\n",
      "train accuracy:  0.98688\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  22.466589733958244\n",
      "test accuracy:  0.9243\n",
      "\n",
      "Epoch: 145\n",
      "train loss:  18.24958943389356\n",
      "train accuracy:  0.9846\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  22.297752521932125\n",
      "test accuracy:  0.9194\n",
      "\n",
      "Epoch: 146\n",
      "train loss:  18.947516387328506\n",
      "train accuracy:  0.98366\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  20.402716904878616\n",
      "test accuracy:  0.9276\n",
      "\n",
      "Epoch: 147\n",
      "train loss:  14.604930270463228\n",
      "train accuracy:  0.98828\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  19.74571641534567\n",
      "test accuracy:  0.9305\n",
      "\n",
      "Epoch: 148\n",
      "train loss:  17.88129129447043\n",
      "train accuracy:  0.9849\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  20.26391365379095\n",
      "test accuracy:  0.9286\n",
      "\n",
      "Epoch: 149\n",
      "train loss:  16.20090276747942\n",
      "train accuracy:  0.98656\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  19.881090357899666\n",
      "test accuracy:  0.9269\n",
      "current learning rate:  0.001\n",
      "\n",
      "Epoch: 150\n",
      "train loss:  8.255671046674252\n",
      "train accuracy:  0.99378\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  15.213155088946223\n",
      "test accuracy:  0.9441\n",
      "\n",
      "Epoch: 151\n",
      "train loss:  4.6719651510939\n",
      "train accuracy:  0.99728\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.990675158798695\n",
      "test accuracy:  0.945\n",
      "\n",
      "Epoch: 152\n",
      "train loss:  3.928599538980052\n",
      "train accuracy:  0.9976\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.668473144993186\n",
      "test accuracy:  0.946\n",
      "\n",
      "Epoch: 153\n",
      "train loss:  2.936924636363983\n",
      "train accuracy:  0.99864\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.895030781626701\n",
      "test accuracy:  0.9471\n",
      "\n",
      "Epoch: 154\n",
      "train loss:  2.6367074153386056\n",
      "train accuracy:  0.99888\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.935681378468871\n",
      "test accuracy:  0.9468\n",
      "\n",
      "Epoch: 155\n",
      "train loss:  2.5348109318874776\n",
      "train accuracy:  0.99872\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.739518685266376\n",
      "test accuracy:  0.9471\n",
      "\n",
      "Epoch: 156\n",
      "train loss:  2.573485907865688\n",
      "train accuracy:  0.99862\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.883345682173967\n",
      "test accuracy:  0.9455\n",
      "\n",
      "Epoch: 157\n",
      "train loss:  2.1382817020639777\n",
      "train accuracy:  0.99904\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.712128188461065\n",
      "test accuracy:  0.948\n",
      "\n",
      "Epoch: 158\n",
      "train loss:  1.9366363869048655\n",
      "train accuracy:  0.99924\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.765070971101522\n",
      "test accuracy:  0.9478\n",
      "\n",
      "Epoch: 159\n",
      "train loss:  1.9460659581236541\n",
      "train accuracy:  0.99912\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.777390569448471\n",
      "test accuracy:  0.9488\n",
      "\n",
      "Epoch: 160\n",
      "train loss:  1.8045383128337562\n",
      "train accuracy:  0.99926\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.62475811317563\n",
      "test accuracy:  0.9484\n",
      "\n",
      "Epoch: 161\n",
      "train loss:  1.7041234958451241\n",
      "train accuracy:  0.99942\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.628744706511497\n",
      "test accuracy:  0.9472\n",
      "\n",
      "Epoch: 162\n",
      "train loss:  1.6935342233628035\n",
      "train accuracy:  0.99946\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.754031591117382\n",
      "test accuracy:  0.9487\n",
      "\n",
      "Epoch: 163\n",
      "train loss:  1.6404172461479902\n",
      "train accuracy:  0.99938\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.55603414401412\n",
      "test accuracy:  0.947\n",
      "\n",
      "Epoch: 164\n",
      "train loss:  1.4145917010027915\n",
      "train accuracy:  0.99952\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.550950516015291\n",
      "test accuracy:  0.9482\n",
      "\n",
      "Epoch: 165\n",
      "train loss:  1.4558881666744128\n",
      "train accuracy:  0.9996\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.394782174378633\n",
      "test accuracy:  0.9492\n",
      "\n",
      "Epoch: 166\n",
      "train loss:  1.4211574899964035\n",
      "train accuracy:  0.9996\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.527089238166809\n",
      "test accuracy:  0.9485\n",
      "\n",
      "Epoch: 167\n",
      "train loss:  1.4226410873234272\n",
      "train accuracy:  0.9995\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.36040062457323\n",
      "test accuracy:  0.9487\n",
      "\n",
      "Epoch: 168\n",
      "train loss:  1.3255708422511816\n",
      "train accuracy:  0.9996\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.483563613146544\n",
      "test accuracy:  0.9492\n",
      "\n",
      "Epoch: 169\n",
      "train loss:  1.361567810177803\n",
      "train accuracy:  0.99968\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.332212969660759\n",
      "test accuracy:  0.9497\n",
      "\n",
      "Epoch: 170\n",
      "train loss:  1.3264849357074127\n",
      "train accuracy:  0.99962\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.434215173125267\n",
      "test accuracy:  0.95\n",
      "\n",
      "Epoch: 171\n",
      "train loss:  1.2210456517059356\n",
      "train accuracy:  0.99964\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.415621429681778\n",
      "test accuracy:  0.9494\n",
      "\n",
      "Epoch: 172\n",
      "train loss:  1.1192775731906295\n",
      "train accuracy:  0.99984\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.476103775203228\n",
      "test accuracy:  0.9495\n",
      "\n",
      "Epoch: 173\n",
      "train loss:  1.1875050667440519\n",
      "train accuracy:  0.9997\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.550583451986313\n",
      "test accuracy:  0.9486\n",
      "\n",
      "Epoch: 174\n",
      "train loss:  1.097430492984131\n",
      "train accuracy:  0.99978\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.713017204776406\n",
      "test accuracy:  0.9483\n",
      "\n",
      "Epoch: 175\n",
      "train loss:  1.1598684582859278\n",
      "train accuracy:  0.99974\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.413454934954643\n",
      "test accuracy:  0.9503\n",
      "\n",
      "Epoch: 176\n",
      "train loss:  1.172973996726796\n",
      "train accuracy:  0.99972\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.533483184874058\n",
      "test accuracy:  0.9502\n",
      "\n",
      "Epoch: 177\n",
      "train loss:  1.0229623150080442\n",
      "train accuracy:  0.99982\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.474670084193349\n",
      "test accuracy:  0.9511\n",
      "\n",
      "Epoch: 178\n",
      "train loss:  1.0127416350878775\n",
      "train accuracy:  0.99982\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.495809778571129\n",
      "test accuracy:  0.9501\n",
      "\n",
      "Epoch: 179\n",
      "train loss:  1.036386426188983\n",
      "train accuracy:  0.99972\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.40502393990755\n",
      "test accuracy:  0.9512\n",
      "\n",
      "Epoch: 180\n",
      "train loss:  1.0955220710020512\n",
      "train accuracy:  0.9998\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.365157760679722\n",
      "test accuracy:  0.9506\n",
      "\n",
      "Epoch: 181\n",
      "train loss:  0.9870747555978596\n",
      "train accuracy:  0.99986\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.313655890524387\n",
      "test accuracy:  0.951\n",
      "\n",
      "Epoch: 182\n",
      "train loss:  0.978027731529437\n",
      "train accuracy:  0.99988\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.541754614561796\n",
      "test accuracy:  0.9512\n",
      "\n",
      "Epoch: 183\n",
      "train loss:  0.986536703305319\n",
      "train accuracy:  0.99984\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.37369342520833\n",
      "test accuracy:  0.9501\n",
      "\n",
      "Epoch: 184\n",
      "train loss:  1.1088573401793838\n",
      "train accuracy:  0.99972\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.543898168951273\n",
      "test accuracy:  0.9503\n",
      "\n",
      "Epoch: 185\n",
      "train loss:  0.9191442936426029\n",
      "train accuracy:  0.99984\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.344109125435352\n",
      "test accuracy:  0.95\n",
      "\n",
      "Epoch: 186\n",
      "train loss:  0.970949649810791\n",
      "train accuracy:  0.99984\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.421515684574842\n",
      "test accuracy:  0.9499\n",
      "\n",
      "Epoch: 187\n",
      "train loss:  0.9516784660518169\n",
      "train accuracy:  0.99986\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.243900332599878\n",
      "test accuracy:  0.9501\n",
      "\n",
      "Epoch: 188\n",
      "train loss:  0.9717207544017583\n",
      "train accuracy:  0.9998\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.272908385843039\n",
      "test accuracy:  0.9504\n",
      "\n",
      "Epoch: 189\n",
      "train loss:  0.9387066054623574\n",
      "train accuracy:  0.9999\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.427245631814003\n",
      "test accuracy:  0.9501\n",
      "\n",
      "Epoch: 190\n",
      "train loss:  0.9670266066677868\n",
      "train accuracy:  0.99984\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.265298459678888\n",
      "test accuracy:  0.9504\n",
      "\n",
      "Epoch: 191\n",
      "train loss:  0.8843993213959038\n",
      "train accuracy:  0.99992\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.189489770680666\n",
      "test accuracy:  0.9518\n",
      "\n",
      "Epoch: 192\n",
      "train loss:  0.8818266332382336\n",
      "train accuracy:  0.9999\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  14.173613011837006\n",
      "test accuracy:  0.9515\n",
      "\n",
      "Epoch: 193\n",
      "train loss:  0.9085032228613272\n",
      "train accuracy:  0.9999\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.273177791386843\n",
      "test accuracy:  0.9501\n",
      "\n",
      "Epoch: 194\n",
      "train loss:  0.8606634950265288\n",
      "train accuracy:  0.9999\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.270782131701708\n",
      "test accuracy:  0.9508\n",
      "\n",
      "Epoch: 195\n",
      "train loss:  0.7978313658386469\n",
      "train accuracy:  0.99994\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.186302624642849\n",
      "test accuracy:  0.9509\n",
      "\n",
      "Epoch: 196\n",
      "train loss:  0.8880569009343162\n",
      "train accuracy:  0.99988\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.195976741611958\n",
      "test accuracy:  0.9513\n",
      "\n",
      "Epoch: 197\n",
      "train loss:  0.8240347463870421\n",
      "train accuracy:  0.99994\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.257228247821331\n",
      "test accuracy:  0.9509\n",
      "\n",
      "Epoch: 198\n",
      "train loss:  0.8443641539197415\n",
      "train accuracy:  0.99988\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.233614452183247\n",
      "test accuracy:  0.9512\n",
      "\n",
      "Epoch: 199\n",
      "train loss:  0.8488566782325506\n",
      "train accuracy:  0.99992\n",
      "saving model at: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.27922461181879\n",
      "test accuracy:  0.9503\n"
     ]
    }
   ],
   "source": [
    "train_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from: weights/cifar10_resnet18_SGD.pth\n",
      "test loss:  14.27922461181879\n",
      "test accuracy:  0.9503\n"
     ]
    }
   ],
   "source": [
    "##### if you already have a trained model ##############\n",
    "CIFAR10_PATH = 'weights/cifar10_resnet18_SGD.pth'\n",
    "CIFAR10_model = ResNet18().to(device)\n",
    "print(\"loading model from: {}\".format(CIFAR10_PATH))\n",
    "CIFAR10_model.load_state_dict(torch.load(CIFAR10_PATH))#, map_location=torch.device('cpu')))\n",
    "#test the model\n",
    "test(CIFAR10_model, 0, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Diag_second_order(model, train_loader, var0 = 10, device='cpu'):\n",
    "\n",
    "    W = list(model.parameters())[-2]\n",
    "    b = list(model.parameters())[-1]\n",
    "    m, n = W.shape\n",
    "    print(\"n: {} inputs to linear layer with m: {} classes\".format(n, m))\n",
    "    lossfunc = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    tau = 1/var0\n",
    "\n",
    "    extend(lossfunc, debug=False)\n",
    "    extend(model.fc, debug=False)\n",
    "\n",
    "    with backpack(DiagHessian()):\n",
    "\n",
    "        max_len = len(train_loader)\n",
    "        weights_cov = torch.zeros(max_len, m, n, device=device)\n",
    "        biases_cov = torch.zeros(max_len, m, device=device)\n",
    "\n",
    "        for batch_idx, (x, y) in enumerate(train_loader):\n",
    "\n",
    "            if device == 'cuda':\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "\n",
    "            model.zero_grad()\n",
    "            lossfunc(model(x), y).backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Hessian of weight\n",
    "                W_ = W.diag_h\n",
    "                b_ = b.diag_h\n",
    "\n",
    "                #add_prior: since it will be flattened later we can just add the prior like that\n",
    "                W_ += tau * torch.ones(W_.size(), device=device)\n",
    "                b_ += tau * torch.ones(b_.size(), device=device)\n",
    "\n",
    "\n",
    "            weights_cov[batch_idx] = W_\n",
    "            biases_cov[batch_idx] = b_\n",
    "\n",
    "            print(\"Batch: {}/{}\".format(batch_idx, max_len))\n",
    "\n",
    "        print(len(weights_cov))\n",
    "        C_W = torch.mean(weights_cov, dim=0)\n",
    "        C_b = torch.mean(biases_cov, dim=0)\n",
    "\n",
    "    # Predictive distribution\n",
    "    with torch.no_grad():\n",
    "        M_W_post = W.t()\n",
    "        M_b_post = b\n",
    "\n",
    "        C_W_post = C_W\n",
    "        C_b_post = C_b\n",
    "        \n",
    "    print(\"M_W_post size: \", M_W_post.size())\n",
    "    print(\"M_b_post size: \", M_b_post.size())\n",
    "    print(\"C_W_post size: \", C_W_post.size())\n",
    "    print(\"C_b_post size: \", C_b_post.size())\n",
    "\n",
    "    return(M_W_post, M_b_post, C_W_post, C_b_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 512 inputs to linear layer with m: 10 classes\n",
      "Batch: 0/391\n",
      "Batch: 1/391\n",
      "Batch: 2/391\n",
      "Batch: 3/391\n",
      "Batch: 4/391\n",
      "Batch: 5/391\n",
      "Batch: 6/391\n",
      "Batch: 7/391\n",
      "Batch: 8/391\n",
      "Batch: 9/391\n",
      "Batch: 10/391\n",
      "Batch: 11/391\n",
      "Batch: 12/391\n",
      "Batch: 13/391\n",
      "Batch: 14/391\n",
      "Batch: 15/391\n",
      "Batch: 16/391\n",
      "Batch: 17/391\n",
      "Batch: 18/391\n",
      "Batch: 19/391\n",
      "Batch: 20/391\n",
      "Batch: 21/391\n",
      "Batch: 22/391\n",
      "Batch: 23/391\n",
      "Batch: 24/391\n",
      "Batch: 25/391\n",
      "Batch: 26/391\n",
      "Batch: 27/391\n",
      "Batch: 28/391\n",
      "Batch: 29/391\n",
      "Batch: 30/391\n",
      "Batch: 31/391\n",
      "Batch: 32/391\n",
      "Batch: 33/391\n",
      "Batch: 34/391\n",
      "Batch: 35/391\n",
      "Batch: 36/391\n",
      "Batch: 37/391\n",
      "Batch: 38/391\n",
      "Batch: 39/391\n",
      "Batch: 40/391\n",
      "Batch: 41/391\n",
      "Batch: 42/391\n",
      "Batch: 43/391\n",
      "Batch: 44/391\n",
      "Batch: 45/391\n",
      "Batch: 46/391\n",
      "Batch: 47/391\n",
      "Batch: 48/391\n",
      "Batch: 49/391\n",
      "Batch: 50/391\n",
      "Batch: 51/391\n",
      "Batch: 52/391\n",
      "Batch: 53/391\n",
      "Batch: 54/391\n",
      "Batch: 55/391\n",
      "Batch: 56/391\n",
      "Batch: 57/391\n",
      "Batch: 58/391\n",
      "Batch: 59/391\n",
      "Batch: 60/391\n",
      "Batch: 61/391\n",
      "Batch: 62/391\n",
      "Batch: 63/391\n",
      "Batch: 64/391\n",
      "Batch: 65/391\n",
      "Batch: 66/391\n",
      "Batch: 67/391\n",
      "Batch: 68/391\n",
      "Batch: 69/391\n",
      "Batch: 70/391\n",
      "Batch: 71/391\n",
      "Batch: 72/391\n",
      "Batch: 73/391\n",
      "Batch: 74/391\n",
      "Batch: 75/391\n",
      "Batch: 76/391\n",
      "Batch: 77/391\n",
      "Batch: 78/391\n",
      "Batch: 79/391\n",
      "Batch: 80/391\n",
      "Batch: 81/391\n",
      "Batch: 82/391\n",
      "Batch: 83/391\n",
      "Batch: 84/391\n",
      "Batch: 85/391\n",
      "Batch: 86/391\n",
      "Batch: 87/391\n",
      "Batch: 88/391\n",
      "Batch: 89/391\n",
      "Batch: 90/391\n",
      "Batch: 91/391\n",
      "Batch: 92/391\n",
      "Batch: 93/391\n",
      "Batch: 94/391\n",
      "Batch: 95/391\n",
      "Batch: 96/391\n",
      "Batch: 97/391\n",
      "Batch: 98/391\n",
      "Batch: 99/391\n",
      "Batch: 100/391\n",
      "Batch: 101/391\n",
      "Batch: 102/391\n",
      "Batch: 103/391\n",
      "Batch: 104/391\n",
      "Batch: 105/391\n",
      "Batch: 106/391\n",
      "Batch: 107/391\n",
      "Batch: 108/391\n",
      "Batch: 109/391\n",
      "Batch: 110/391\n",
      "Batch: 111/391\n",
      "Batch: 112/391\n",
      "Batch: 113/391\n",
      "Batch: 114/391\n",
      "Batch: 115/391\n",
      "Batch: 116/391\n",
      "Batch: 117/391\n",
      "Batch: 118/391\n",
      "Batch: 119/391\n",
      "Batch: 120/391\n",
      "Batch: 121/391\n",
      "Batch: 122/391\n",
      "Batch: 123/391\n",
      "Batch: 124/391\n",
      "Batch: 125/391\n",
      "Batch: 126/391\n",
      "Batch: 127/391\n",
      "Batch: 128/391\n",
      "Batch: 129/391\n",
      "Batch: 130/391\n",
      "Batch: 131/391\n",
      "Batch: 132/391\n",
      "Batch: 133/391\n",
      "Batch: 134/391\n",
      "Batch: 135/391\n",
      "Batch: 136/391\n",
      "Batch: 137/391\n",
      "Batch: 138/391\n",
      "Batch: 139/391\n",
      "Batch: 140/391\n",
      "Batch: 141/391\n",
      "Batch: 142/391\n",
      "Batch: 143/391\n",
      "Batch: 144/391\n",
      "Batch: 145/391\n",
      "Batch: 146/391\n",
      "Batch: 147/391\n",
      "Batch: 148/391\n",
      "Batch: 149/391\n",
      "Batch: 150/391\n",
      "Batch: 151/391\n",
      "Batch: 152/391\n",
      "Batch: 153/391\n",
      "Batch: 154/391\n",
      "Batch: 155/391\n",
      "Batch: 156/391\n",
      "Batch: 157/391\n",
      "Batch: 158/391\n",
      "Batch: 159/391\n",
      "Batch: 160/391\n",
      "Batch: 161/391\n",
      "Batch: 162/391\n",
      "Batch: 163/391\n",
      "Batch: 164/391\n",
      "Batch: 165/391\n",
      "Batch: 166/391\n",
      "Batch: 167/391\n",
      "Batch: 168/391\n",
      "Batch: 169/391\n",
      "Batch: 170/391\n",
      "Batch: 171/391\n",
      "Batch: 172/391\n",
      "Batch: 173/391\n",
      "Batch: 174/391\n",
      "Batch: 175/391\n",
      "Batch: 176/391\n",
      "Batch: 177/391\n",
      "Batch: 178/391\n",
      "Batch: 179/391\n",
      "Batch: 180/391\n",
      "Batch: 181/391\n",
      "Batch: 182/391\n",
      "Batch: 183/391\n",
      "Batch: 184/391\n",
      "Batch: 185/391\n",
      "Batch: 186/391\n",
      "Batch: 187/391\n",
      "Batch: 188/391\n",
      "Batch: 189/391\n",
      "Batch: 190/391\n",
      "Batch: 191/391\n",
      "Batch: 192/391\n",
      "Batch: 193/391\n",
      "Batch: 194/391\n",
      "Batch: 195/391\n",
      "Batch: 196/391\n",
      "Batch: 197/391\n",
      "Batch: 198/391\n",
      "Batch: 199/391\n",
      "Batch: 200/391\n",
      "Batch: 201/391\n",
      "Batch: 202/391\n",
      "Batch: 203/391\n",
      "Batch: 204/391\n",
      "Batch: 205/391\n",
      "Batch: 206/391\n",
      "Batch: 207/391\n",
      "Batch: 208/391\n",
      "Batch: 209/391\n",
      "Batch: 210/391\n",
      "Batch: 211/391\n",
      "Batch: 212/391\n",
      "Batch: 213/391\n",
      "Batch: 214/391\n",
      "Batch: 215/391\n",
      "Batch: 216/391\n",
      "Batch: 217/391\n",
      "Batch: 218/391\n",
      "Batch: 219/391\n",
      "Batch: 220/391\n",
      "Batch: 221/391\n",
      "Batch: 222/391\n",
      "Batch: 223/391\n",
      "Batch: 224/391\n",
      "Batch: 225/391\n",
      "Batch: 226/391\n",
      "Batch: 227/391\n",
      "Batch: 228/391\n",
      "Batch: 229/391\n",
      "Batch: 230/391\n",
      "Batch: 231/391\n",
      "Batch: 232/391\n",
      "Batch: 233/391\n",
      "Batch: 234/391\n",
      "Batch: 235/391\n",
      "Batch: 236/391\n",
      "Batch: 237/391\n",
      "Batch: 238/391\n",
      "Batch: 239/391\n",
      "Batch: 240/391\n",
      "Batch: 241/391\n",
      "Batch: 242/391\n",
      "Batch: 243/391\n",
      "Batch: 244/391\n",
      "Batch: 245/391\n",
      "Batch: 246/391\n",
      "Batch: 247/391\n",
      "Batch: 248/391\n",
      "Batch: 249/391\n",
      "Batch: 250/391\n",
      "Batch: 251/391\n",
      "Batch: 252/391\n",
      "Batch: 253/391\n",
      "Batch: 254/391\n",
      "Batch: 255/391\n",
      "Batch: 256/391\n",
      "Batch: 257/391\n",
      "Batch: 258/391\n",
      "Batch: 259/391\n",
      "Batch: 260/391\n",
      "Batch: 261/391\n",
      "Batch: 262/391\n",
      "Batch: 263/391\n",
      "Batch: 264/391\n",
      "Batch: 265/391\n",
      "Batch: 266/391\n",
      "Batch: 267/391\n",
      "Batch: 268/391\n",
      "Batch: 269/391\n",
      "Batch: 270/391\n",
      "Batch: 271/391\n",
      "Batch: 272/391\n",
      "Batch: 273/391\n",
      "Batch: 274/391\n",
      "Batch: 275/391\n",
      "Batch: 276/391\n",
      "Batch: 277/391\n",
      "Batch: 278/391\n",
      "Batch: 279/391\n",
      "Batch: 280/391\n",
      "Batch: 281/391\n",
      "Batch: 282/391\n",
      "Batch: 283/391\n",
      "Batch: 284/391\n",
      "Batch: 285/391\n",
      "Batch: 286/391\n",
      "Batch: 287/391\n",
      "Batch: 288/391\n",
      "Batch: 289/391\n",
      "Batch: 290/391\n",
      "Batch: 291/391\n",
      "Batch: 292/391\n",
      "Batch: 293/391\n",
      "Batch: 294/391\n",
      "Batch: 295/391\n",
      "Batch: 296/391\n",
      "Batch: 297/391\n",
      "Batch: 298/391\n",
      "Batch: 299/391\n",
      "Batch: 300/391\n",
      "Batch: 301/391\n",
      "Batch: 302/391\n",
      "Batch: 303/391\n",
      "Batch: 304/391\n",
      "Batch: 305/391\n",
      "Batch: 306/391\n",
      "Batch: 307/391\n",
      "Batch: 308/391\n",
      "Batch: 309/391\n",
      "Batch: 310/391\n",
      "Batch: 311/391\n",
      "Batch: 312/391\n",
      "Batch: 313/391\n",
      "Batch: 314/391\n",
      "Batch: 315/391\n",
      "Batch: 316/391\n",
      "Batch: 317/391\n",
      "Batch: 318/391\n",
      "Batch: 319/391\n",
      "Batch: 320/391\n",
      "Batch: 321/391\n",
      "Batch: 322/391\n",
      "Batch: 323/391\n",
      "Batch: 324/391\n",
      "Batch: 325/391\n",
      "Batch: 326/391\n",
      "Batch: 327/391\n",
      "Batch: 328/391\n",
      "Batch: 329/391\n",
      "Batch: 330/391\n",
      "Batch: 331/391\n",
      "Batch: 332/391\n",
      "Batch: 333/391\n",
      "Batch: 334/391\n",
      "Batch: 335/391\n",
      "Batch: 336/391\n",
      "Batch: 337/391\n",
      "Batch: 338/391\n",
      "Batch: 339/391\n",
      "Batch: 340/391\n",
      "Batch: 341/391\n",
      "Batch: 342/391\n",
      "Batch: 343/391\n",
      "Batch: 344/391\n",
      "Batch: 345/391\n",
      "Batch: 346/391\n",
      "Batch: 347/391\n",
      "Batch: 348/391\n",
      "Batch: 349/391\n",
      "Batch: 350/391\n",
      "Batch: 351/391\n",
      "Batch: 352/391\n",
      "Batch: 353/391\n",
      "Batch: 354/391\n",
      "Batch: 355/391\n",
      "Batch: 356/391\n",
      "Batch: 357/391\n",
      "Batch: 358/391\n",
      "Batch: 359/391\n",
      "Batch: 360/391\n",
      "Batch: 361/391\n",
      "Batch: 362/391\n",
      "Batch: 363/391\n",
      "Batch: 364/391\n",
      "Batch: 365/391\n",
      "Batch: 366/391\n",
      "Batch: 367/391\n",
      "Batch: 368/391\n",
      "Batch: 369/391\n",
      "Batch: 370/391\n",
      "Batch: 371/391\n",
      "Batch: 372/391\n",
      "Batch: 373/391\n",
      "Batch: 374/391\n",
      "Batch: 375/391\n",
      "Batch: 376/391\n",
      "Batch: 377/391\n",
      "Batch: 378/391\n",
      "Batch: 379/391\n",
      "Batch: 380/391\n",
      "Batch: 381/391\n",
      "Batch: 382/391\n",
      "Batch: 383/391\n",
      "Batch: 384/391\n",
      "Batch: 385/391\n",
      "Batch: 386/391\n",
      "Batch: 387/391\n",
      "Batch: 388/391\n",
      "Batch: 389/391\n",
      "Batch: 390/391\n",
      "391\n",
      "M_W_post size:  torch.Size([512, 10])\n",
      "M_b_post size:  torch.Size([10])\n",
      "C_W_post size:  torch.Size([10, 512])\n",
      "C_b_post size:  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D = Diag_second_order(model=CIFAR10_model,\n",
    "                                                               train_loader=trainloader,\n",
    "                                                               var0 = 10,\n",
    "                                                               device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_in_dist_values(py_in, targets):\n",
    "    acc_in = np.mean(np.argmax(py_in, 1) == targets)\n",
    "    #prob_correct = np.choose(targets, py_in.T).mean()\n",
    "    prob_correct = py_in[targets].mean()\n",
    "    average_entropy = -np.sum(py_in*np.log(py_in+1e-8), axis=1).mean()\n",
    "    MMC = py_in.max(1).mean()\n",
    "    return(acc_in, prob_correct, average_entropy, MMC)\n",
    "\n",
    "def get_out_dist_values(py_in, py_out, targets):\n",
    "    average_entropy = -np.sum(py_out*np.log(py_out+1e-8), axis=1).mean()\n",
    "    acc_out = np.mean(np.argmax(py_out, 1) == targets)\n",
    "    if max(targets) > len(py_in[0]):\n",
    "        targets = np.array(targets)\n",
    "        targets[targets >= len(py_in[0])] = 0\n",
    "    #prob_correct = np.choose(targets, py_out.T).mean()\n",
    "    prob_correct = py_out[targets].mean()\n",
    "    labels = np.zeros(len(py_in)+len(py_out), dtype='int32')\n",
    "    labels[:len(py_in)] = 1\n",
    "    examples = np.concatenate([py_in.max(1), py_out.max(1)])\n",
    "    auroc = roc_auc_score(labels, examples)\n",
    "    MMC = py_out.max(1).mean()\n",
    "    return(acc_out, prob_correct, average_entropy, MMC, auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Gaussian_output_old(x, mu_w, mu_b, sigma_w, sigma_b):\n",
    "    #get the distributions per class\n",
    "    batch_size = x.size(0)\n",
    "    num_classes = len(mu_b)\n",
    "    #print(\"batch_size, num_classes: \", batch_size, num_classes)\n",
    "    mu_batch = torch.zeros(batch_size, num_classes)\n",
    "    sigma_batch = torch.zeros(batch_size, num_classes, num_classes)\n",
    "    for i in range(batch_size):\n",
    "        per_class_sigmas = torch.zeros(num_classes)\n",
    "        for j in range(num_classes):\n",
    "            #create a diagonal Hessian\n",
    "            hess = torch.diag(sigma_w[j])\n",
    "            #b = x[i] @ hess @ x[i].t()\n",
    "            #a = sigma_b[i]\n",
    "            per_class_sigmas[j] = x[i] @ hess @ x[i].t() + sigma_b[j]\n",
    "\n",
    "        #print(\"sizes: \", mu_w.size(), x[i].size(), mu_b.size())\n",
    "        per_class_mus = x[i] @ mu_w + mu_b\n",
    "        mu_batch[i] = per_class_mus\n",
    "        sigma_batch[i] = torch.diag(per_class_sigmas)\n",
    "\n",
    "    return(mu_batch, sigma_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Gaussian_output(x, mu_w, mu_b, sigma_w, sigma_b):\n",
    "    #get the distributions per class\n",
    "    batch_size = x.size(0)\n",
    "    num_classes = mu_b.size(0)\n",
    "    \n",
    "    # get mu batch\n",
    "    mu_w_batch = mu_w.repeat(batch_size, 1, 1)\n",
    "    mu_b_batch = mu_b.repeat(batch_size, 1)\n",
    "    mu_batch = torch.bmm(x.view(batch_size, 1, -1), mu_w_batch).view(batch_size, -1) + mu_b_batch\n",
    "    \n",
    "    #get sigma batch\n",
    "    sigma_w_batch = sigma_w.repeat(batch_size, 1, 1)\n",
    "    sigma_b_batch = sigma_b.repeat(batch_size, 1)\n",
    "    sigmas_diag = torch.zeros(batch_size, num_classes, device='cuda')\n",
    "    for j in range(num_classes):\n",
    "        h1 = x * sigma_w_batch[:, j]\n",
    "        helper = torch.matmul(h1.view(batch_size, 1, -1), x.view(batch_size, -1, 1))\n",
    "        helper = helper.view(-1) + sigma_b_batch[:,j]\n",
    "        sigmas_diag[:,j] = helper\n",
    "        \n",
    "    sigma_batch = torch.stack([torch.diag(x) for x in sigmas_diag])\n",
    "\n",
    "    \n",
    "    return(mu_batch, sigma_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_diagonal_sampling(model, test_loader, M_W_post, M_b_post, C_W_post, C_b_post, n_samples, verbose=False, cuda=False, timing=False):\n",
    "    py = []\n",
    "    max_len = len(test_loader)\n",
    "    if timing:\n",
    "        time_sum = 0\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(test_loader):\n",
    "\n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        phi = model.phi(x)\n",
    "\n",
    "        mu, Sigma = get_Gaussian_output(phi, M_W_post, M_b_post, C_W_post, C_b_post)\n",
    "        #print(\"mu size: \", mu.size())\n",
    "        #print(\"sigma size: \", Sigma.size())\n",
    "\n",
    "        post_pred = MultivariateNormal(mu, Sigma)\n",
    "\n",
    "        # MC-integral\n",
    "        t0 = time.time()\n",
    "        py_ = 0\n",
    "\n",
    "        for _ in range(n_samples):\n",
    "            f_s = post_pred.rsample()\n",
    "            py_ += torch.softmax(f_s, 1)\n",
    "\n",
    "        py_ /= n_samples\n",
    "        py_ = py_.detach()\n",
    "\n",
    "        py.append(py_)\n",
    "        t1 = time.time()\n",
    "        if timing:\n",
    "            time_sum += (t1 - t0)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Batch: {}/{}\".format(batch_idx, max_len))\n",
    "\n",
    "    if timing: print(\"time used for sampling with {} samples: {}\".format(n_samples, time_sum))\n",
    "    \n",
    "    return torch.cat(py, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_CIFAR10 = testset.targets\n",
    "targets_CIFAR100 = CIFAR100_test.targets\n",
    "targets_SVHN = []\n",
    "for x,y in test_loader_SVHN:\n",
    "    targets_SVHN.append(y)\n",
    "targets_SVHN = torch.cat(targets_SVHN).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_test_in_MAP = predict_MAP(CIFAR10_model, testloader, cuda=True).cpu().numpy()\n",
    "CIFAR10_test_out_CIFAR100_MAP = predict_MAP(CIFAR10_model, CIFAR100_test_loader, cuda=True).cpu().numpy()\n",
    "CIFAR10_test_out_SVHN_MAP = predict_MAP(CIFAR10_model, test_loader_SVHN, cuda=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP = get_in_dist_values(CIFAR10_test_in_MAP, targets_CIFAR10)\n",
    "acc_out_CIFAR100_MAP, prob_correct_out_CIFAR100_MAP, ent_out_CIFAR100, MMC_out_CIFAR100_MAP, auroc_out_CIFAR100_MAP = get_out_dist_values(CIFAR10_test_in_MAP, CIFAR10_test_out_CIFAR100_MAP, targets_CIFAR100)\n",
    "acc_out_SVHN_MAP, prob_correct_out_SVHN_MAP, ent_out_SVHN, MMC_out_SVHN_MAP, auroc_out_SVHN_MAP = get_out_dist_values(CIFAR10_test_in_MAP, CIFAR10_test_out_SVHN_MAP, targets_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, MAP, CIFAR10] Accuracy: 0.950; average entropy: 0.072;     MMC: 0.976; Prob @ correct: 0.100\n",
      "[Out-MAP, KFAC, CIFAR100] Accuracy: 0.010; Average entropy: 0.498;    MMC: 0.827; AUROC: 0.864; Prob @ correct: 0.100\n",
      "[Out-MAP, KFAC, SVHN] Accuracy: 0.103; Average entropy: 0.637;    MMC: 0.784; AUROC: 0.917; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP, 'CIFAR10', 'MAP')\n",
    "print_out_dist_values(acc_out_CIFAR100_MAP, prob_correct_out_CIFAR100_MAP, ent_out_CIFAR100, MMC_out_CIFAR100_MAP, auroc_out_CIFAR100_MAP, 'CIFAR100', 'MAP')\n",
    "print_out_dist_values(acc_out_SVHN_MAP, prob_correct_out_SVHN_MAP, ent_out_SVHN, MMC_out_SVHN_MAP, auroc_out_SVHN_MAP, 'SVHN', 'MAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.952 with std 0.001\n",
      "MMC in: 0.978 with std 0.001\n",
      "MMC out CIFAR100: 0.829 with std 0.002\n",
      "MMC out SVHN: 0.774 with std 0.032\n",
      "AUROC out CIFAR100: 0.872 with std 0.005\n",
      "AUROC out SVHN: 0.925 with std 0.009\n"
     ]
    }
   ],
   "source": [
    "#MAP estimate\n",
    "#seeds are 123,124,125,126,127\n",
    "acc_in = [0.953, 0.952, 0.952, 0.950]\n",
    "mmc_in = [0.979, 0.978, 0.979, 0.976]\n",
    "mmc_out_CIFAR100 = [0.831, 0.827, 0.829, 0.827]\n",
    "mmc_out_SVHN = [0.721, 0.809, 0.780, 0.784]\n",
    "\n",
    "auroc_out_CIFAR100 = [0.872, 0.877, 0.874, 0.864]\n",
    "auroc_out_SVHN = [0.939, 0.919, 0.927, 0.917]\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagonal estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used for sampling with 1000 samples: 6.605843544006348\n",
      "time used for sampling with 1000 samples: 6.474161148071289\n",
      "time used for sampling with 1000 samples: 16.71169662475586\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_test_in_D = predict_diagonal_sampling(CIFAR10_model, testloader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, n_samples=1000, cuda=True, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_CIFAR100_D = predict_diagonal_sampling(CIFAR10_model, CIFAR100_test_loader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, n_samples=1000, cuda=True, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_SVHN_D = predict_diagonal_sampling(CIFAR10_model, test_loader_SVHN, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, n_samples=1000, cuda=True, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D = get_in_dist_values(CIFAR10_test_in_D, targets_CIFAR10)\n",
    "acc_out_CIFAR100_D, prob_correct_out_CIFAR100_D, ent_out_CIFAR100_D, MMC_out_CIFAR100_D, auroc_out_CIFAR100_D = get_out_dist_values(CIFAR10_test_in_D, CIFAR10_test_out_CIFAR100_D, targets_CIFAR100)\n",
    "acc_out_SVHN_D, prob_correct_out_SVHN_D, ent_out_SVHN_D, MMC_out_SVHN_D, auroc_out_SVHN_D = get_out_dist_values(CIFAR10_test_in_D, CIFAR10_test_out_SVHN_D, targets_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, Diag, CIFAR10] Accuracy: 0.950; average entropy: 0.200;     MMC: 0.947; Prob @ correct: 0.100\n",
      "[Out-Diag, KFAC, CIFAR100] Accuracy: 0.010; Average entropy: 0.498;    MMC: 0.724; AUROC: 0.876; Prob @ correct: 0.100\n",
      "[Out-Diag, KFAC, SVHN] Accuracy: 0.103; Average entropy: 0.979;    MMC: 0.672; AUROC: 0.921; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D, 'CIFAR10', 'Diag')\n",
    "print_out_dist_values(acc_out_CIFAR100_D, prob_correct_out_CIFAR100_D, ent_out_CIFAR100, MMC_out_CIFAR100_D, auroc_out_CIFAR100_D, 'CIFAR100', 'Diag')\n",
    "print_out_dist_values(acc_out_SVHN_D, prob_correct_out_SVHN_D, ent_out_SVHN_D, MMC_out_SVHN_D, auroc_out_SVHN_D, 'SVHN', 'Diag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Bridge time in: 6.633 with std 0.053\n",
      "Sampling Bridge time out CIFAR100: 6.566 with std 0.057\n",
      "Sampling Bridge time out SVHN: 16.962 with std 0.148\n",
      "accuracy: 0.952 with std 0.001\n",
      "MMC in: 0.949 with std 0.001\n",
      "MMC out CIFAR100: 0.724 with std 0.002\n",
      "MMC out SVHN: 0.656 with std 0.031\n",
      "AUROC out CIFAR100: 0.884 with std 0.005\n",
      "AUROC out SVHN: 0.931 with std 0.008\n"
     ]
    }
   ],
   "source": [
    "#Diag Sampling\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [6.636955976486206, 6.716174125671387, 6.57476282119751, 6.605843544006348]\n",
    "time_lpb_out_CIFAR100 = [6.614115238189697, 6.61441969871521, 6.560410737991333, 6.474161148071289]\n",
    "time_lpb_out_SVHN = [17.011831521987915, 17.094997882843018, 17.031347036361694,16.71169662475586]\n",
    "\n",
    "acc_in = [0.953, 0.952, 0.952, 0.950]\n",
    "mmc_in = [0.950, 0.950, 0.950, 0.947]\n",
    "mmc_out_CIFAR100 = [0.727, 0.721, 0.725, 0.724]\n",
    "mmc_out_SVHN = [0.605, 0.685, 0.661, 0.672]\n",
    "\n",
    "auroc_out_CIFAR100 = [0.884, 0.889, 0.885, 0.876]\n",
    "auroc_out_SVHN = [0.943, 0.927, 0.933, 0.921]\n",
    "\n",
    "print(\"Sampling Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Sampling Bridge time out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR100), np.std(time_lpb_out_CIFAR100)))\n",
    "print(\"Sampling Bridge time out SVHN: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_SVHN), np.std(time_lpb_out_SVHN)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet Laplace estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha_from_Normal(mu, Sigma):\n",
    "    batch_size, K = mu.size(0), mu.size(-1)\n",
    "    Sigma_d = torch.diagonal(Sigma, dim1=1, dim2=2)\n",
    "    sum_exp = torch.sum(torch.exp(-1*mu), dim=1).view(-1,1)\n",
    "    alpha = 1/Sigma_d * (1 - 2/K + torch.exp(mu)/K**2 * sum_exp)\n",
    "    \n",
    "    return(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "#U_post, V_post, B_post\n",
    "def predict_DIR_LPA(model, test_loader, M_W_post, M_b_post, C_W_post, C_b_post, verbose=False, cuda=False, timing=False):\n",
    "    alphas = []\n",
    "    if timing:\n",
    "        time_sum = 0\n",
    "\n",
    "    max_len = int(np.ceil(len(test_loader.dataset)/len(test_loader)))\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(test_loader):\n",
    "        \n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        phi = model.phi(x)\n",
    "\n",
    "        #mu_pred = phi @ M_W_post + M_b_post\n",
    "        #mu_pred -= mu_pred.mean(1).view(-1,1)\n",
    "        #Cov_pred = torch.diag(phi @ U_post @ phi.t()).reshape(-1, 1, 1) * V_post.unsqueeze(0) + B_post.unsqueeze(0)\n",
    "\n",
    "        mu_pred, Cov_pred = get_Gaussian_output(phi, M_W_post, M_b_post, C_W_post, C_b_post)\n",
    "        \n",
    "        t0 = time.time()\n",
    "        alpha = get_alpha_from_Normal(mu_pred, Cov_pred).detach()\n",
    "        t1 = time.time()\n",
    "        if timing:\n",
    "            time_sum += (t1-t0)\n",
    "\n",
    "        alphas.append(alpha)\n",
    "\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Batch: {}/{}\".format(batch_idx, max_len))\n",
    "\n",
    "    if timing:\n",
    "        print(\"total time used for transform: {:.05f}\".format(time_sum))\n",
    "    \n",
    "    return(torch.cat(alphas, dim = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used for transform: 0.01724\n",
      "total time used for transform: 0.01580\n",
      "total time used for transform: 0.04067\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_test_in_DIR_LPA = predict_DIR_LPA(CIFAR10_model, testloader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, cuda=True, verbose=False, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_CIFAR100_DIR_LPA = predict_DIR_LPA(CIFAR10_model, CIFAR100_test_loader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, cuda=True, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_SVHN_DIR_LPA = predict_DIR_LPA(CIFAR10_model, test_loader_SVHN, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, cuda=True, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize to get the MAP estimate (which is the mode) of the Dirichlet\n",
    "CIFAR10_test_in_DIR_LPAn = CIFAR10_test_in_DIR_LPA/CIFAR10_test_in_DIR_LPA.sum(1).reshape(-1,1)\n",
    "CIFAR10_test_out_CIFAR100_DIR_LPAn = CIFAR10_test_out_CIFAR100_DIR_LPA/CIFAR10_test_out_CIFAR100_DIR_LPA.sum(1).reshape(-1,1)\n",
    "CIFAR10_test_out_SVHN_DIR_LPAn = CIFAR10_test_out_SVHN_DIR_LPA/CIFAR10_test_out_SVHN_DIR_LPA.sum(1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_DIR_LPA, prob_correct_in_DIR_LPA, ent_in_DIR_LPA, MMC_in_DIR_LPA = get_in_dist_values(CIFAR10_test_in_DIR_LPAn, targets_CIFAR10)\n",
    "acc_out_CIFAR100_DIR_LPA, prob_correct_out_CIFAR100_DIR_LPA, ent_out_CIFAR100_DIR_LPA, MMC_out_CIFAR100_DIR_LPA, auroc_out_CIFAR100_DIR_LPA = get_out_dist_values(CIFAR10_test_in_DIR_LPAn, CIFAR10_test_out_CIFAR100_DIR_LPAn, targets_CIFAR100)\n",
    "acc_out_SVHN_DIR_LPA, prob_correct_out_SVHN_DIR_LPA, ent_out_SVHN_DIR_LPA, MMC_out_SVHN_DIR_LPA, auroc_out_SVHN_DIR_LPA = get_out_dist_values(CIFAR10_test_in_DIR_LPAn, CIFAR10_test_out_SVHN_DIR_LPAn, targets_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, DIR_LPA, CIFAR10] Accuracy: 0.950; average entropy: 0.130;     MMC: 0.966; Prob @ correct: 0.100\n",
      "[Out-DIR_LPA, KFAC, CIFAR100] Accuracy: 0.010; Average entropy: 0.762;    MMC: 0.771; AUROC: 0.852; Prob @ correct: 0.100\n",
      "[Out-DIR_LPA, KFAC, SVHN] Accuracy: 0.103; Average entropy: 1.013;    MMC: 0.698; AUROC: 0.919; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_DIR_LPA, prob_correct_in_DIR_LPA, ent_in_DIR_LPA, MMC_in_DIR_LPA, 'CIFAR10', 'DIR_LPA')\n",
    "print_out_dist_values(acc_out_CIFAR100_DIR_LPA, prob_correct_out_CIFAR100_DIR_LPA, ent_out_CIFAR100_DIR_LPA, MMC_out_CIFAR100_DIR_LPA, auroc_out_CIFAR100_DIR_LPA, 'CIFAR100', 'DIR_LPA')\n",
    "print_out_dist_values(acc_out_SVHN_DIR_LPA, prob_correct_out_SVHN_DIR_LPA, ent_out_SVHN_DIR_LPA, MMC_out_SVHN_DIR_LPA, auroc_out_SVHN_DIR_LPA, 'SVHN', 'DIR_LPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplace Bridge time in: 0.017 with std 0.000\n",
      "Laplace Bridge time out CIFAR100: 0.016 with std 0.000\n",
      "Laplace Bridge time out notmnist: 0.041 with std 0.000\n",
      "accuracy: 0.952 with std 0.001\n",
      "MMC in: 0.969 with std 0.002\n",
      "MMC out CIFAR100: 0.775 with std 0.003\n",
      "MMC out SVHN: 0.701 with std 0.040\n",
      "AUROC out CIFAR100: 0.857 with std 0.004\n",
      "AUROC out SVHN: 0.922 with std 0.008\n"
     ]
    }
   ],
   "source": [
    "#Laplace Bridge\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [0.01729, 0.01750, 0.01749,0.01724]\n",
    "time_lpb_out_CIFAR100 = [0.01571,0.01601, 0.01570, 0.01580]\n",
    "time_lpb_out_SVHN = [0.04075, 0.04107, 0.04046, 0.04067]\n",
    "\n",
    "\n",
    "acc_in = [0.953, 0.952, 0.952, 0.950]\n",
    "mmc_in = [0.971, 0.970, 0.970, 0.966]\n",
    "mmc_out_CIFAR100 = [0.779, 0.774, 0.775, 0.771]\n",
    "mmc_out_SVHN = [0.639, 0.747, 0.719, 0.698]\n",
    "\n",
    "\n",
    "auroc_out_CIFAR100 = [0.856, 0.863, 0.859, 0.852]\n",
    "auroc_out_SVHN = [0.935, 0.912, 0.923, 0.919]\n",
    "\n",
    "\n",
    "print(\"Laplace Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Laplace Bridge time out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR100), np.std(time_lpb_out_CIFAR100)))\n",
    "print(\"Laplace Bridge time out notmnist: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_SVHN), np.std(time_lpb_out_SVHN)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import digamma, loggamma\n",
    "\n",
    "def beta_function(alpha):\n",
    "    return(np.exp(np.sum([loggamma(a_i) for a_i in alpha]) - loggamma(np.sum(alpha))))\n",
    "\n",
    "def alphas_norm(alphas):\n",
    "    alphas = np.array(alphas)\n",
    "    return(alphas/alphas.sum(axis=1).reshape(-1,1))\n",
    "\n",
    "def alphas_variance(alphas):\n",
    "    alphas = np.array(alphas)\n",
    "    norm = alphas_norm(alphas)\n",
    "    nom = norm * (1 - norm)\n",
    "    den = alphas.sum(axis=1).reshape(-1,1) + 1\n",
    "    return(nom/den)\n",
    "\n",
    "def log_beta_function(alpha):\n",
    "    return(np.sum([loggamma(a_i) for a_i in alpha]) - loggamma(np.sum(alpha)))\n",
    "\n",
    "def alphas_entropy(alphas):\n",
    "    K = len(alphas[0])\n",
    "    alphas = np.array(alphas)\n",
    "    entropy = []\n",
    "    for x in alphas:\n",
    "        B = log_beta_function(x)\n",
    "        alpha_0 = np.sum(x)\n",
    "        C = (alpha_0 - K)*digamma(alpha_0)\n",
    "        D = np.sum((x-1)*digamma(x))\n",
    "        entropy.append(B + C - D)\n",
    "    \n",
    "    return(np.array(entropy))\n",
    "        \n",
    "\n",
    "def alphas_log_prob(alphas):\n",
    "    alphas = np.array(alphas)\n",
    "    dig_sum = digamma(alphas.sum(axis=1).reshape(-1,1))\n",
    "    log_prob = digamma(alphas) - dig_sum\n",
    "    return(log_prob)\n",
    "\n",
    "def auroc_entropy(alphas_in, alphas_out):\n",
    "    \n",
    "    entropy_in = alphas_entropy(alphas_in)\n",
    "    entropy_out = alphas_entropy(alphas_out)\n",
    "    labels = np.zeros(len(entropy_in)+len(entropy_out), dtype='int32')\n",
    "    labels[:len(entropy_in)] = 1\n",
    "    examples = np.concatenate([entropy_in, entropy_out])\n",
    "    auroc_ent = roc_auc_score(labels, examples)\n",
    "    return(auroc_ent)\n",
    "\n",
    "def auroc_variance(alphas_in, alphas_out, method='mean'):\n",
    "    \n",
    "    if method=='mean':\n",
    "        variance_in = alphas_variance(alphas_in).mean(1)\n",
    "        variance_out = alphas_variance(alphas_out).mean(1)\n",
    "    elif method=='max':\n",
    "        variance_in = alphas_variance(alphas_in).max(1)\n",
    "        variance_out = alphas_variance(alphas_out).max(1)\n",
    "    labels = np.zeros(len(variance_in)+len(variance_out), dtype='int32')\n",
    "    labels[:len(variance_in)] = 1\n",
    "    examples = np.concatenate([variance_in, variance_out])\n",
    "    auroc_ent = roc_auc_score(labels, examples)\n",
    "    return(auroc_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc entropy: CIFAR10 in, CIFAR100 out:  0.8466216449999999\n",
      "auroc entropy: CIFAR10 in, SVHN out:  0.9289126920712969\n"
     ]
    }
   ],
   "source": [
    "print(\"auroc entropy: CIFAR10 in, CIFAR100 out: \", 1-auroc_entropy(alphas_in=CIFAR10_test_in_DIR_LPA, alphas_out=CIFAR10_test_out_CIFAR100_DIR_LPA))\n",
    "print(\"auroc entropy: CIFAR10 in, SVHN out: \", 1-auroc_entropy(alphas_in=CIFAR10_test_in_DIR_LPA, alphas_out=CIFAR10_test_out_SVHN_DIR_LPA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc variance: CIFAR10 in, CIFAR100 out:  0.85347633\n",
      "auroc variance: CIFAR10 in, SVHN out:  0.9263336297633682\n"
     ]
    }
   ],
   "source": [
    "print(\"auroc variance: CIFAR10 in, CIFAR100 out: \", 1-auroc_variance(alphas_in=CIFAR10_test_in_DIR_LPA, alphas_out=CIFAR10_test_out_CIFAR100_DIR_LPA, method='mean'))\n",
    "print(\"auroc variance: CIFAR10 in, SVHN out: \", 1-auroc_variance(alphas_in=CIFAR10_test_in_DIR_LPA, alphas_out=CIFAR10_test_out_SVHN_DIR_LPA, method='mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train on SVHN test on CIFAR10 and CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "SVHN_model = ResNet18(num_classes=10).to(device)\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all_SVHN():\n",
    "    SVHN_path = 'weights/SVHN_resnet18_SGD.pth'\n",
    "    lr = 0.1\n",
    "    epoch = 0\n",
    "    for e in [100, 25, 25]:\n",
    "        print(\"current learning rate: \", lr)\n",
    "        for _ in range(e):\n",
    "            optimizer = optim.SGD(SVHN_model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "            train(SVHN_model, epoch, optimizer, train_loader_SVHN, SVHN_path)\n",
    "            test(SVHN_model, epoch, test_loader_SVHN)\n",
    "            epoch += 1\n",
    "        lr /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current learning rate:  0.1\n",
      "\n",
      "Epoch: 0\n",
      "train loss:  526.6906039714813\n",
      "train accuracy:  0.1851183159188691\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  448.27835869789124\n",
      "test accuracy:  0.19779502151198525\n",
      "\n",
      "Epoch: 1\n",
      "train loss:  422.3239378929138\n",
      "train accuracy:  0.2555700676090965\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  370.6238044500351\n",
      "test accuracy:  0.36839274738783034\n",
      "\n",
      "Epoch: 2\n",
      "train loss:  272.32134944200516\n",
      "train accuracy:  0.5446757836508912\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  194.712015748024\n",
      "test accuracy:  0.6841963736939152\n",
      "\n",
      "Epoch: 3\n",
      "train loss:  120.10154750943184\n",
      "train accuracy:  0.8163030116779348\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  78.36422492563725\n",
      "test accuracy:  0.8812615242778119\n",
      "\n",
      "Epoch: 4\n",
      "train loss:  67.5305732190609\n",
      "train accuracy:  0.8981637984019668\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  61.02035349607468\n",
      "test accuracy:  0.9059618930547019\n",
      "\n",
      "Epoch: 5\n",
      "train loss:  46.66582275554538\n",
      "train accuracy:  0.9326213890596189\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  49.214359160512686\n",
      "test accuracy:  0.9262062077443147\n",
      "\n",
      "Epoch: 6\n",
      "train loss:  34.25827656313777\n",
      "train accuracy:  0.9498309772587584\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  45.41755485534668\n",
      "test accuracy:  0.9312768899815611\n",
      "\n",
      "Epoch: 7\n",
      "train loss:  26.926171451807022\n",
      "train accuracy:  0.9611631837738168\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  49.868548069149256\n",
      "test accuracy:  0.9201367547633682\n",
      "\n",
      "Epoch: 8\n",
      "train loss:  23.145160416141152\n",
      "train accuracy:  0.9668100799016595\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  35.955148011446\n",
      "test accuracy:  0.9435694529809465\n",
      "\n",
      "Epoch: 9\n",
      "train loss:  19.758095182478428\n",
      "train accuracy:  0.9701521204671174\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  34.22589321061969\n",
      "test accuracy:  0.9450291948371236\n",
      "\n",
      "Epoch: 10\n",
      "train loss:  15.319916922599077\n",
      "train accuracy:  0.9764904732636754\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  24.325992420315742\n",
      "test accuracy:  0.9603564843269822\n",
      "\n",
      "Epoch: 11\n",
      "train loss:  14.268189737573266\n",
      "train accuracy:  0.9783727719729564\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  26.52192459627986\n",
      "test accuracy:  0.9593961278426552\n",
      "\n",
      "Epoch: 12\n",
      "train loss:  13.060896648094058\n",
      "train accuracy:  0.980639213275968\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  23.80577975511551\n",
      "test accuracy:  0.9633912108174555\n",
      "\n",
      "Epoch: 13\n",
      "train loss:  11.897582478821278\n",
      "train accuracy:  0.9819068838352797\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  17.308931328356266\n",
      "test accuracy:  0.9714197910264291\n",
      "\n",
      "Epoch: 14\n",
      "train loss:  9.63824986293912\n",
      "train accuracy:  0.9860172095881992\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  16.84221730614081\n",
      "test accuracy:  0.9716118623232944\n",
      "\n",
      "Epoch: 15\n",
      "train loss:  11.57008201815188\n",
      "train accuracy:  0.9824830977258758\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  21.71345898322761\n",
      "test accuracy:  0.9640442532267978\n",
      "\n",
      "Epoch: 16\n",
      "train loss:  10.26166875101626\n",
      "train accuracy:  0.9841733251382914\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  29.09939220547676\n",
      "test accuracy:  0.9530577750460971\n",
      "\n",
      "Epoch: 17\n",
      "train loss:  12.409047802910209\n",
      "train accuracy:  0.9804855562384758\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  31.008459020406008\n",
      "test accuracy:  0.9504840196681008\n",
      "\n",
      "Epoch: 18\n",
      "train loss:  9.94702158216387\n",
      "train accuracy:  0.9848263675476336\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  15.533163756132126\n",
      "test accuracy:  0.9745697602950215\n",
      "\n",
      "Epoch: 19\n",
      "train loss:  9.38558596931398\n",
      "train accuracy:  0.9850184388444991\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  43.009894574061036\n",
      "test accuracy:  0.9342732022126613\n",
      "\n",
      "Epoch: 20\n",
      "train loss:  9.294809814542532\n",
      "train accuracy:  0.985479409956976\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  35.61457258462906\n",
      "test accuracy:  0.9425322679778734\n",
      "\n",
      "Epoch: 21\n",
      "train loss:  10.579063599929214\n",
      "train accuracy:  0.9835971112476951\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  22.91832392849028\n",
      "test accuracy:  0.9639290104486785\n",
      "\n",
      "Epoch: 22\n",
      "train loss:  11.811603635549545\n",
      "train accuracy:  0.9803318992009834\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  19.581213516183197\n",
      "test accuracy:  0.9686539643515673\n",
      "\n",
      "Epoch: 23\n",
      "train loss:  8.65599806793034\n",
      "train accuracy:  0.9870543945912723\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  26.82659489288926\n",
      "test accuracy:  0.9567839582052858\n",
      "\n",
      "Epoch: 24\n",
      "train loss:  6.720454357564449\n",
      "train accuracy:  0.9903964351567301\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  20.77558221365325\n",
      "test accuracy:  0.9660802089735709\n",
      "\n",
      "Epoch: 25\n",
      "train loss:  12.262442341074347\n",
      "train accuracy:  0.980139827904118\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  24.52538593672216\n",
      "test accuracy:  0.9630454824830977\n",
      "\n",
      "Epoch: 26\n",
      "train loss:  12.297985216602683\n",
      "train accuracy:  0.9813690842040566\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  20.590920479036868\n",
      "test accuracy:  0.9670789797172711\n",
      "\n",
      "Epoch: 27\n",
      "train loss:  8.147179322317243\n",
      "train accuracy:  0.9877458512599877\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  13.970833392813802\n",
      "test accuracy:  0.9769898586355255\n",
      "\n",
      "Epoch: 28\n",
      "train loss:  6.752470461651683\n",
      "train accuracy:  0.9901275353411186\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  21.098265918670222\n",
      "test accuracy:  0.9664259373079287\n",
      "\n",
      "Epoch: 29\n",
      "train loss:  8.827964264899492\n",
      "train accuracy:  0.9867470805162877\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  53.5212925337255\n",
      "test accuracy:  0.9179471419791027\n",
      "\n",
      "Epoch: 30\n",
      "train loss:  6.3238817900419235\n",
      "train accuracy:  0.9915872771972957\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  21.2218251619488\n",
      "test accuracy:  0.9661954517516902\n",
      "\n",
      "Epoch: 31\n",
      "train loss:  10.466775635257363\n",
      "train accuracy:  0.984519053472649\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  25.64202055335045\n",
      "test accuracy:  0.9593961278426552\n",
      "\n",
      "Epoch: 32\n",
      "train loss:  9.39028175920248\n",
      "train accuracy:  0.9848263675476336\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  27.522744013927877\n",
      "test accuracy:  0.9574754148740012\n",
      "\n",
      "Epoch: 33\n",
      "train loss:  9.404363615438342\n",
      "train accuracy:  0.985940381069453\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  19.018236653879285\n",
      "test accuracy:  0.9696527350952674\n",
      "\n",
      "Epoch: 34\n",
      "train loss:  8.012994153425097\n",
      "train accuracy:  0.9874385371850031\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  22.546241777017713\n",
      "test accuracy:  0.9634680393362016\n",
      "\n",
      "Epoch: 35\n",
      "train loss:  6.147449397481978\n",
      "train accuracy:  0.9915104486785494\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  24.97562289237976\n",
      "test accuracy:  0.9605101413644745\n",
      "\n",
      "Epoch: 36\n",
      "train loss:  10.149866728112102\n",
      "train accuracy:  0.9847111247695144\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  9.98379026656039\n",
      "test accuracy:  0.9850568531038721\n",
      "\n",
      "Epoch: 37\n",
      "train loss:  8.558440124616027\n",
      "train accuracy:  0.9872080516287646\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  24.69945269729942\n",
      "test accuracy:  0.9620082974800246\n",
      "\n",
      "Epoch: 38\n",
      "train loss:  8.931059118360281\n",
      "train accuracy:  0.9867854947756607\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  21.013649739325047\n",
      "test accuracy:  0.9659649661954518\n",
      "\n",
      "Epoch: 39\n",
      "train loss:  8.737780643627048\n",
      "train accuracy:  0.9867854947756607\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  14.535745905712247\n",
      "test accuracy:  0.9781422864167179\n",
      "\n",
      "Epoch: 40\n",
      "train loss:  7.263288399204612\n",
      "train accuracy:  0.9895897357098955\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  15.906510615721345\n",
      "test accuracy:  0.9749923171481254\n",
      "\n",
      "Epoch: 41\n",
      "train loss:  7.0497364141047\n",
      "train accuracy:  0.989359250153657\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  25.741958944126964\n",
      "test accuracy:  0.9595881991395205\n",
      "\n",
      "Epoch: 42\n",
      "train loss:  7.29036985244602\n",
      "train accuracy:  0.9893976644130301\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  12.697830069810152\n",
      "test accuracy:  0.9796020282728949\n",
      "\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  6.394165435805917\n",
      "train accuracy:  0.990319606637984\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  28.257756877224892\n",
      "test accuracy:  0.9585510141364475\n",
      "\n",
      "Epoch: 44\n",
      "train loss:  11.974842347204685\n",
      "train accuracy:  0.9807928703134604\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  32.06134302727878\n",
      "test accuracy:  0.9493700061462815\n",
      "\n",
      "Epoch: 45\n",
      "train loss:  9.295794203877449\n",
      "train accuracy:  0.985978795328826\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  16.88351289089769\n",
      "test accuracy:  0.9731100184388445\n",
      "\n",
      "Epoch: 46\n",
      "train loss:  5.5315000731498\n",
      "train accuracy:  0.9923939766441303\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  11.847784034209326\n",
      "test accuracy:  0.9816379840196681\n",
      "\n",
      "Epoch: 47\n",
      "train loss:  6.0908215288072824\n",
      "train accuracy:  0.9913952059004303\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  11.206913838163018\n",
      "test accuracy:  0.9826751690227412\n",
      "\n",
      "Epoch: 48\n",
      "train loss:  6.901603829115629\n",
      "train accuracy:  0.9896665642286416\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  39.28973922505975\n",
      "test accuracy:  0.9381146281499693\n",
      "\n",
      "Epoch: 49\n",
      "train loss:  11.153586521744728\n",
      "train accuracy:  0.9825983405039951\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  37.91019687615335\n",
      "test accuracy:  0.9410341118623233\n",
      "\n",
      "Epoch: 50\n",
      "train loss:  8.074818363413215\n",
      "train accuracy:  0.9882068223724647\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  13.645992091391236\n",
      "test accuracy:  0.9789105716041795\n",
      "\n",
      "Epoch: 51\n",
      "train loss:  5.634648030623794\n",
      "train accuracy:  0.9917025199754149\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  21.649335759691894\n",
      "test accuracy:  0.9670789797172711\n",
      "\n",
      "Epoch: 52\n",
      "train loss:  10.750976160168648\n",
      "train accuracy:  0.9836739397664414\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  40.93872079253197\n",
      "test accuracy:  0.9330055316533498\n",
      "\n",
      "Epoch: 53\n",
      "train loss:  9.466777184978127\n",
      "train accuracy:  0.9862092808850645\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  11.789274416863918\n",
      "test accuracy:  0.982060540872772\n",
      "\n",
      "Epoch: 54\n",
      "train loss:  5.02465707808733\n",
      "train accuracy:  0.9935464044253227\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  8.860355193726718\n",
      "test accuracy:  0.9866318377381684\n",
      "\n",
      "Epoch: 55\n",
      "train loss:  5.246303670108318\n",
      "train accuracy:  0.9932390903503381\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  8.559892031829804\n",
      "test accuracy:  0.9871696373693916\n",
      "\n",
      "Epoch: 56\n",
      "train loss:  5.307644611224532\n",
      "train accuracy:  0.9925476336816226\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  24.176476020365953\n",
      "test accuracy:  0.9613552550706822\n",
      "\n",
      "Epoch: 57\n",
      "train loss:  10.475407699123025\n",
      "train accuracy:  0.984019668100799\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  20.983595948666334\n",
      "test accuracy:  0.9666948371235402\n",
      "\n",
      "Epoch: 58\n",
      "train loss:  10.334116954356432\n",
      "train accuracy:  0.984519053472649\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  13.163587575778365\n",
      "test accuracy:  0.9800629993853719\n",
      "\n",
      "Epoch: 59\n",
      "train loss:  5.3945420030504465\n",
      "train accuracy:  0.9919714197910264\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  10.78598140925169\n",
      "test accuracy:  0.9832129686539643\n",
      "\n",
      "Epoch: 60\n",
      "train loss:  6.500827174633741\n",
      "train accuracy:  0.9905500921942225\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  15.55468218587339\n",
      "test accuracy:  0.9758374308543332\n",
      "\n",
      "Epoch: 61\n",
      "train loss:  10.023075081408024\n",
      "train accuracy:  0.9847111247695144\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  18.34078275691718\n",
      "test accuracy:  0.9713813767670559\n",
      "\n",
      "Epoch: 62\n",
      "train loss:  7.70771661400795\n",
      "train accuracy:  0.988821450522434\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  12.63520677248016\n",
      "test accuracy:  0.9798325138291334\n",
      "\n",
      "Epoch: 63\n",
      "train loss:  6.832803841680288\n",
      "train accuracy:  0.9899354640442533\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  11.63657987024635\n",
      "test accuracy:  0.9834818684695759\n",
      "\n",
      "Epoch: 64\n",
      "train loss:  7.458798008039594\n",
      "train accuracy:  0.9889751075599262\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  14.481319164391607\n",
      "test accuracy:  0.9769514443761524\n",
      "\n",
      "Epoch: 65\n",
      "train loss:  5.157477453351021\n",
      "train accuracy:  0.9929701905347265\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  14.554556264774874\n",
      "test accuracy:  0.9768362015980332\n",
      "\n",
      "Epoch: 66\n",
      "train loss:  9.15861808694899\n",
      "train accuracy:  0.9861324523663184\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  27.57782107591629\n",
      "test accuracy:  0.9572065150583897\n",
      "\n",
      "Epoch: 67\n",
      "train loss:  9.205311633180827\n",
      "train accuracy:  0.9867470805162877\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  13.38903965614736\n",
      "test accuracy:  0.978680086047941\n",
      "\n",
      "Epoch: 68\n",
      "train loss:  7.77250256575644\n",
      "train accuracy:  0.988859864781807\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  12.282310489565134\n",
      "test accuracy:  0.9820989551321451\n",
      "\n",
      "Epoch: 69\n",
      "train loss:  3.968044752255082\n",
      "train accuracy:  0.9949293177627535\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  6.023173523368314\n",
      "test accuracy:  0.9916256914566687\n",
      "\n",
      "Epoch: 70\n",
      "train loss:  6.67787129431963\n",
      "train accuracy:  0.9903580208973571\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  17.77850984642282\n",
      "test accuracy:  0.9731100184388445\n",
      "\n",
      "Epoch: 71\n",
      "train loss:  9.076648923568428\n",
      "train accuracy:  0.985940381069453\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  20.59667327348143\n",
      "test accuracy:  0.967501536570375\n",
      "\n",
      "Epoch: 72\n",
      "train loss:  8.217749151401222\n",
      "train accuracy:  0.98740012292563\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  10.382393019972369\n",
      "test accuracy:  0.9838275968039336\n",
      "\n",
      "Epoch: 73\n",
      "train loss:  8.06778747215867\n",
      "train accuracy:  0.9877842655193608\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  17.53412025840953\n",
      "test accuracy:  0.9722649047326367\n",
      "\n",
      "Epoch: 74\n",
      "train loss:  8.49300947226584\n",
      "train accuracy:  0.9872464658881377\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  19.01801565196365\n",
      "test accuracy:  0.9704210202827289\n",
      "\n",
      "Epoch: 75\n",
      "train loss:  7.420618820935488\n",
      "train accuracy:  0.9890903503380455\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  13.1257777903229\n",
      "test accuracy:  0.9804087277197295\n",
      "\n",
      "Epoch: 76\n",
      "train loss:  5.573186652269214\n",
      "train accuracy:  0.9920482483097726\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  6.068139209761284\n",
      "test accuracy:  0.9912415488629379\n",
      "\n",
      "Epoch: 77\n",
      "train loss:  4.888376567512751\n",
      "train accuracy:  0.9928933620159803\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  13.487432829570025\n",
      "test accuracy:  0.9785648432698217\n",
      "\n",
      "Epoch: 78\n",
      "train loss:  7.7282323855906725\n",
      "train accuracy:  0.9880147510755992\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  27.692627531010658\n",
      "test accuracy:  0.958819913952059\n",
      "\n",
      "Epoch: 79\n",
      "train loss:  11.491765093058348\n",
      "train accuracy:  0.9815611555009219\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  21.75033448357135\n",
      "test accuracy:  0.9640058389674248\n",
      "\n",
      "Epoch: 80\n",
      "train loss:  8.445249298587441\n",
      "train accuracy:  0.9877458512599877\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  10.59530051983893\n",
      "test accuracy:  0.9824446834665027\n",
      "\n",
      "Epoch: 81\n",
      "train loss:  3.538920711260289\n",
      "train accuracy:  0.995620774431469\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  2.6490241051651537\n",
      "test accuracy:  0.996619545175169\n",
      "\n",
      "Epoch: 82\n",
      "train loss:  4.569253956899047\n",
      "train accuracy:  0.9932390903503381\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  31.836404314264655\n",
      "test accuracy:  0.9529041180086048\n",
      "\n",
      "Epoch: 83\n",
      "train loss:  7.776796715334058\n",
      "train accuracy:  0.9882068223724647\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  9.165514410007745\n",
      "test accuracy:  0.9873232944068838\n",
      "\n",
      "Epoch: 84\n",
      "train loss:  11.204751309007406\n",
      "train accuracy:  0.9835971112476951\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  20.31845044158399\n",
      "test accuracy:  0.9676167793484942\n",
      "\n",
      "Epoch: 85\n",
      "train loss:  7.838826050981879\n",
      "train accuracy:  0.9890135218192994\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  15.22482236661017\n",
      "test accuracy:  0.9762215734480639\n",
      "\n",
      "Epoch: 86\n",
      "train loss:  7.07504964992404\n",
      "train accuracy:  0.9890135218192994\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  8.969740292057395\n",
      "test accuracy:  0.9860940381069453\n",
      "\n",
      "Epoch: 87\n",
      "train loss:  3.127676287665963\n",
      "train accuracy:  0.9963890596189305\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  5.121968291932717\n",
      "test accuracy:  0.9924323909035033\n",
      "\n",
      "Epoch: 88\n",
      "train loss:  6.365172215737402\n",
      "train accuracy:  0.9907037492317148\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  14.953086042776704\n",
      "test accuracy:  0.9779118008604795\n",
      "\n",
      "Epoch: 89\n",
      "train loss:  12.330224016681314\n",
      "train accuracy:  0.9807928703134604\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  27.410977555438876\n",
      "test accuracy:  0.9575138291333744\n",
      "\n",
      "Epoch: 90\n",
      "train loss:  8.914430286735296\n",
      "train accuracy:  0.9860940381069453\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  18.466863421723247\n",
      "test accuracy:  0.9719575906576521\n",
      "\n",
      "Epoch: 91\n",
      "train loss:  5.8112686849199235\n",
      "train accuracy:  0.9921250768285187\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  5.277683179592714\n",
      "test accuracy:  0.9918561770129072\n",
      "\n",
      "Epoch: 92\n",
      "train loss:  4.244124602526426\n",
      "train accuracy:  0.994161032575292\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  9.847978041274473\n",
      "test accuracy:  0.9843653964351567\n",
      "\n",
      "Epoch: 93\n",
      "train loss:  4.965139432810247\n",
      "train accuracy:  0.9935848186846957\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  6.626058503985405\n",
      "test accuracy:  0.9905116779348494\n",
      "\n",
      "Epoch: 94\n",
      "train loss:  9.869500204920769\n",
      "train accuracy:  0.9849416103257529\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  17.69224078953266\n",
      "test accuracy:  0.9725722188076213\n",
      "\n",
      "Epoch: 95\n",
      "train loss:  6.953624454326928\n",
      "train accuracy:  0.990818992009834\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  25.925049915909767\n",
      "test accuracy:  0.9607790411800861\n",
      "\n",
      "Epoch: 96\n",
      "train loss:  8.904222659766674\n",
      "train accuracy:  0.9857098955132145\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  32.5774333961308\n",
      "test accuracy:  0.9498309772587584\n",
      "\n",
      "Epoch: 97\n",
      "train loss:  7.9727787701413035\n",
      "train accuracy:  0.9879763368162262\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  14.194513174705207\n",
      "test accuracy:  0.9796020282728949\n",
      "\n",
      "Epoch: 98\n",
      "train loss:  6.356761682778597\n",
      "train accuracy:  0.9913952059004303\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  10.103319015353918\n",
      "test accuracy:  0.9853257529194838\n",
      "\n",
      "Epoch: 99\n",
      "train loss:  5.310297440737486\n",
      "train accuracy:  0.9925476336816226\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  11.787061764858663\n",
      "test accuracy:  0.981599569760295\n",
      "current learning rate:  0.01\n",
      "\n",
      "Epoch: 100\n",
      "train loss:  1.7711845015874133\n",
      "train accuracy:  0.9978872157344807\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.41869245655834675\n",
      "test accuracy:  0.9999615857406269\n",
      "\n",
      "Epoch: 101\n",
      "train loss:  0.3422964228084311\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.30983291316078976\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 102\n",
      "train loss:  0.28059244772884995\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2788353003561497\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 103\n",
      "train loss:  0.2579630786785856\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.262107380956877\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 104\n",
      "train loss:  0.2465203801402822\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2524556194548495\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 105\n",
      "train loss:  0.24088977032806724\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.24696359661174938\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 106\n",
      "train loss:  0.23879158741328865\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.244200699031353\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 107\n",
      "train loss:  0.23904322588350624\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.24331950646592304\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 108\n",
      "train loss:  0.24095974618103355\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2438373689656146\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 109\n",
      "train loss:  0.2440813109278679\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.24535727500915527\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 110\n",
      "train loss:  0.2480878731003031\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2476450726389885\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 111\n",
      "train loss:  0.25276335945818573\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2505166580667719\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 112\n",
      "train loss:  0.2579267000546679\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2538116661598906\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 113\n",
      "train loss:  0.26344829180743545\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.25739225873257965\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 114\n",
      "train loss:  0.2692186856875196\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.261132781743072\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 115\n",
      "train loss:  0.27515614649746567\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2650010461220518\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 116\n",
      "train loss:  0.28115310391876847\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2689187526702881\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 117\n",
      "train loss:  0.2871510088443756\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.27279636135790497\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 118\n",
      "train loss:  0.29308654367923737\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2766113741090521\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 119\n",
      "train loss:  0.29891378059983253\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.280323980958201\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 120\n",
      "train loss:  0.30458846932742745\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2839206071803346\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 121\n",
      "train loss:  0.31007563206367195\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.28731905424501747\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 122\n",
      "train loss:  0.3153467911761254\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2905433786800131\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 123\n",
      "train loss:  0.3203761850018054\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2935132769634947\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 124\n",
      "train loss:  0.3251551736611873\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2962784009287134\n",
      "test accuracy:  1.0\n",
      "current learning rate:  0.001\n",
      "\n",
      "Epoch: 125\n",
      "train loss:  0.3244311437010765\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29226988425944\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 126\n",
      "train loss:  0.32490752381272614\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2925515150418505\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 127\n",
      "train loss:  0.325382073642686\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29283285641577095\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 128\n",
      "train loss:  0.32585610332898796\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29311311373021454\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 129\n",
      "train loss:  0.3263251595199108\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29339198395609856\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 130\n",
      "train loss:  0.32679303735494614\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2936689978232607\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 131\n",
      "train loss:  0.3272584192454815\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2939444606890902\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 132\n",
      "train loss:  0.3277197990100831\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29421718418598175\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 133\n",
      "train loss:  0.32818013918586075\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2944875471293926\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  0.3286369778215885\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29475659504532814\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 135\n",
      "train loss:  0.32908959803171456\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.295023693353869\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 136\n",
      "train loss:  0.3295415889006108\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2952897237846628\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 137\n",
      "train loss:  0.3299892221111804\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2955513671040535\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 138\n",
      "train loss:  0.3304341535549611\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29581074288580567\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 139\n",
      "train loss:  0.33087606984190643\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29606871434953064\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 140\n",
      "train loss:  0.3313150405883789\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2963244765996933\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 141\n",
      "train loss:  0.3317510348279029\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2965790368616581\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 142\n",
      "train loss:  0.33218428608961403\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2968291217694059\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 143\n",
      "train loss:  0.33261482417583466\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.297079224139452\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 144\n",
      "train loss:  0.3330421857535839\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29732499399688095\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 145\n",
      "train loss:  0.3334661237895489\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2975709413876757\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 146\n",
      "train loss:  0.3338889863807708\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2978123923530802\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 147\n",
      "train loss:  0.33430734649300575\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29805321991443634\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 148\n",
      "train loss:  0.33472337457351387\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.29829047119710594\n",
      "test accuracy:  1.0\n",
      "\n",
      "Epoch: 149\n",
      "train loss:  0.3351362980902195\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2985247807810083\n",
      "test accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "train_all_SVHN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from: weights/SVHN_resnet18_SGD.pth\n",
      "test loss:  0.2985247807810083\n",
      "test accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "##### if you already have a trained model ##############\n",
    "SVHN_PATH = 'weights/SVHN_resnet18_SGD.pth'\n",
    "SVHN_model = ResNet18().to(device)\n",
    "print(\"loading model from: {}\".format(SVHN_PATH))\n",
    "SVHN_model.load_state_dict(torch.load(SVHN_PATH))#, map_location=torch.device('cpu')))\n",
    "#test the model\n",
    "test(SVHN_model, 0, test_loader_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 512 inputs to linear layer with m: 10 classes\n",
      "Batch: 0/204\n",
      "Batch: 1/204\n",
      "Batch: 2/204\n",
      "Batch: 3/204\n",
      "Batch: 4/204\n",
      "Batch: 5/204\n",
      "Batch: 6/204\n",
      "Batch: 7/204\n",
      "Batch: 8/204\n",
      "Batch: 9/204\n",
      "Batch: 10/204\n",
      "Batch: 11/204\n",
      "Batch: 12/204\n",
      "Batch: 13/204\n",
      "Batch: 14/204\n",
      "Batch: 15/204\n",
      "Batch: 16/204\n",
      "Batch: 17/204\n",
      "Batch: 18/204\n",
      "Batch: 19/204\n",
      "Batch: 20/204\n",
      "Batch: 21/204\n",
      "Batch: 22/204\n",
      "Batch: 23/204\n",
      "Batch: 24/204\n",
      "Batch: 25/204\n",
      "Batch: 26/204\n",
      "Batch: 27/204\n",
      "Batch: 28/204\n",
      "Batch: 29/204\n",
      "Batch: 30/204\n",
      "Batch: 31/204\n",
      "Batch: 32/204\n",
      "Batch: 33/204\n",
      "Batch: 34/204\n",
      "Batch: 35/204\n",
      "Batch: 36/204\n",
      "Batch: 37/204\n",
      "Batch: 38/204\n",
      "Batch: 39/204\n",
      "Batch: 40/204\n",
      "Batch: 41/204\n",
      "Batch: 42/204\n",
      "Batch: 43/204\n",
      "Batch: 44/204\n",
      "Batch: 45/204\n",
      "Batch: 46/204\n",
      "Batch: 47/204\n",
      "Batch: 48/204\n",
      "Batch: 49/204\n",
      "Batch: 50/204\n",
      "Batch: 51/204\n",
      "Batch: 52/204\n",
      "Batch: 53/204\n",
      "Batch: 54/204\n",
      "Batch: 55/204\n",
      "Batch: 56/204\n",
      "Batch: 57/204\n",
      "Batch: 58/204\n",
      "Batch: 59/204\n",
      "Batch: 60/204\n",
      "Batch: 61/204\n",
      "Batch: 62/204\n",
      "Batch: 63/204\n",
      "Batch: 64/204\n",
      "Batch: 65/204\n",
      "Batch: 66/204\n",
      "Batch: 67/204\n",
      "Batch: 68/204\n",
      "Batch: 69/204\n",
      "Batch: 70/204\n",
      "Batch: 71/204\n",
      "Batch: 72/204\n",
      "Batch: 73/204\n",
      "Batch: 74/204\n",
      "Batch: 75/204\n",
      "Batch: 76/204\n",
      "Batch: 77/204\n",
      "Batch: 78/204\n",
      "Batch: 79/204\n",
      "Batch: 80/204\n",
      "Batch: 81/204\n",
      "Batch: 82/204\n",
      "Batch: 83/204\n",
      "Batch: 84/204\n",
      "Batch: 85/204\n",
      "Batch: 86/204\n",
      "Batch: 87/204\n",
      "Batch: 88/204\n",
      "Batch: 89/204\n",
      "Batch: 90/204\n",
      "Batch: 91/204\n",
      "Batch: 92/204\n",
      "Batch: 93/204\n",
      "Batch: 94/204\n",
      "Batch: 95/204\n",
      "Batch: 96/204\n",
      "Batch: 97/204\n",
      "Batch: 98/204\n",
      "Batch: 99/204\n",
      "Batch: 100/204\n",
      "Batch: 101/204\n",
      "Batch: 102/204\n",
      "Batch: 103/204\n",
      "Batch: 104/204\n",
      "Batch: 105/204\n",
      "Batch: 106/204\n",
      "Batch: 107/204\n",
      "Batch: 108/204\n",
      "Batch: 109/204\n",
      "Batch: 110/204\n",
      "Batch: 111/204\n",
      "Batch: 112/204\n",
      "Batch: 113/204\n",
      "Batch: 114/204\n",
      "Batch: 115/204\n",
      "Batch: 116/204\n",
      "Batch: 117/204\n",
      "Batch: 118/204\n",
      "Batch: 119/204\n",
      "Batch: 120/204\n",
      "Batch: 121/204\n",
      "Batch: 122/204\n",
      "Batch: 123/204\n",
      "Batch: 124/204\n",
      "Batch: 125/204\n",
      "Batch: 126/204\n",
      "Batch: 127/204\n",
      "Batch: 128/204\n",
      "Batch: 129/204\n",
      "Batch: 130/204\n",
      "Batch: 131/204\n",
      "Batch: 132/204\n",
      "Batch: 133/204\n",
      "Batch: 134/204\n",
      "Batch: 135/204\n",
      "Batch: 136/204\n",
      "Batch: 137/204\n",
      "Batch: 138/204\n",
      "Batch: 139/204\n",
      "Batch: 140/204\n",
      "Batch: 141/204\n",
      "Batch: 142/204\n",
      "Batch: 143/204\n",
      "Batch: 144/204\n",
      "Batch: 145/204\n",
      "Batch: 146/204\n",
      "Batch: 147/204\n",
      "Batch: 148/204\n",
      "Batch: 149/204\n",
      "Batch: 150/204\n",
      "Batch: 151/204\n",
      "Batch: 152/204\n",
      "Batch: 153/204\n",
      "Batch: 154/204\n",
      "Batch: 155/204\n",
      "Batch: 156/204\n",
      "Batch: 157/204\n",
      "Batch: 158/204\n",
      "Batch: 159/204\n",
      "Batch: 160/204\n",
      "Batch: 161/204\n",
      "Batch: 162/204\n",
      "Batch: 163/204\n",
      "Batch: 164/204\n",
      "Batch: 165/204\n",
      "Batch: 166/204\n",
      "Batch: 167/204\n",
      "Batch: 168/204\n",
      "Batch: 169/204\n",
      "Batch: 170/204\n",
      "Batch: 171/204\n",
      "Batch: 172/204\n",
      "Batch: 173/204\n",
      "Batch: 174/204\n",
      "Batch: 175/204\n",
      "Batch: 176/204\n",
      "Batch: 177/204\n",
      "Batch: 178/204\n",
      "Batch: 179/204\n",
      "Batch: 180/204\n",
      "Batch: 181/204\n",
      "Batch: 182/204\n",
      "Batch: 183/204\n",
      "Batch: 184/204\n",
      "Batch: 185/204\n",
      "Batch: 186/204\n",
      "Batch: 187/204\n",
      "Batch: 188/204\n",
      "Batch: 189/204\n",
      "Batch: 190/204\n",
      "Batch: 191/204\n",
      "Batch: 192/204\n",
      "Batch: 193/204\n",
      "Batch: 194/204\n",
      "Batch: 195/204\n",
      "Batch: 196/204\n",
      "Batch: 197/204\n",
      "Batch: 198/204\n",
      "Batch: 199/204\n",
      "Batch: 200/204\n",
      "Batch: 201/204\n",
      "Batch: 202/204\n",
      "Batch: 203/204\n",
      "204\n",
      "M_W_post size:  torch.Size([512, 10])\n",
      "M_b_post size:  torch.Size([10])\n",
      "C_W_post size:  torch.Size([10, 512])\n",
      "C_b_post size:  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "M_W_post_D_SVHN, M_b_post_D_SVHN, C_W_post_D_SVHN, C_b_post_D_SVHN = Diag_second_order(model=SVHN_model,\n",
    "                                                               train_loader=train_loader_SVHN,\n",
    "                                                               var0 = 10,\n",
    "                                                               device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVHN_test_in_MAP = predict_MAP(SVHN_model, test_loader_SVHN, cuda=True).cpu().numpy()\n",
    "SVHN_test_out_CIFAR10_MAP = predict_MAP(SVHN_model, testloader, cuda=True).cpu().numpy()\n",
    "SVHN_test_out_CIFAR100_MAP = predict_MAP(SVHN_model, CIFAR100_test_loader, cuda=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP = get_in_dist_values(SVHN_test_in_MAP, targets_SVHN)\n",
    "acc_out_CIFAR10_MAP, prob_correct_out_CIFAR10_MAP, ent_out_CIFAR10, MMC_out_CIFAR10_MAP, auroc_out_CIFAR10_MAP = get_out_dist_values(SVHN_test_in_MAP, SVHN_test_out_CIFAR10_MAP, targets_CIFAR10)\n",
    "acc_out_CIFAR100_MAP, prob_correct_out_CIFAR100_MAP, ent_out_CIFAR100_MAP, MMC_out_CIFAR100_MAP, auroc_out_CIFAR100_MAP = get_out_dist_values(SVHN_test_in_MAP, SVHN_test_out_CIFAR100_MAP, targets_CIFAR100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, MAP, SVHN] Accuracy: 1.000; average entropy: 0.012;     MMC: 0.999; Prob @ correct: 0.100\n",
      "[Out-MAP, KFAC, CIFAR10] Accuracy: 0.085; Average entropy: 1.193;    MMC: 0.609; AUROC: 0.997; Prob @ correct: 0.100\n",
      "[Out-MAP, KFAC, CIFAR100] Accuracy: 0.012; Average entropy: 1.181;    MMC: 0.614; AUROC: 0.996; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP, 'SVHN', 'MAP')\n",
    "print_out_dist_values(acc_out_CIFAR10_MAP, prob_correct_out_CIFAR10_MAP, ent_out_CIFAR10, MMC_out_CIFAR10_MAP, auroc_out_CIFAR10_MAP, 'CIFAR10', 'MAP')\n",
    "print_out_dist_values(acc_out_CIFAR100_MAP, prob_correct_out_CIFAR100_MAP, ent_out_CIFAR100_MAP, MMC_out_CIFAR100_MAP, auroc_out_CIFAR100_MAP, 'CIFAR100', 'MAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.000 with std 0.000\n",
      "MMC in: 0.999 with std 0.000\n",
      "MMC out CIFAR10: 0.621 with std 0.009\n",
      "MMC out CIFAR100: 0.625 with std 0.007\n",
      "AUROC out CIFAR10: 0.996 with std 0.000\n",
      "AUROC out CIFAR100: 0.996 with std 0.000\n"
     ]
    }
   ],
   "source": [
    "#MAP estimate\n",
    "#seeds are 123,124,125,126,127\n",
    "acc_in = [1, 1, 1, 1]\n",
    "mmc_in = [0.999, 0.999, 0.998, 0.999]\n",
    "mmc_out_CIFAR10 = [0.633, 0.622, 0.620, 0.609]\n",
    "mmc_out_CIFAR100 = [0.632, 0.630, 0.624, 0.614]\n",
    "\n",
    "auroc_out_CIFAR10 = [0.996, 0.996, 0.996, 0.997]\n",
    "auroc_out_CIFAR100 = [0.996, 0.996, 0.996, 0.996]\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR10), np.std(mmc_out_CIFAR10)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "\n",
    "print(\"AUROC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR10), np.std(auroc_out_CIFAR10)))\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diag sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used for sampling with 1000 samples: 16.769160509109497\n",
      "time used for sampling with 1000 samples: 6.551377058029175\n",
      "time used for sampling with 1000 samples: 6.577383518218994\n"
     ]
    }
   ],
   "source": [
    "SVHN_test_in_D = predict_diagonal_sampling(SVHN_model, test_loader_SVHN, M_W_post_D_SVHN, M_b_post_D_SVHN, C_W_post_D_SVHN, C_b_post_D_SVHN, n_samples=1000, cuda=True, timing=True).cpu().numpy()\n",
    "SVHN_test_out_CIFAR10_D = predict_diagonal_sampling(SVHN_model, testloader, M_W_post_D_SVHN, M_b_post_D_SVHN, C_W_post_D_SVHN, C_b_post_D_SVHN, n_samples=1000, cuda=True, timing=True).cpu().numpy()\n",
    "SVHN_test_out_CIFAR100_D = predict_diagonal_sampling(SVHN_model, CIFAR100_test_loader, M_W_post_D_SVHN, M_b_post_D_SVHN, C_W_post_D_SVHN, C_b_post_D_SVHN, n_samples=1000, cuda=True, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D = get_in_dist_values(SVHN_test_in_D, targets_SVHN)\n",
    "acc_out_CIFAR10_D, prob_correct_out_CIFAR10_D, ent_out_CIFAR10_D, MMC_out_CIFAR10_D, auroc_out_CIFAR10_D = get_out_dist_values(SVHN_test_in_D, SVHN_test_out_CIFAR10_D, targets_CIFAR10)\n",
    "acc_out_CIFAR100_D, prob_correct_out_CIFAR100_D, ent_out_CIFAR100_D, MMC_out_CIFAR100_D, auroc_out_CIFAR100_D = get_out_dist_values(SVHN_test_in_D, SVHN_test_out_CIFAR100_D, targets_CIFAR100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, Diag, SVHN] Accuracy: 1.000; average entropy: 0.094;     MMC: 0.986; Prob @ correct: 0.100\n",
      "[Out-Diag, KFAC, CIFAR10] Accuracy: 0.084; Average entropy: 1.420;    MMC: 0.530; AUROC: 0.996; Prob @ correct: 0.100\n",
      "[Out-Diag, KFAC, CIFAR100] Accuracy: 0.011; Average entropy: 1.410;    MMC: 0.535; AUROC: 0.995; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D, 'SVHN', 'Diag')\n",
    "print_out_dist_values(acc_out_CIFAR10_D, prob_correct_out_CIFAR10_D, ent_out_CIFAR10_D, MMC_out_CIFAR10_D, auroc_out_CIFAR10_D, 'CIFAR10', 'Diag')\n",
    "print_out_dist_values(acc_out_CIFAR100_D, prob_correct_out_CIFAR100_D, ent_out_CIFAR100_D, MMC_out_CIFAR100_D, auroc_out_CIFAR100_D, 'CIFAR100', 'Diag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Bridge time in: 17.052 with std 0.200\n",
      "Sampling Bridge time out CIFAR10: 6.597 with std 0.045\n",
      "Sampling Bridge time out CIFAR100: 6.603 with std 0.029\n",
      "accuracy: 1.000 with std 0.000\n",
      "MMC in: 0.986 with std 0.000\n",
      "MMC out CIFAR10: 0.542 with std 0.009\n",
      "MMC out CIFAR100: 0.546 with std 0.007\n",
      "AUROC out CIFAR10: 0.995 with std 0.000\n",
      "AUROC out CIFAR100: 0.994 with std 0.000\n"
     ]
    }
   ],
   "source": [
    "#Diag Sampling\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [17.116743326187134, 17.32284379005432, 16.99942111968994, 16.769160509109497]\n",
    "time_lpb_out_CIFAR10 = [6.582088470458984, 6.672346353530884,6.582506418228149, 6.551377058029175]\n",
    "time_lpb_out_CIFAR100 = [6.610069751739502, 6.648055791854858, 6.576121807098389, 6.577383518218994]\n",
    "\n",
    "acc_in = [1, 1, 1, 1]\n",
    "mmc_in = [0.986, 0.986, 0.986, 0.986]\n",
    "mmc_out_CIFAR10 = [0.554, 0.543, 0.540, 0.530]\n",
    "mmc_out_CIFAR100 = [0.554, 0.550, 0.544, 0.535]\n",
    "\n",
    "auroc_out_CIFAR10 = [0.995, 0.995, 0.995, 0.996]\n",
    "auroc_out_CIFAR100 = [0.994, 0.994, 0.994, 0.995]\n",
    "\n",
    "print(\"Sampling Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Sampling Bridge time out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR10), np.std(time_lpb_out_CIFAR10)))\n",
    "print(\"Sampling Bridge time out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR100), np.std(time_lpb_out_CIFAR100)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR10), np.std(mmc_out_CIFAR10)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "\n",
    "print(\"AUROC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR10), np.std(auroc_out_CIFAR10)))\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplace Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used for transform: 0.04087\n",
      "total time used for transform: 0.01707\n",
      "total time used for transform: 0.01584\n"
     ]
    }
   ],
   "source": [
    "SVHN_test_in_DIR_LPA = predict_DIR_LPA(SVHN_model, test_loader_SVHN, M_W_post_D_SVHN, M_b_post_D_SVHN, C_W_post_D_SVHN, C_b_post_D_SVHN, cuda=True, timing=True).cpu().numpy()\n",
    "SVHN_test_out_CIFAR10_DIR_LPA = predict_DIR_LPA(SVHN_model, testloader, M_W_post_D_SVHN, M_b_post_D_SVHN, C_W_post_D_SVHN, C_b_post_D_SVHN, cuda=True, timing=True).cpu().numpy()\n",
    "SVHN_test_out_CIFAR100_DIR_LPA = predict_DIR_LPA(SVHN_model, CIFAR100_test_loader, M_W_post_D_SVHN, M_b_post_D_SVHN, C_W_post_D_SVHN, C_b_post_D_SVHN, cuda=True, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize to get the MAP estimate (which is the mode) of the Dirichlet\n",
    "SVHN_test_in_DIR_LPAn = SVHN_test_in_DIR_LPA/SVHN_test_in_DIR_LPA.sum(1).reshape(-1,1)\n",
    "SVHN_test_out_CIFAR10_DIR_LPAn = SVHN_test_out_CIFAR10_DIR_LPA/SVHN_test_out_CIFAR10_DIR_LPA.sum(1).reshape(-1,1)\n",
    "SVHN_test_out_CIFAR100_DIR_LPAn = SVHN_test_out_CIFAR100_DIR_LPA/SVHN_test_out_CIFAR100_DIR_LPA.sum(1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_DIR_LPA, prob_correct_in_DIR_LPA, ent_in_DIR_LPA, MMC_in_DIR_LPA = get_in_dist_values(SVHN_test_in_DIR_LPAn, targets_SVHN)\n",
    "acc_out_CIFAR10_DIR_LPA, prob_correct_out_CIFAR10_DIR_LPA, ent_out_CIFAR10_DIR_LPA, MMC_out_CIFAR10_DIR_LPA, auroc_out_CIFAR10_DIR_LPA = get_out_dist_values(SVHN_test_in_DIR_LPAn, SVHN_test_out_CIFAR10_DIR_LPAn, targets_CIFAR10)\n",
    "acc_out_CIFAR100_DIR_LPA, prob_correct_out_CIFAR100_DIR_LPA, ent_out_CIFAR100_DIR_LPA, MMC_out_CIFAR100_DIR_LPA, auroc_out_CIFAR100_DIR_LPA = get_out_dist_values(SVHN_test_in_DIR_LPAn, SVHN_test_out_CIFAR100_DIR_LPAn, targets_CIFAR100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, DIR_LPA, SVHN] Accuracy: 1.000; average entropy: 0.061;     MMC: 0.991; Prob @ correct: 0.100\n",
      "[Out-DIR_LPA, KFAC, CIFAR10] Accuracy: 0.085; Average entropy: 1.861;    MMC: 0.386; AUROC: 0.997; Prob @ correct: 0.100\n",
      "[Out-DIR_LPA, KFAC, CIFAR100] Accuracy: 0.012; Average entropy: 1.846;    MMC: 0.391; AUROC: 0.996; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_DIR_LPA, prob_correct_in_DIR_LPA, ent_in_DIR_LPA, MMC_in_DIR_LPA, 'SVHN', 'DIR_LPA')\n",
    "print_out_dist_values(acc_out_CIFAR10_DIR_LPA, prob_correct_out_CIFAR10_DIR_LPA, ent_out_CIFAR10_DIR_LPA, MMC_out_CIFAR10_DIR_LPA, auroc_out_CIFAR10_DIR_LPA, 'CIFAR10', 'DIR_LPA')\n",
    "print_out_dist_values(acc_out_CIFAR100_DIR_LPA, prob_correct_out_CIFAR100_DIR_LPA, ent_out_CIFAR100_DIR_LPA, MMC_out_CIFAR100_DIR_LPA, auroc_out_CIFAR100_DIR_LPA, 'CIFAR100', 'DIR_LPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplace Bridge time in: 0.041 with std 0.000\n",
      "Laplace Bridge time out CIFAR10: 0.017 with std 0.000\n",
      "Laplace Bridge time out CIFAR100: 0.016 with std 0.000\n",
      "accuracy: 1.000 with std 0.000\n",
      "MMC in: 0.992 with std 0.001\n",
      "MMC out CIFAR10: 0.399 with std 0.009\n",
      "MMC out CIFAR100: 0.405 with std 0.009\n",
      "AUROC out CIFAR10: 0.996 with std 0.000\n",
      "AUROC out CIFAR100: 0.996 with std 0.001\n"
     ]
    }
   ],
   "source": [
    "#Laplace Bridge\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [0.04104,0.04193, 0.04068, 0.04087]\n",
    "time_lpb_out_CIFAR10 = [0.01681,0.01735, 0.01730, 0.01707]\n",
    "time_lpb_out_CIFAR100 = [0.01592, 0.01599, 0.01594, 0.01584]\n",
    "\n",
    "\n",
    "acc_in = [1, 1, 1, 1]\n",
    "mmc_in = [0.992, 0.992, 0.991, 0.991]\n",
    "mmc_out_CIFAR10 = [0.411, 0.401, 0.398, 0.386]\n",
    "mmc_out_CIFAR100 = [0.413, 0.412, 0.405, 0.391]\n",
    "\n",
    "auroc_out_CIFAR10 = [0.996, 0.996, 0.996, 0.997]\n",
    "auroc_out_CIFAR100 = [0.995, 0.996, 0.995, 0.996]\n",
    "\n",
    "\n",
    "print(\"Laplace Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Laplace Bridge time out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR10), np.std(time_lpb_out_CIFAR10)))\n",
    "print(\"Laplace Bridge time out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR100), np.std(time_lpb_out_CIFAR100)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR10), np.std(mmc_out_CIFAR10)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "\n",
    "print(\"AUROC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR10), np.std(auroc_out_CIFAR10)))\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train on CIFAR100 and test on CIFAR10, SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "CIFAR100_model = ResNet18(num_classes=100).to(device)\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all_CIFAR100():\n",
    "    CIFAR100_path = 'weights/CIFAR100_resnet18_SGD.pth'\n",
    "    lr = 0.1\n",
    "    epoch = 0\n",
    "    for e in [100, 50, 50]:\n",
    "        print(\"current learning rate: \", lr)\n",
    "        for _ in range(e):\n",
    "            optimizer = optim.SGD(CIFAR100_model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "            train(CIFAR100_model, epoch, optimizer, CIFAR100_train_loader, CIFAR100_path)\n",
    "            test(CIFAR100_model, epoch, CIFAR100_test_loader)\n",
    "            epoch += 1\n",
    "        lr /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current learning rate:  0.1\n",
      "\n",
      "Epoch: 0\n",
      "train loss:  1505.484792470932\n",
      "train accuracy:  0.1066\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  276.8743803501129\n",
      "test accuracy:  0.1518\n",
      "\n",
      "Epoch: 1\n",
      "train loss:  1215.2684829235077\n",
      "train accuracy:  0.2225\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  226.92723655700684\n",
      "test accuracy:  0.2713\n",
      "\n",
      "Epoch: 2\n",
      "train loss:  983.4229259490967\n",
      "train accuracy:  0.34046\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  216.82321286201477\n",
      "test accuracy:  0.3151\n",
      "\n",
      "Epoch: 3\n",
      "train loss:  808.1287701129913\n",
      "train accuracy:  0.43846\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  189.58223831653595\n",
      "test accuracy:  0.3747\n",
      "\n",
      "Epoch: 4\n",
      "train loss:  680.4043654203415\n",
      "train accuracy:  0.51208\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  175.06507766246796\n",
      "test accuracy:  0.4172\n",
      "\n",
      "Epoch: 5\n",
      "train loss:  576.6060322523117\n",
      "train accuracy:  0.5796\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  177.59220910072327\n",
      "test accuracy:  0.4274\n",
      "\n",
      "Epoch: 6\n",
      "train loss:  497.3591169118881\n",
      "train accuracy:  0.63222\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  200.8312703371048\n",
      "test accuracy:  0.4086\n",
      "\n",
      "Epoch: 7\n",
      "train loss:  438.169561624527\n",
      "train accuracy:  0.66832\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  205.57873964309692\n",
      "test accuracy:  0.4115\n",
      "\n",
      "Epoch: 8\n",
      "train loss:  377.30245691537857\n",
      "train accuracy:  0.7116\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  216.27668571472168\n",
      "test accuracy:  0.4026\n",
      "\n",
      "Epoch: 9\n",
      "train loss:  336.73587852716446\n",
      "train accuracy:  0.74\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  213.5155246257782\n",
      "test accuracy:  0.4171\n",
      "\n",
      "Epoch: 10\n",
      "train loss:  296.87767910957336\n",
      "train accuracy:  0.76632\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  227.69025707244873\n",
      "test accuracy:  0.3998\n",
      "\n",
      "Epoch: 11\n",
      "train loss:  262.67487025260925\n",
      "train accuracy:  0.79424\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  249.7507073879242\n",
      "test accuracy:  0.3843\n",
      "\n",
      "Epoch: 12\n",
      "train loss:  241.7126768231392\n",
      "train accuracy:  0.80882\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  220.86544275283813\n",
      "test accuracy:  0.4176\n",
      "\n",
      "Epoch: 13\n",
      "train loss:  225.15965741872787\n",
      "train accuracy:  0.82294\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  234.52683091163635\n",
      "test accuracy:  0.3886\n",
      "\n",
      "Epoch: 14\n",
      "train loss:  212.81828129291534\n",
      "train accuracy:  0.83454\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  232.8577778339386\n",
      "test accuracy:  0.4037\n",
      "\n",
      "Epoch: 15\n",
      "train loss:  199.86396825313568\n",
      "train accuracy:  0.84432\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  267.404133439064\n",
      "test accuracy:  0.375\n",
      "\n",
      "Epoch: 16\n",
      "train loss:  197.27969646453857\n",
      "train accuracy:  0.84576\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  288.61303639411926\n",
      "test accuracy:  0.3623\n",
      "\n",
      "Epoch: 17\n",
      "train loss:  191.8108949661255\n",
      "train accuracy:  0.84848\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  264.087553024292\n",
      "test accuracy:  0.373\n",
      "\n",
      "Epoch: 18\n",
      "train loss:  185.66775292158127\n",
      "train accuracy:  0.85632\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  257.266175031662\n",
      "test accuracy:  0.3925\n",
      "\n",
      "Epoch: 19\n",
      "train loss:  185.67065998911858\n",
      "train accuracy:  0.85462\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  229.98966717720032\n",
      "test accuracy:  0.3673\n",
      "\n",
      "Epoch: 20\n",
      "train loss:  180.27554877102375\n",
      "train accuracy:  0.86078\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  235.38860249519348\n",
      "test accuracy:  0.3985\n",
      "\n",
      "Epoch: 21\n",
      "train loss:  179.55741022527218\n",
      "train accuracy:  0.85956\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  217.33456325531006\n",
      "test accuracy:  0.4362\n",
      "\n",
      "Epoch: 22\n",
      "train loss:  176.71389850974083\n",
      "train accuracy:  0.86182\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  225.19140625\n",
      "test accuracy:  0.4205\n",
      "\n",
      "Epoch: 23\n",
      "train loss:  180.4629272222519\n",
      "train accuracy:  0.86\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  263.616975069046\n",
      "test accuracy:  0.3994\n",
      "\n",
      "Epoch: 24\n",
      "train loss:  172.97695468366146\n",
      "train accuracy:  0.8651\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  266.64746594429016\n",
      "test accuracy:  0.402\n",
      "\n",
      "Epoch: 25\n",
      "train loss:  171.16946145892143\n",
      "train accuracy:  0.86568\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  271.55393385887146\n",
      "test accuracy:  0.3913\n",
      "\n",
      "Epoch: 26\n",
      "train loss:  171.17252279818058\n",
      "train accuracy:  0.86804\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  229.08900809288025\n",
      "test accuracy:  0.4244\n",
      "\n",
      "Epoch: 27\n",
      "train loss:  169.98347958922386\n",
      "train accuracy:  0.86796\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  222.25923037528992\n",
      "test accuracy:  0.4229\n",
      "\n",
      "Epoch: 28\n",
      "train loss:  170.06183724105358\n",
      "train accuracy:  0.8671\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  235.5997338294983\n",
      "test accuracy:  0.4148\n",
      "\n",
      "Epoch: 29\n",
      "train loss:  164.5463070422411\n",
      "train accuracy:  0.87286\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  219.88880133628845\n",
      "test accuracy:  0.4231\n",
      "\n",
      "Epoch: 30\n",
      "train loss:  170.525455057621\n",
      "train accuracy:  0.86882\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  246.1376233100891\n",
      "test accuracy:  0.4102\n",
      "\n",
      "Epoch: 31\n",
      "train loss:  168.9936192780733\n",
      "train accuracy:  0.8682\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  258.9280297756195\n",
      "test accuracy:  0.3997\n",
      "\n",
      "Epoch: 32\n",
      "train loss:  163.0963929593563\n",
      "train accuracy:  0.87426\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  241.23520755767822\n",
      "test accuracy:  0.4249\n",
      "\n",
      "Epoch: 33\n",
      "train loss:  163.94483092427254\n",
      "train accuracy:  0.87414\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  239.96035242080688\n",
      "test accuracy:  0.405\n",
      "\n",
      "Epoch: 34\n",
      "train loss:  163.62336179614067\n",
      "train accuracy:  0.87402\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  275.44565057754517\n",
      "test accuracy:  0.3905\n",
      "\n",
      "Epoch: 35\n",
      "train loss:  160.48429475724697\n",
      "train accuracy:  0.87428\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  262.3873379230499\n",
      "test accuracy:  0.3975\n",
      "\n",
      "Epoch: 36\n",
      "train loss:  165.27148689329624\n",
      "train accuracy:  0.87316\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  240.91920447349548\n",
      "test accuracy:  0.412\n",
      "\n",
      "Epoch: 37\n",
      "train loss:  161.6911739706993\n",
      "train accuracy:  0.87612\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  239.67614889144897\n",
      "test accuracy:  0.4065\n",
      "\n",
      "Epoch: 38\n",
      "train loss:  163.1074887663126\n",
      "train accuracy:  0.87488\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  248.2048373222351\n",
      "test accuracy:  0.417\n",
      "\n",
      "Epoch: 39\n",
      "train loss:  163.23175153136253\n",
      "train accuracy:  0.8735\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  233.92307782173157\n",
      "test accuracy:  0.418\n",
      "\n",
      "Epoch: 40\n",
      "train loss:  161.24293507635593\n",
      "train accuracy:  0.875\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  233.8397662639618\n",
      "test accuracy:  0.4117\n",
      "\n",
      "Epoch: 41\n",
      "train loss:  161.38734976947308\n",
      "train accuracy:  0.87608\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  243.91518115997314\n",
      "test accuracy:  0.4144\n",
      "\n",
      "Epoch: 42\n",
      "train loss:  157.92190065979958\n",
      "train accuracy:  0.87756\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  231.6211760044098\n",
      "test accuracy:  0.4316\n",
      "\n",
      "Epoch: 43\n",
      "train loss:  160.08572018146515\n",
      "train accuracy:  0.87654\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  218.63688945770264\n",
      "test accuracy:  0.4373\n",
      "\n",
      "Epoch: 44\n",
      "train loss:  157.10749758780003\n",
      "train accuracy:  0.87918\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  231.93163335323334\n",
      "test accuracy:  0.4133\n",
      "\n",
      "Epoch: 45\n",
      "train loss:  162.57832846045494\n",
      "train accuracy:  0.87386\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  225.63482022285461\n",
      "test accuracy:  0.4214\n",
      "\n",
      "Epoch: 46\n",
      "train loss:  154.18418404459953\n",
      "train accuracy:  0.88078\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  298.29621148109436\n",
      "test accuracy:  0.3758\n",
      "\n",
      "Epoch: 47\n",
      "train loss:  158.31871639192104\n",
      "train accuracy:  0.879\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  242.96061539649963\n",
      "test accuracy:  0.4224\n",
      "\n",
      "Epoch: 48\n",
      "train loss:  159.72696191072464\n",
      "train accuracy:  0.8762\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  239.18833446502686\n",
      "test accuracy:  0.4234\n",
      "\n",
      "Epoch: 49\n",
      "train loss:  158.92351952195168\n",
      "train accuracy:  0.87764\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  255.9475769996643\n",
      "test accuracy:  0.4048\n",
      "\n",
      "Epoch: 50\n",
      "train loss:  154.14392052590847\n",
      "train accuracy:  0.88182\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  229.60609912872314\n",
      "test accuracy:  0.4234\n",
      "\n",
      "Epoch: 51\n",
      "train loss:  158.4327777773142\n",
      "train accuracy:  0.8784\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  235.13265538215637\n",
      "test accuracy:  0.4139\n",
      "\n",
      "Epoch: 52\n",
      "train loss:  153.73919370770454\n",
      "train accuracy:  0.88132\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  231.72642302513123\n",
      "test accuracy:  0.4363\n",
      "\n",
      "Epoch: 53\n",
      "train loss:  161.7436589896679\n",
      "train accuracy:  0.87464\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  238.368661403656\n",
      "test accuracy:  0.4173\n",
      "\n",
      "Epoch: 54\n",
      "train loss:  161.6238830089569\n",
      "train accuracy:  0.87518\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  236.84829235076904\n",
      "test accuracy:  0.441\n",
      "\n",
      "Epoch: 55\n",
      "train loss:  158.32370430231094\n",
      "train accuracy:  0.87776\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  231.9273443222046\n",
      "test accuracy:  0.4241\n",
      "\n",
      "Epoch: 56\n",
      "train loss:  153.68659760057926\n",
      "train accuracy:  0.88236\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  229.59492802619934\n",
      "test accuracy:  0.4479\n",
      "\n",
      "Epoch: 57\n",
      "train loss:  152.61107398569584\n",
      "train accuracy:  0.88272\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  238.7418510913849\n",
      "test accuracy:  0.4245\n",
      "\n",
      "Epoch: 58\n",
      "train loss:  161.3465175330639\n",
      "train accuracy:  0.87568\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  218.5238721370697\n",
      "test accuracy:  0.4323\n",
      "\n",
      "Epoch: 59\n",
      "train loss:  157.0288057476282\n",
      "train accuracy:  0.87946\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  232.3540074825287\n",
      "test accuracy:  0.4256\n",
      "\n",
      "Epoch: 60\n",
      "train loss:  155.884470179677\n",
      "train accuracy:  0.87998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  235.80398178100586\n",
      "test accuracy:  0.4354\n",
      "\n",
      "Epoch: 61\n",
      "train loss:  151.7347723543644\n",
      "train accuracy:  0.88396\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  237.21221351623535\n",
      "test accuracy:  0.4133\n",
      "\n",
      "Epoch: 62\n",
      "train loss:  153.1507119089365\n",
      "train accuracy:  0.88242\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  227.7249939441681\n",
      "test accuracy:  0.4214\n",
      "\n",
      "Epoch: 63\n",
      "train loss:  157.04605177044868\n",
      "train accuracy:  0.8798\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  224.28792667388916\n",
      "test accuracy:  0.4232\n",
      "\n",
      "Epoch: 64\n",
      "train loss:  157.08563125133514\n",
      "train accuracy:  0.88076\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  255.57421493530273\n",
      "test accuracy:  0.4055\n",
      "\n",
      "Epoch: 65\n",
      "train loss:  150.10719047486782\n",
      "train accuracy:  0.88322\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  228.0431616306305\n",
      "test accuracy:  0.4342\n",
      "\n",
      "Epoch: 66\n",
      "train loss:  157.39607293903828\n",
      "train accuracy:  0.87898\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  236.85383355617523\n",
      "test accuracy:  0.4219\n",
      "\n",
      "Epoch: 67\n",
      "train loss:  164.7055923640728\n",
      "train accuracy:  0.87228\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  229.00219011306763\n",
      "test accuracy:  0.4488\n",
      "\n",
      "Epoch: 68\n",
      "train loss:  150.75080101191998\n",
      "train accuracy:  0.88452\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  226.86661517620087\n",
      "test accuracy:  0.4393\n",
      "\n",
      "Epoch: 69\n",
      "train loss:  157.34364973008633\n",
      "train accuracy:  0.87952\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  281.72901248931885\n",
      "test accuracy:  0.3905\n",
      "\n",
      "Epoch: 70\n",
      "train loss:  153.01309277117252\n",
      "train accuracy:  0.88298\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  220.35166144371033\n",
      "test accuracy:  0.4462\n",
      "\n",
      "Epoch: 71\n",
      "train loss:  155.5734533816576\n",
      "train accuracy:  0.88092\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  243.16321468353271\n",
      "test accuracy:  0.4183\n",
      "\n",
      "Epoch: 72\n",
      "train loss:  151.43638230860233\n",
      "train accuracy:  0.88426\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  239.57684540748596\n",
      "test accuracy:  0.4332\n",
      "\n",
      "Epoch: 73\n",
      "train loss:  159.8831251859665\n",
      "train accuracy:  0.87758\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  218.9357647895813\n",
      "test accuracy:  0.4506\n",
      "\n",
      "Epoch: 74\n",
      "train loss:  152.29215644299984\n",
      "train accuracy:  0.88346\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  245.76192092895508\n",
      "test accuracy:  0.4327\n",
      "\n",
      "Epoch: 75\n",
      "train loss:  158.5678576529026\n",
      "train accuracy:  0.87722\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  217.71503067016602\n",
      "test accuracy:  0.4473\n",
      "\n",
      "Epoch: 76\n",
      "train loss:  157.40443097054958\n",
      "train accuracy:  0.87926\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  239.0524685382843\n",
      "test accuracy:  0.4271\n",
      "\n",
      "Epoch: 77\n",
      "train loss:  152.85191506147385\n",
      "train accuracy:  0.88286\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  255.60468804836273\n",
      "test accuracy:  0.4256\n",
      "\n",
      "Epoch: 78\n",
      "train loss:  151.75825265049934\n",
      "train accuracy:  0.88214\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  224.61480736732483\n",
      "test accuracy:  0.4453\n",
      "\n",
      "Epoch: 79\n",
      "train loss:  163.86940152943134\n",
      "train accuracy:  0.8741\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  233.1586023569107\n",
      "test accuracy:  0.4438\n",
      "\n",
      "Epoch: 80\n",
      "train loss:  153.595154479146\n",
      "train accuracy:  0.88244\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  240.8665804862976\n",
      "test accuracy:  0.433\n",
      "\n",
      "Epoch: 81\n",
      "train loss:  154.86743959784508\n",
      "train accuracy:  0.88164\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  244.25687551498413\n",
      "test accuracy:  0.4354\n",
      "\n",
      "Epoch: 82\n",
      "train loss:  155.66059957444668\n",
      "train accuracy:  0.88132\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  248.58474111557007\n",
      "test accuracy:  0.4232\n",
      "\n",
      "Epoch: 83\n",
      "train loss:  153.39517876505852\n",
      "train accuracy:  0.88348\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  238.0751667022705\n",
      "test accuracy:  0.4267\n",
      "\n",
      "Epoch: 84\n",
      "train loss:  153.43294854462147\n",
      "train accuracy:  0.88222\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  235.9156367778778\n",
      "test accuracy:  0.4126\n",
      "\n",
      "Epoch: 85\n",
      "train loss:  156.86311635375023\n",
      "train accuracy:  0.88052\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  229.8398473262787\n",
      "test accuracy:  0.4313\n",
      "\n",
      "Epoch: 86\n",
      "train loss:  157.98092213273048\n",
      "train accuracy:  0.8794\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  242.1678545475006\n",
      "test accuracy:  0.4205\n",
      "\n",
      "Epoch: 87\n",
      "train loss:  157.25092309713364\n",
      "train accuracy:  0.87918\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  255.80161237716675\n",
      "test accuracy:  0.3738\n",
      "\n",
      "Epoch: 88\n",
      "train loss:  156.4214822202921\n",
      "train accuracy:  0.87966\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  259.8279023170471\n",
      "test accuracy:  0.4058\n",
      "\n",
      "Epoch: 89\n",
      "train loss:  153.96869212388992\n",
      "train accuracy:  0.88302\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  227.47515511512756\n",
      "test accuracy:  0.4375\n",
      "\n",
      "Epoch: 90\n",
      "train loss:  155.88599875569344\n",
      "train accuracy:  0.88082\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  214.2453637123108\n",
      "test accuracy:  0.4546\n",
      "\n",
      "Epoch: 91\n",
      "train loss:  155.32686917483807\n",
      "train accuracy:  0.88148\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  230.26267409324646\n",
      "test accuracy:  0.4204\n",
      "\n",
      "Epoch: 92\n",
      "train loss:  154.97397774457932\n",
      "train accuracy:  0.88134\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  244.65247917175293\n",
      "test accuracy:  0.4216\n",
      "\n",
      "Epoch: 93\n",
      "train loss:  157.20471122860909\n",
      "train accuracy:  0.87976\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  243.80367946624756\n",
      "test accuracy:  0.3929\n",
      "\n",
      "Epoch: 94\n",
      "train loss:  149.76974046230316\n",
      "train accuracy:  0.88504\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  239.7504894733429\n",
      "test accuracy:  0.4291\n",
      "\n",
      "Epoch: 95\n",
      "train loss:  158.53533709049225\n",
      "train accuracy:  0.87692\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  244.8308084011078\n",
      "test accuracy:  0.4122\n",
      "\n",
      "Epoch: 96\n",
      "train loss:  146.49452583491802\n",
      "train accuracy:  0.88712\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  233.39905834197998\n",
      "test accuracy:  0.4355\n",
      "\n",
      "Epoch: 97\n",
      "train loss:  159.36918805539608\n",
      "train accuracy:  0.87618\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  233.98640084266663\n",
      "test accuracy:  0.4326\n",
      "\n",
      "Epoch: 98\n",
      "train loss:  156.78728100657463\n",
      "train accuracy:  0.88108\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  214.5253517627716\n",
      "test accuracy:  0.4479\n",
      "\n",
      "Epoch: 99\n",
      "train loss:  144.48354351520538\n",
      "train accuracy:  0.8888\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  247.35405468940735\n",
      "test accuracy:  0.4262\n",
      "current learning rate:  0.01\n",
      "\n",
      "Epoch: 100\n",
      "train loss:  70.70228352025151\n",
      "train accuracy:  0.94684\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  137.72414243221283\n",
      "test accuracy:  0.5858\n",
      "\n",
      "Epoch: 101\n",
      "train loss:  9.55387856438756\n",
      "train accuracy:  0.99836\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  136.94543087482452\n",
      "test accuracy:  0.5874\n",
      "\n",
      "Epoch: 102\n",
      "train loss:  5.501346152275801\n",
      "train accuracy:  0.9994\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  136.47304332256317\n",
      "test accuracy:  0.5891\n",
      "\n",
      "Epoch: 103\n",
      "train loss:  4.536581188440323\n",
      "train accuracy:  0.99966\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  135.82915008068085\n",
      "test accuracy:  0.5888\n",
      "\n",
      "Epoch: 104\n",
      "train loss:  4.023317608982325\n",
      "train accuracy:  0.99986\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  135.1339591741562\n",
      "test accuracy:  0.5901\n",
      "\n",
      "Epoch: 105\n",
      "train loss:  3.7332621328532696\n",
      "train accuracy:  0.99996\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  134.4408653974533\n",
      "test accuracy:  0.5904\n",
      "\n",
      "Epoch: 106\n",
      "train loss:  3.5702466890215874\n",
      "train accuracy:  0.99996\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  133.7765632867813\n",
      "test accuracy:  0.591\n",
      "\n",
      "Epoch: 107\n",
      "train loss:  3.4775825887918472\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  133.16439986228943\n",
      "test accuracy:  0.5914\n",
      "\n",
      "Epoch: 108\n",
      "train loss:  3.425614356994629\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  132.6192318201065\n",
      "test accuracy:  0.5927\n",
      "\n",
      "Epoch: 109\n",
      "train loss:  3.3969814628362656\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  132.14284455776215\n",
      "test accuracy:  0.5928\n",
      "\n",
      "Epoch: 110\n",
      "train loss:  3.383168287575245\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  131.74254548549652\n",
      "test accuracy:  0.5937\n",
      "\n",
      "Epoch: 111\n",
      "train loss:  3.377998512238264\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  131.40996730327606\n",
      "test accuracy:  0.5941\n",
      "\n",
      "Epoch: 112\n",
      "train loss:  3.3768697939813137\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  131.15226566791534\n",
      "test accuracy:  0.5941\n",
      "\n",
      "Epoch: 113\n",
      "train loss:  3.3777614794671535\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  130.96202683448792\n",
      "test accuracy:  0.5947\n",
      "\n",
      "Epoch: 114\n",
      "train loss:  3.3792215026915073\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  130.85054349899292\n",
      "test accuracy:  0.595\n",
      "\n",
      "Epoch: 115\n",
      "train loss:  3.3794974833726883\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  130.80205714702606\n",
      "test accuracy:  0.5964\n",
      "\n",
      "Epoch: 116\n",
      "train loss:  3.378274541348219\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  130.812934756279\n",
      "test accuracy:  0.5959\n",
      "\n",
      "Epoch: 117\n",
      "train loss:  3.3753321692347527\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  130.88227367401123\n",
      "test accuracy:  0.5959\n",
      "\n",
      "Epoch: 118\n",
      "train loss:  3.3702724054455757\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  131.01427817344666\n",
      "test accuracy:  0.5964\n",
      "\n",
      "Epoch: 119\n",
      "train loss:  3.362968847155571\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  131.18397212028503\n",
      "test accuracy:  0.5956\n",
      "\n",
      "Epoch: 120\n",
      "train loss:  3.354548431932926\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  131.4001543521881\n",
      "test accuracy:  0.5963\n",
      "\n",
      "Epoch: 121\n",
      "train loss:  3.3448200039565563\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  131.6526461839676\n",
      "test accuracy:  0.5963\n",
      "\n",
      "Epoch: 122\n",
      "train loss:  3.333890687674284\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  131.94482493400574\n",
      "test accuracy:  0.5958\n",
      "\n",
      "Epoch: 123\n",
      "train loss:  3.321825761348009\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  132.27018117904663\n",
      "test accuracy:  0.5956\n",
      "\n",
      "Epoch: 124\n",
      "train loss:  3.309196475893259\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  132.61731052398682\n",
      "test accuracy:  0.5955\n",
      "\n",
      "Epoch: 125\n",
      "train loss:  3.296225380152464\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  132.99178290367126\n",
      "test accuracy:  0.5955\n",
      "\n",
      "Epoch: 126\n",
      "train loss:  3.283077571541071\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  133.3741443157196\n",
      "test accuracy:  0.5954\n",
      "\n",
      "Epoch: 127\n",
      "train loss:  3.270728498697281\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  133.78044545650482\n",
      "test accuracy:  0.5954\n",
      "\n",
      "Epoch: 128\n",
      "train loss:  3.258693229407072\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  134.1943198442459\n",
      "test accuracy:  0.5949\n",
      "\n",
      "Epoch: 129\n",
      "train loss:  3.2473006546497345\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  134.60483181476593\n",
      "test accuracy:  0.5946\n",
      "\n",
      "Epoch: 130\n",
      "train loss:  3.2366879545152187\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  135.02092719078064\n",
      "test accuracy:  0.594\n",
      "\n",
      "Epoch: 131\n",
      "train loss:  3.226962771266699\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  135.4420508146286\n",
      "test accuracy:  0.594\n",
      "\n",
      "Epoch: 132\n",
      "train loss:  3.217624794691801\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  135.8562731742859\n",
      "test accuracy:  0.5953\n",
      "\n",
      "Epoch: 133\n",
      "train loss:  3.2091462314128876\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  136.26534581184387\n",
      "test accuracy:  0.596\n",
      "\n",
      "Epoch: 134\n",
      "train loss:  3.201131384819746\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  136.66356658935547\n",
      "test accuracy:  0.5966\n",
      "\n",
      "Epoch: 135\n",
      "train loss:  3.1936323791742325\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  137.0453737974167\n",
      "test accuracy:  0.5969\n",
      "\n",
      "Epoch: 136\n",
      "train loss:  3.18639699742198\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  137.4296145439148\n",
      "test accuracy:  0.597\n",
      "\n",
      "Epoch: 137\n",
      "train loss:  3.1791077256202698\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  137.796741604805\n",
      "test accuracy:  0.5972\n",
      "\n",
      "Epoch: 138\n",
      "train loss:  3.171895384788513\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  138.14851677417755\n",
      "test accuracy:  0.5973\n",
      "\n",
      "Epoch: 139\n",
      "train loss:  3.1641274765133858\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  138.48773300647736\n",
      "test accuracy:  0.5966\n",
      "\n",
      "Epoch: 140\n",
      "train loss:  3.156271532177925\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  138.8091106414795\n",
      "test accuracy:  0.5958\n",
      "\n",
      "Epoch: 141\n",
      "train loss:  3.148124184459448\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  139.13394916057587\n",
      "test accuracy:  0.5962\n",
      "\n",
      "Epoch: 142\n",
      "train loss:  3.1391675621271133\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  139.4477391242981\n",
      "test accuracy:  0.5958\n",
      "\n",
      "Epoch: 143\n",
      "train loss:  3.1299172304570675\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  139.763174533844\n",
      "test accuracy:  0.596\n",
      "\n",
      "Epoch: 144\n",
      "train loss:  3.1678294986486435\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  140.06699419021606\n",
      "test accuracy:  0.5958\n",
      "\n",
      "Epoch: 145\n",
      "train loss:  3.2509724497795105\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  140.24841010570526\n",
      "test accuracy:  0.5966\n",
      "\n",
      "Epoch: 146\n",
      "train loss:  3.1894267424941063\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  140.53623259067535\n",
      "test accuracy:  0.5963\n",
      "\n",
      "Epoch: 147\n",
      "train loss:  3.1276372708380222\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  140.88379073143005\n",
      "test accuracy:  0.5974\n",
      "\n",
      "Epoch: 148\n",
      "train loss:  3.20934084802866\n",
      "train accuracy:  0.99994\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.0236201286316\n",
      "test accuracy:  0.5976\n",
      "\n",
      "Epoch: 149\n",
      "train loss:  3.409605212509632\n",
      "train accuracy:  0.99992\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.1812551021576\n",
      "test accuracy:  0.5968\n",
      "current learning rate:  0.001\n",
      "\n",
      "Epoch: 150\n",
      "train loss:  3.045342341065407\n",
      "train accuracy:  0.99998\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.2871434688568\n",
      "test accuracy:  0.5976\n",
      "\n",
      "Epoch: 151\n",
      "train loss:  2.9929152466356754\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.3630554676056\n",
      "test accuracy:  0.5972\n",
      "\n",
      "Epoch: 152\n",
      "train loss:  2.9787848442792892\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.44425785541534\n",
      "test accuracy:  0.5972\n",
      "\n",
      "Epoch: 153\n",
      "train loss:  2.971279952675104\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.5180106163025\n",
      "test accuracy:  0.5971\n",
      "\n",
      "Epoch: 154\n",
      "train loss:  2.966505851596594\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.58488953113556\n",
      "test accuracy:  0.5967\n",
      "\n",
      "Epoch: 155\n",
      "train loss:  2.963198184967041\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.64604139328003\n",
      "test accuracy:  0.5964\n",
      "\n",
      "Epoch: 156\n",
      "train loss:  2.960752494633198\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.70295917987823\n",
      "test accuracy:  0.5969\n",
      "\n",
      "Epoch: 157\n",
      "train loss:  2.9588671065866947\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.7556313276291\n",
      "test accuracy:  0.5973\n",
      "\n",
      "Epoch: 158\n",
      "train loss:  2.9573771581053734\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.80341589450836\n",
      "test accuracy:  0.5972\n",
      "\n",
      "Epoch: 159\n",
      "train loss:  2.9561669416725636\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.848961353302\n",
      "test accuracy:  0.5972\n",
      "\n",
      "Epoch: 160\n",
      "train loss:  2.955162238329649\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.89186692237854\n",
      "test accuracy:  0.5972\n",
      "\n",
      "Epoch: 161\n",
      "train loss:  2.9543045461177826\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.93292713165283\n",
      "test accuracy:  0.5973\n",
      "\n",
      "Epoch: 162\n",
      "train loss:  2.9535622224211693\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  141.97212541103363\n",
      "test accuracy:  0.5974\n",
      "\n",
      "Epoch: 163\n",
      "train loss:  2.9528952464461327\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.01023972034454\n",
      "test accuracy:  0.5976\n",
      "\n",
      "Epoch: 164\n",
      "train loss:  2.952275350689888\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.04667901992798\n",
      "test accuracy:  0.5976\n",
      "\n",
      "Epoch: 165\n",
      "train loss:  2.951690699905157\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.0818247795105\n",
      "test accuracy:  0.5975\n",
      "\n",
      "Epoch: 166\n",
      "train loss:  2.951131660491228\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.1161708831787\n",
      "test accuracy:  0.5979\n",
      "\n",
      "Epoch: 167\n",
      "train loss:  2.950592566281557\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.15087389945984\n",
      "test accuracy:  0.5979\n",
      "\n",
      "Epoch: 168\n",
      "train loss:  2.9500728584825993\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.1844106912613\n",
      "test accuracy:  0.5979\n",
      "\n",
      "Epoch: 169\n",
      "train loss:  2.949555531144142\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.21758830547333\n",
      "test accuracy:  0.598\n",
      "\n",
      "Epoch: 170\n",
      "train loss:  2.9490385577082634\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.2502111196518\n",
      "test accuracy:  0.5978\n",
      "\n",
      "Epoch: 171\n",
      "train loss:  2.948508359491825\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.28237760066986\n",
      "test accuracy:  0.5979\n",
      "\n",
      "Epoch: 172\n",
      "train loss:  2.9479708932340145\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.31461906433105\n",
      "test accuracy:  0.598\n",
      "\n",
      "Epoch: 173\n",
      "train loss:  2.9474137276411057\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.3460532426834\n",
      "test accuracy:  0.5981\n",
      "\n",
      "Epoch: 174\n",
      "train loss:  2.946845106780529\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.37674510478973\n",
      "test accuracy:  0.5984\n",
      "\n",
      "Epoch: 175\n",
      "train loss:  2.9462505765259266\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.4078096151352\n",
      "test accuracy:  0.5983\n",
      "\n",
      "Epoch: 176\n",
      "train loss:  2.945630230009556\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.43855440616608\n",
      "test accuracy:  0.5979\n",
      "\n",
      "Epoch: 177\n",
      "train loss:  2.9449977688491344\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.46912813186646\n",
      "test accuracy:  0.5979\n",
      "\n",
      "Epoch: 178\n",
      "train loss:  2.9443392269313335\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.50024592876434\n",
      "test accuracy:  0.5979\n",
      "\n",
      "Epoch: 179\n",
      "train loss:  2.9436581060290337\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.53055369853973\n",
      "test accuracy:  0.5978\n",
      "\n",
      "Epoch: 180\n",
      "train loss:  2.942953899502754\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.56089901924133\n",
      "test accuracy:  0.5978\n",
      "\n",
      "Epoch: 181\n",
      "train loss:  2.942222960293293\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.5915343761444\n",
      "test accuracy:  0.5979\n",
      "\n",
      "Epoch: 182\n",
      "train loss:  2.941464003175497\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.62242078781128\n",
      "test accuracy:  0.5979\n",
      "\n",
      "Epoch: 183\n",
      "train loss:  2.9406865909695625\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.65286374092102\n",
      "test accuracy:  0.5977\n",
      "\n",
      "Epoch: 184\n",
      "train loss:  2.939887370914221\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.6833815574646\n",
      "test accuracy:  0.5977\n",
      "\n",
      "Epoch: 185\n",
      "train loss:  2.939067829400301\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.71382427215576\n",
      "test accuracy:  0.5976\n",
      "\n",
      "Epoch: 186\n",
      "train loss:  2.9382188953459263\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.74435222148895\n",
      "test accuracy:  0.5976\n",
      "\n",
      "Epoch: 187\n",
      "train loss:  2.9373513534665108\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.7740535736084\n",
      "test accuracy:  0.5979\n",
      "\n",
      "Epoch: 188\n",
      "train loss:  2.9364610612392426\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.80442595481873\n",
      "test accuracy:  0.5982\n",
      "\n",
      "Epoch: 189\n",
      "train loss:  2.935541596263647\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.83497893810272\n",
      "test accuracy:  0.5983\n",
      "\n",
      "Epoch: 190\n",
      "train loss:  2.9346024580299854\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.86601746082306\n",
      "test accuracy:  0.5984\n",
      "\n",
      "Epoch: 191\n",
      "train loss:  2.9336383752524853\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.89568865299225\n",
      "test accuracy:  0.5982\n",
      "\n",
      "Epoch: 192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.932649005204439\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.92631673812866\n",
      "test accuracy:  0.5985\n",
      "\n",
      "Epoch: 193\n",
      "train loss:  2.93164099752903\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.95696532726288\n",
      "test accuracy:  0.5988\n",
      "\n",
      "Epoch: 194\n",
      "train loss:  2.9306061565876007\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  142.98753809928894\n",
      "test accuracy:  0.5986\n",
      "\n",
      "Epoch: 195\n",
      "train loss:  2.9295422062277794\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.01770746707916\n",
      "test accuracy:  0.5985\n",
      "\n",
      "Epoch: 196\n",
      "train loss:  2.928451646119356\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.0469024181366\n",
      "test accuracy:  0.5987\n",
      "\n",
      "Epoch: 197\n",
      "train loss:  2.9273421242833138\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.0764044523239\n",
      "test accuracy:  0.5988\n",
      "\n",
      "Epoch: 198\n",
      "train loss:  2.9262074381113052\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.10543870925903\n",
      "test accuracy:  0.5987\n",
      "\n",
      "Epoch: 199\n",
      "train loss:  2.9250523149967194\n",
      "train accuracy:  1.0\n",
      "saving model at: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.13504207134247\n",
      "test accuracy:  0.5986\n"
     ]
    }
   ],
   "source": [
    "train_all_CIFAR100()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from: weights/CIFAR100_resnet18_SGD.pth\n",
      "test loss:  143.13504207134247\n",
      "test accuracy:  0.5986\n"
     ]
    }
   ],
   "source": [
    "##### if you already have a trained model ##############\n",
    "CIFAR100_PATH = 'weights/CIFAR100_resnet18_SGD.pth'\n",
    "CIFAR100_model = ResNet18(num_classes=100).to(device)\n",
    "print(\"loading model from: {}\".format(CIFAR100_PATH))\n",
    "CIFAR100_model.load_state_dict(torch.load(CIFAR100_PATH))#, map_location=torch.device('cpu')))\n",
    "#test the model\n",
    "test(CIFAR100_model, 0, CIFAR100_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 512 inputs to linear layer with m: 100 classes\n",
      "Batch: 0/391\n",
      "Batch: 1/391\n",
      "Batch: 2/391\n",
      "Batch: 3/391\n",
      "Batch: 4/391\n",
      "Batch: 5/391\n",
      "Batch: 6/391\n",
      "Batch: 7/391\n",
      "Batch: 8/391\n",
      "Batch: 9/391\n",
      "Batch: 10/391\n",
      "Batch: 11/391\n",
      "Batch: 12/391\n",
      "Batch: 13/391\n",
      "Batch: 14/391\n",
      "Batch: 15/391\n",
      "Batch: 16/391\n",
      "Batch: 17/391\n",
      "Batch: 18/391\n",
      "Batch: 19/391\n",
      "Batch: 20/391\n",
      "Batch: 21/391\n",
      "Batch: 22/391\n",
      "Batch: 23/391\n",
      "Batch: 24/391\n",
      "Batch: 25/391\n",
      "Batch: 26/391\n",
      "Batch: 27/391\n",
      "Batch: 28/391\n",
      "Batch: 29/391\n",
      "Batch: 30/391\n",
      "Batch: 31/391\n",
      "Batch: 32/391\n",
      "Batch: 33/391\n",
      "Batch: 34/391\n",
      "Batch: 35/391\n",
      "Batch: 36/391\n",
      "Batch: 37/391\n",
      "Batch: 38/391\n",
      "Batch: 39/391\n",
      "Batch: 40/391\n",
      "Batch: 41/391\n",
      "Batch: 42/391\n",
      "Batch: 43/391\n",
      "Batch: 44/391\n",
      "Batch: 45/391\n",
      "Batch: 46/391\n",
      "Batch: 47/391\n",
      "Batch: 48/391\n",
      "Batch: 49/391\n",
      "Batch: 50/391\n",
      "Batch: 51/391\n",
      "Batch: 52/391\n",
      "Batch: 53/391\n",
      "Batch: 54/391\n",
      "Batch: 55/391\n",
      "Batch: 56/391\n",
      "Batch: 57/391\n",
      "Batch: 58/391\n",
      "Batch: 59/391\n",
      "Batch: 60/391\n",
      "Batch: 61/391\n",
      "Batch: 62/391\n",
      "Batch: 63/391\n",
      "Batch: 64/391\n",
      "Batch: 65/391\n",
      "Batch: 66/391\n",
      "Batch: 67/391\n",
      "Batch: 68/391\n",
      "Batch: 69/391\n",
      "Batch: 70/391\n",
      "Batch: 71/391\n",
      "Batch: 72/391\n",
      "Batch: 73/391\n",
      "Batch: 74/391\n",
      "Batch: 75/391\n",
      "Batch: 76/391\n",
      "Batch: 77/391\n",
      "Batch: 78/391\n",
      "Batch: 79/391\n",
      "Batch: 80/391\n",
      "Batch: 81/391\n",
      "Batch: 82/391\n",
      "Batch: 83/391\n",
      "Batch: 84/391\n",
      "Batch: 85/391\n",
      "Batch: 86/391\n",
      "Batch: 87/391\n",
      "Batch: 88/391\n",
      "Batch: 89/391\n",
      "Batch: 90/391\n",
      "Batch: 91/391\n",
      "Batch: 92/391\n",
      "Batch: 93/391\n",
      "Batch: 94/391\n",
      "Batch: 95/391\n",
      "Batch: 96/391\n",
      "Batch: 97/391\n",
      "Batch: 98/391\n",
      "Batch: 99/391\n",
      "Batch: 100/391\n",
      "Batch: 101/391\n",
      "Batch: 102/391\n",
      "Batch: 103/391\n",
      "Batch: 104/391\n",
      "Batch: 105/391\n",
      "Batch: 106/391\n",
      "Batch: 107/391\n",
      "Batch: 108/391\n",
      "Batch: 109/391\n",
      "Batch: 110/391\n",
      "Batch: 111/391\n",
      "Batch: 112/391\n",
      "Batch: 113/391\n",
      "Batch: 114/391\n",
      "Batch: 115/391\n",
      "Batch: 116/391\n",
      "Batch: 117/391\n",
      "Batch: 118/391\n",
      "Batch: 119/391\n",
      "Batch: 120/391\n",
      "Batch: 121/391\n",
      "Batch: 122/391\n",
      "Batch: 123/391\n",
      "Batch: 124/391\n",
      "Batch: 125/391\n",
      "Batch: 126/391\n",
      "Batch: 127/391\n",
      "Batch: 128/391\n",
      "Batch: 129/391\n",
      "Batch: 130/391\n",
      "Batch: 131/391\n",
      "Batch: 132/391\n",
      "Batch: 133/391\n",
      "Batch: 134/391\n",
      "Batch: 135/391\n",
      "Batch: 136/391\n",
      "Batch: 137/391\n",
      "Batch: 138/391\n",
      "Batch: 139/391\n",
      "Batch: 140/391\n",
      "Batch: 141/391\n",
      "Batch: 142/391\n",
      "Batch: 143/391\n",
      "Batch: 144/391\n",
      "Batch: 145/391\n",
      "Batch: 146/391\n",
      "Batch: 147/391\n",
      "Batch: 148/391\n",
      "Batch: 149/391\n",
      "Batch: 150/391\n",
      "Batch: 151/391\n",
      "Batch: 152/391\n",
      "Batch: 153/391\n",
      "Batch: 154/391\n",
      "Batch: 155/391\n",
      "Batch: 156/391\n",
      "Batch: 157/391\n",
      "Batch: 158/391\n",
      "Batch: 159/391\n",
      "Batch: 160/391\n",
      "Batch: 161/391\n",
      "Batch: 162/391\n",
      "Batch: 163/391\n",
      "Batch: 164/391\n",
      "Batch: 165/391\n",
      "Batch: 166/391\n",
      "Batch: 167/391\n",
      "Batch: 168/391\n",
      "Batch: 169/391\n",
      "Batch: 170/391\n",
      "Batch: 171/391\n",
      "Batch: 172/391\n",
      "Batch: 173/391\n",
      "Batch: 174/391\n",
      "Batch: 175/391\n",
      "Batch: 176/391\n",
      "Batch: 177/391\n",
      "Batch: 178/391\n",
      "Batch: 179/391\n",
      "Batch: 180/391\n",
      "Batch: 181/391\n",
      "Batch: 182/391\n",
      "Batch: 183/391\n",
      "Batch: 184/391\n",
      "Batch: 185/391\n",
      "Batch: 186/391\n",
      "Batch: 187/391\n",
      "Batch: 188/391\n",
      "Batch: 189/391\n",
      "Batch: 190/391\n",
      "Batch: 191/391\n",
      "Batch: 192/391\n",
      "Batch: 193/391\n",
      "Batch: 194/391\n",
      "Batch: 195/391\n",
      "Batch: 196/391\n",
      "Batch: 197/391\n",
      "Batch: 198/391\n",
      "Batch: 199/391\n",
      "Batch: 200/391\n",
      "Batch: 201/391\n",
      "Batch: 202/391\n",
      "Batch: 203/391\n",
      "Batch: 204/391\n",
      "Batch: 205/391\n",
      "Batch: 206/391\n",
      "Batch: 207/391\n",
      "Batch: 208/391\n",
      "Batch: 209/391\n",
      "Batch: 210/391\n",
      "Batch: 211/391\n",
      "Batch: 212/391\n",
      "Batch: 213/391\n",
      "Batch: 214/391\n",
      "Batch: 215/391\n",
      "Batch: 216/391\n",
      "Batch: 217/391\n",
      "Batch: 218/391\n",
      "Batch: 219/391\n",
      "Batch: 220/391\n",
      "Batch: 221/391\n",
      "Batch: 222/391\n",
      "Batch: 223/391\n",
      "Batch: 224/391\n",
      "Batch: 225/391\n",
      "Batch: 226/391\n",
      "Batch: 227/391\n",
      "Batch: 228/391\n",
      "Batch: 229/391\n",
      "Batch: 230/391\n",
      "Batch: 231/391\n",
      "Batch: 232/391\n",
      "Batch: 233/391\n",
      "Batch: 234/391\n",
      "Batch: 235/391\n",
      "Batch: 236/391\n",
      "Batch: 237/391\n",
      "Batch: 238/391\n",
      "Batch: 239/391\n",
      "Batch: 240/391\n",
      "Batch: 241/391\n",
      "Batch: 242/391\n",
      "Batch: 243/391\n",
      "Batch: 244/391\n",
      "Batch: 245/391\n",
      "Batch: 246/391\n",
      "Batch: 247/391\n",
      "Batch: 248/391\n",
      "Batch: 249/391\n",
      "Batch: 250/391\n",
      "Batch: 251/391\n",
      "Batch: 252/391\n",
      "Batch: 253/391\n",
      "Batch: 254/391\n",
      "Batch: 255/391\n",
      "Batch: 256/391\n",
      "Batch: 257/391\n",
      "Batch: 258/391\n",
      "Batch: 259/391\n",
      "Batch: 260/391\n",
      "Batch: 261/391\n",
      "Batch: 262/391\n",
      "Batch: 263/391\n",
      "Batch: 264/391\n",
      "Batch: 265/391\n",
      "Batch: 266/391\n",
      "Batch: 267/391\n",
      "Batch: 268/391\n",
      "Batch: 269/391\n",
      "Batch: 270/391\n",
      "Batch: 271/391\n",
      "Batch: 272/391\n",
      "Batch: 273/391\n",
      "Batch: 274/391\n",
      "Batch: 275/391\n",
      "Batch: 276/391\n",
      "Batch: 277/391\n",
      "Batch: 278/391\n",
      "Batch: 279/391\n",
      "Batch: 280/391\n",
      "Batch: 281/391\n",
      "Batch: 282/391\n",
      "Batch: 283/391\n",
      "Batch: 284/391\n",
      "Batch: 285/391\n",
      "Batch: 286/391\n",
      "Batch: 287/391\n",
      "Batch: 288/391\n",
      "Batch: 289/391\n",
      "Batch: 290/391\n",
      "Batch: 291/391\n",
      "Batch: 292/391\n",
      "Batch: 293/391\n",
      "Batch: 294/391\n",
      "Batch: 295/391\n",
      "Batch: 296/391\n",
      "Batch: 297/391\n",
      "Batch: 298/391\n",
      "Batch: 299/391\n",
      "Batch: 300/391\n",
      "Batch: 301/391\n",
      "Batch: 302/391\n",
      "Batch: 303/391\n",
      "Batch: 304/391\n",
      "Batch: 305/391\n",
      "Batch: 306/391\n",
      "Batch: 307/391\n",
      "Batch: 308/391\n",
      "Batch: 309/391\n",
      "Batch: 310/391\n",
      "Batch: 311/391\n",
      "Batch: 312/391\n",
      "Batch: 313/391\n",
      "Batch: 314/391\n",
      "Batch: 315/391\n",
      "Batch: 316/391\n",
      "Batch: 317/391\n",
      "Batch: 318/391\n",
      "Batch: 319/391\n",
      "Batch: 320/391\n",
      "Batch: 321/391\n",
      "Batch: 322/391\n",
      "Batch: 323/391\n",
      "Batch: 324/391\n",
      "Batch: 325/391\n",
      "Batch: 326/391\n",
      "Batch: 327/391\n",
      "Batch: 328/391\n",
      "Batch: 329/391\n",
      "Batch: 330/391\n",
      "Batch: 331/391\n",
      "Batch: 332/391\n",
      "Batch: 333/391\n",
      "Batch: 334/391\n",
      "Batch: 335/391\n",
      "Batch: 336/391\n",
      "Batch: 337/391\n",
      "Batch: 338/391\n",
      "Batch: 339/391\n",
      "Batch: 340/391\n",
      "Batch: 341/391\n",
      "Batch: 342/391\n",
      "Batch: 343/391\n",
      "Batch: 344/391\n",
      "Batch: 345/391\n",
      "Batch: 346/391\n",
      "Batch: 347/391\n",
      "Batch: 348/391\n",
      "Batch: 349/391\n",
      "Batch: 350/391\n",
      "Batch: 351/391\n",
      "Batch: 352/391\n",
      "Batch: 353/391\n",
      "Batch: 354/391\n",
      "Batch: 355/391\n",
      "Batch: 356/391\n",
      "Batch: 357/391\n",
      "Batch: 358/391\n",
      "Batch: 359/391\n",
      "Batch: 360/391\n",
      "Batch: 361/391\n",
      "Batch: 362/391\n",
      "Batch: 363/391\n",
      "Batch: 364/391\n",
      "Batch: 365/391\n",
      "Batch: 366/391\n",
      "Batch: 367/391\n",
      "Batch: 368/391\n",
      "Batch: 369/391\n",
      "Batch: 370/391\n",
      "Batch: 371/391\n",
      "Batch: 372/391\n",
      "Batch: 373/391\n",
      "Batch: 374/391\n",
      "Batch: 375/391\n",
      "Batch: 376/391\n",
      "Batch: 377/391\n",
      "Batch: 378/391\n",
      "Batch: 379/391\n",
      "Batch: 380/391\n",
      "Batch: 381/391\n",
      "Batch: 382/391\n",
      "Batch: 383/391\n",
      "Batch: 384/391\n",
      "Batch: 385/391\n",
      "Batch: 386/391\n",
      "Batch: 387/391\n",
      "Batch: 388/391\n",
      "Batch: 389/391\n",
      "Batch: 390/391\n",
      "391\n",
      "M_W_post size:  torch.Size([512, 100])\n",
      "M_b_post size:  torch.Size([100])\n",
      "C_W_post size:  torch.Size([100, 512])\n",
      "C_b_post size:  torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "M_W_post_D_CIFAR100, M_b_post_D_CIFAR100, C_W_post_D_CIFAR100, C_b_post_D_CIFAR100 = Diag_second_order(model=CIFAR100_model,\n",
    "                                                               train_loader=CIFAR100_train_loader,\n",
    "                                                               var0 = 75,\n",
    "                                                               device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP estimate for CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR100_test_in_MAP = predict_MAP(CIFAR100_model, CIFAR100_test_loader, cuda=True).cpu().numpy()\n",
    "CIFAR100_test_out_CIFAR10_MAP = predict_MAP(CIFAR100_model, testloader, cuda=True).cpu().numpy()\n",
    "CIFAR100_test_out_SVHN_MAP = predict_MAP(CIFAR100_model, test_loader_SVHN, cuda=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP = get_in_dist_values(CIFAR100_test_in_MAP, targets_CIFAR100)\n",
    "acc_out_CIFAR10_MAP, prob_correct_out_CIFAR10_MAP, ent_out_CIFAR10, MMC_out_CIFAR10_MAP, auroc_out_CIFAR10_MAP = get_out_dist_values(CIFAR100_test_in_MAP, CIFAR100_test_out_CIFAR10_MAP, targets_CIFAR10)\n",
    "acc_out_SVHN_MAP, prob_correct_out_SVHN_MAP, ent_out_SVHN_MAP, MMC_out_SVHN_MAP, auroc_out_SVHN_MAP = get_out_dist_values(CIFAR100_test_in_MAP, CIFAR100_test_out_SVHN_MAP, targets_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, MAP, CIFAR100] Accuracy: 0.599; average entropy: 2.136;     MMC: 0.560; Prob @ correct: 0.010\n",
      "[Out-MAP, KFAC, CIFAR10] Accuracy: 0.007; Average entropy: 3.323;    MMC: 0.305; AUROC: 0.704; Prob @ correct: 0.010\n",
      "[Out-MAP, KFAC, SVHN] Accuracy: 0.002; Average entropy: 3.112;    MMC: 0.368; AUROC: 0.658; Prob @ correct: 0.010\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP, 'CIFAR100', 'MAP')\n",
    "print_out_dist_values(acc_out_CIFAR10_MAP, prob_correct_out_CIFAR10_MAP, ent_out_CIFAR10, MMC_out_CIFAR10_MAP, auroc_out_CIFAR10_MAP, 'CIFAR10', 'MAP')\n",
    "print_out_dist_values(acc_out_SVHN_MAP, prob_correct_out_SVHN_MAP, ent_out_SVHN_MAP, MMC_out_SVHN_MAP, auroc_out_SVHN_MAP, 'SVHN', 'MAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.593 with std 0.006\n",
      "MMC in: 0.566 with std 0.019\n",
      "MMC out CIFAR10: 0.297 with std 0.005\n",
      "MMC out SVHN: 0.367 with std 0.012\n",
      "AUROC out CIFAR10: 0.707 with std 0.004\n",
      "AUROC out SVHN: 0.653 with std 0.009\n"
     ]
    }
   ],
   "source": [
    "#MAP estimate\n",
    "#seeds are 123,124,125,126,127\n",
    "acc_in = [0.589, 0.585, 0.599, 0.599]\n",
    "mmc_in = [0.552, 0.552, 0.599, 0.560]\n",
    "mmc_out_CIFAR10 = [0.294, 0.296, 0.293, 0.305]\n",
    "mmc_out_SVHN = [0.386, 0.355, 0.359, 0.368]\n",
    "\n",
    "auroc_out_CIFAR10 = [0.705, 0.706, 0.713, 0.704]\n",
    "auroc_out_SVHN = [0.637, 0.656, 0.660, 0.658]\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR10), np.std(mmc_out_CIFAR10)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR10), np.std(auroc_out_CIFAR10)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diag sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used for sampling with 1000 samples: 6.670319318771362\n",
      "time used for sampling with 1000 samples: 6.569646596908569\n",
      "time used for sampling with 1000 samples: 16.87152647972107\n"
     ]
    }
   ],
   "source": [
    "CIFAR100_test_in_D = predict_diagonal_sampling(CIFAR100_model, CIFAR100_test_loader, M_W_post_D_CIFAR100, M_b_post_D_CIFAR100, C_W_post_D_CIFAR100, C_b_post_D_CIFAR100, n_samples=1000, cuda=True, timing=True).cpu().numpy()\n",
    "CIFAR100_test_out_CIFAR10_D = predict_diagonal_sampling(CIFAR100_model, testloader, M_W_post_D_CIFAR100, M_b_post_D_CIFAR100, C_W_post_D_CIFAR100, C_b_post_D_CIFAR100, n_samples=1000, cuda=True, timing=True).cpu().numpy()\n",
    "CIFAR100_test_out_SVHN_D = predict_diagonal_sampling(CIFAR100_model, test_loader_SVHN, M_W_post_D_CIFAR100, M_b_post_D_CIFAR100, C_W_post_D_CIFAR100, C_b_post_D_CIFAR100, n_samples=1000, cuda=True, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marius/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D = get_in_dist_values(CIFAR100_test_in_D, targets_CIFAR100)\n",
    "acc_out_CIFAR10_D, prob_correct_out_CIFAR10_D, ent_out_CIFAR10_D, MMC_out_CIFAR10_D, auroc_out_CIFAR10_D = get_out_dist_values(CIFAR100_test_in_D, CIFAR100_test_out_CIFAR10_D, targets_CIFAR10)\n",
    "acc_out_SVHN_D, prob_correct_out_SVHN_D, ent_out_SVHN_D, MMC_out_SVHN_D, auroc_out_SVHN_D = get_out_dist_values(CIFAR100_test_in_D, CIFAR100_test_out_SVHN_D, targets_CIFAR100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, Diag, CIFAR100] Accuracy: 0.598; average entropy: 2.276;     MMC: 0.532; Prob @ correct: 0.010\n",
      "[Out-Diag, KFAC, CIFAR10] Accuracy: 0.007; Average entropy: 3.421;    MMC: 0.283; AUROC: 0.704; Prob @ correct: 0.010\n",
      "[Out-Diag, KFAC, SVHN] Accuracy: 0.000; Average entropy: 3.222;    MMC: 0.346; AUROC: 0.655; Prob @ correct: 0.010\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D, 'CIFAR100', 'Diag')\n",
    "print_out_dist_values(acc_out_CIFAR10_D, prob_correct_out_CIFAR10_D, ent_out_CIFAR10_D, MMC_out_CIFAR10_D, auroc_out_CIFAR10_D, 'CIFAR10', 'Diag')\n",
    "print_out_dist_values(acc_out_SVHN_D, prob_correct_out_SVHN_D, ent_out_SVHN_D, MMC_out_SVHN_D, auroc_out_SVHN_D, 'SVHN', 'Diag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Bridge time in: 6.667 with std 0.037\n",
      "Sampling Bridge time out CIFAR10: 6.680 with std 0.082\n",
      "Sampling Bridge time out SVHN: 17.136 with std 0.155\n",
      "accuracy: 0.592 with std 0.006\n",
      "MMC in: 0.528 with std 0.004\n",
      "MMC out CIFAR10: 0.275 with std 0.005\n",
      "MMC out SVHN: 0.344 with std 0.012\n",
      "AUROC out CIFAR10: 0.708 with std 0.004\n",
      "AUROC out SVHN: 0.651 with std 0.009\n"
     ]
    }
   ],
   "source": [
    "#Diag Sampling\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [6.612371921539307, 6.715473651885986,6.670197486877441, 6.670319318771362]\n",
    "time_lpb_out_CIFAR10 = [6.698111295700073, 6.796610593795776, 6.656818866729736, 6.569646596908569]\n",
    "time_lpb_out_SVHN = [17.256507873535156,17.233936071395874, 17.18303084373474, 16.87152647972107]\n",
    "\n",
    "acc_in = [0.588, 0.586, 0.598, 0.598]\n",
    "mmc_in = [0.523, 0.524, 0.531, 0.532]\n",
    "mmc_out_CIFAR10 = [0.273, 0.274, 0.271, 0.283]\n",
    "mmc_out_SVHN = [0.362, 0.332, 0.335, 0.346]\n",
    "\n",
    "auroc_out_CIFAR10 = [0.706, 0.706, 0.714, 0.704]\n",
    "auroc_out_SVHN = [0.636, 0.654, 0.658, 0.655]\n",
    "\n",
    "print(\"Sampling Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Sampling Bridge time out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR10), np.std(time_lpb_out_CIFAR10)))\n",
    "print(\"Sampling Bridge time out SVHN: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_SVHN), np.std(time_lpb_out_SVHN)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR10), np.std(mmc_out_CIFAR10)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR10), np.std(auroc_out_CIFAR10)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplace Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used for transform: 0.01607\n",
      "total time used for transform: 0.01724\n",
      "total time used for transform: 0.04108\n"
     ]
    }
   ],
   "source": [
    "CIFAR100_test_in_DIR_LPA = predict_DIR_LPA(CIFAR100_model, CIFAR100_test_loader, M_W_post_D_CIFAR100, M_b_post_D_CIFAR100, C_W_post_D_CIFAR100, C_b_post_D_CIFAR100, cuda=True, timing=True).cpu().numpy()\n",
    "CIFAR100_test_out_CIFAR10_DIR_LPA = predict_DIR_LPA(CIFAR100_model, testloader, M_W_post_D_CIFAR100, M_b_post_D_CIFAR100, C_W_post_D_CIFAR100, C_b_post_D_CIFAR100, cuda=True, timing=True).cpu().numpy()\n",
    "CIFAR100_test_out_SVHN_DIR_LPA = predict_DIR_LPA(CIFAR100_model, test_loader_SVHN, M_W_post_D_CIFAR100, M_b_post_D_CIFAR100, C_W_post_D_CIFAR100, C_b_post_D_CIFAR100, cuda=True, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize to get the MAP estimate (which is the mode) of the Dirichlet\n",
    "CIFAR100_test_in_DIR_LPAn = CIFAR100_test_in_DIR_LPA/CIFAR100_test_in_DIR_LPA.sum(1).reshape(-1,1)\n",
    "CIFAR100_test_out_CIFAR10_DIR_LPAn = CIFAR100_test_out_CIFAR10_DIR_LPA/CIFAR100_test_out_CIFAR10_DIR_LPA.sum(1).reshape(-1,1)\n",
    "CIFAR100_test_out_SVHN_DIR_LPAn = CIFAR100_test_out_SVHN_DIR_LPA/CIFAR100_test_out_SVHN_DIR_LPA.sum(1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_DIR_LPA, prob_correct_in_DIR_LPA, ent_in_DIR_LPA, MMC_in_DIR_LPA = get_in_dist_values(CIFAR100_test_in_DIR_LPAn, targets_CIFAR100)\n",
    "acc_out_CIFAR10_DIR_LPA, prob_correct_out_CIFAR10_DIR_LPA, ent_out_CIFAR10_DIR_LPA, MMC_out_CIFAR10_DIR_LPA, auroc_out_CIFAR10_DIR_LPA = get_out_dist_values(CIFAR100_test_in_DIR_LPAn, CIFAR100_test_out_CIFAR10_DIR_LPAn, targets_CIFAR10)\n",
    "acc_out_SVHN_DIR_LPA, prob_correct_out_SVHN_DIR_LPA, ent_out_SVHN_DIR_LPA, MMC_out_SVHN_DIR_LPA, auroc_out_SVHN_DIR_LPA = get_out_dist_values(CIFAR100_test_in_DIR_LPAn, CIFAR100_test_out_SVHN_DIR_LPAn, targets_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, DIR_LPA, CIFAR100] Accuracy: 0.598; average entropy: 3.586;     MMC: 0.263; Prob @ correct: 0.010\n",
      "[Out-DIR_LPA, KFAC, CIFAR10] Accuracy: 0.007; Average entropy: 4.386;    MMC: 0.073; AUROC: 0.700; Prob @ correct: 0.010\n",
      "[Out-DIR_LPA, KFAC, SVHN] Accuracy: 0.002; Average entropy: 4.414;    MMC: 0.072; AUROC: 0.673; Prob @ correct: 0.010\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_DIR_LPA, prob_correct_in_DIR_LPA, ent_in_DIR_LPA, MMC_in_DIR_LPA, 'CIFAR100', 'DIR_LPA')\n",
    "print_out_dist_values(acc_out_CIFAR10_DIR_LPA, prob_correct_out_CIFAR10_DIR_LPA, ent_out_CIFAR10_DIR_LPA, MMC_out_CIFAR10_DIR_LPA, auroc_out_CIFAR10_DIR_LPA, 'CIFAR10', 'DIR_LPA')\n",
    "print_out_dist_values(acc_out_SVHN_DIR_LPA, prob_correct_out_SVHN_DIR_LPA, ent_out_SVHN_DIR_LPA, MMC_out_SVHN_DIR_LPA, auroc_out_SVHN_DIR_LPA, 'SVHN', 'DIR_LPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplace Bridge time in: 0.018 with std 0.002\n",
      "Laplace Bridge time out CIFAR10: 0.018 with std 0.000\n",
      "Laplace Bridge time out SVHN: 0.041 with std 0.000\n",
      "accuracy: 0.593 with std 0.006\n",
      "MMC in: 0.262 with std 0.003\n",
      "MMC out CIFAR10: 0.068 with std 0.004\n",
      "MMC out SVHN: 0.073 with std 0.013\n",
      "AUROC out CIFAR10: 0.704 with std 0.003\n",
      "AUROC out SVHN: 0.665 with std 0.010\n"
     ]
    }
   ],
   "source": [
    "#Laplace Bridge\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [0.02161,0.01674, 0.01601, 0.01607]\n",
    "time_lpb_out_CIFAR10 = [0.01830, 0.01804, 0.01745, 0.01724]\n",
    "time_lpb_out_SVHN = [0.04126, 0.04220, 0.04133, 0.04108]\n",
    "\n",
    "\n",
    "acc_in = [0.590, 0.585, 0.600, 0.598]\n",
    "mmc_in = [0.259, 0.260, 0.266, 0.263]\n",
    "mmc_out_CIFAR10 = [0.067, 0.067, 0.063, 0.073]\n",
    "mmc_out_SVHN = [0.096, 0.063, 0.063, 0.072]\n",
    "\n",
    "auroc_out_CIFAR10 = [0.702, 0.703, 0.709, 0.700]\n",
    "auroc_out_SVHN = [0.648, 0.668, 0.671, 0.673]\n",
    "\n",
    "\n",
    "print(\"Laplace Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Laplace Bridge time out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR10), np.std(time_lpb_out_CIFAR10)))\n",
    "print(\"Laplace Bridge time out SVHN: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_SVHN), np.std(time_lpb_out_SVHN)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR10), np.std(mmc_out_CIFAR10)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR10: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR10), np.std(auroc_out_CIFAR10)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
