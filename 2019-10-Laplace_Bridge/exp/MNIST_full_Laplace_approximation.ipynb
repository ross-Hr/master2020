{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "#import input_data\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "from math import *\n",
    "from backpack import backpack, extend\n",
    "from backpack.extensions import KFAC, DiagHessian, DiagGGNMC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy\n",
    "from tqdm import tqdm, trange\n",
    "from bpjacext import NetJac\n",
    "import pytest\n",
    "from DirLPA_utils import * \n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "s = 127\n",
    "np.random.seed(s)\n",
    "torch.manual_seed(s)\n",
    "torch.cuda.manual_seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LPADirNN(num_classes=10, num_LL=256):\n",
    "    \n",
    "    features = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 32, 5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(2,2),\n",
    "        torch.nn.Conv2d(32, 64, 5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(2,2),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(4 * 4 * 64, num_LL), #changed from 500\n",
    "        torch.nn.Linear(num_LL, num_classes)  #changed from 500\n",
    "    )\n",
    "    return(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TRAIN_MNIST = 128\n",
    "BATCH_SIZE_TEST_MNIST = 128\n",
    "MAX_ITER_MNIST = 6\n",
    "LR_TRAIN_MNIST = 10e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "MNIST_train = torchvision.datasets.MNIST(\n",
    "        '~/data/mnist',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=MNIST_transform)\n",
    "\n",
    "mnist_train_loader = torch.utils.data.dataloader.DataLoader(\n",
    "    MNIST_train,\n",
    "    batch_size=BATCH_SIZE_TRAIN_MNIST,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "MNIST_test = torchvision.datasets.MNIST(\n",
    "        '~/data/mnist',\n",
    "        train=False,\n",
    "        download=False,\n",
    "        transform=MNIST_transform)\n",
    "\n",
    "mnist_test_loader = torch.utils.data.dataloader.DataLoader(\n",
    "    MNIST_test,\n",
    "    batch_size=BATCH_SIZE_TEST_MNIST,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model = LPADirNN(num_LL=256).cuda()\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#mnist_train_optimizer = torch.optim.Adam(mnist_model.parameters(), lr=LR_TRAIN_MNIST)\n",
    "mnist_train_optimizer = torch.optim.Adam(mnist_model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "MNIST_PATH = \"weights/mnist_test_6iter_10c_simpleCNN_256.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training routine\n",
    "\n",
    "def train(model, train_loader, optimizer, max_iter, path, verbose=True):\n",
    "    max_len = len(train_loader)\n",
    "\n",
    "    for iter in range(max_iter):\n",
    "        for batch_idx, (x, y) in enumerate(train_loader):\n",
    "            \n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            \n",
    "            output = model(x)\n",
    "\n",
    "            accuracy = get_accuracy(output, y)\n",
    "\n",
    "            loss = loss_function(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    \"Iteration {}; {}/{} \\t\".format(iter, batch_idx, max_len) +\n",
    "                    \"Minibatch Loss %.3f  \" % (loss) +\n",
    "                    \"Accuracy %.0f\" % (accuracy * 100) + \"%\"\n",
    "                )\n",
    "\n",
    "    print(\"saving model at: {}\".format(path))\n",
    "    torch.save(mnist_model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0; 0/469 \tMinibatch Loss 2.307  Accuracy 9%\n",
      "Iteration 0; 1/469 \tMinibatch Loss 2.283  Accuracy 7%\n",
      "Iteration 0; 2/469 \tMinibatch Loss 2.167  Accuracy 20%\n",
      "Iteration 0; 3/469 \tMinibatch Loss 2.152  Accuracy 48%\n",
      "Iteration 0; 4/469 \tMinibatch Loss 2.070  Accuracy 45%\n",
      "Iteration 0; 5/469 \tMinibatch Loss 1.927  Accuracy 66%\n",
      "Iteration 0; 6/469 \tMinibatch Loss 1.728  Accuracy 68%\n",
      "Iteration 0; 7/469 \tMinibatch Loss 1.643  Accuracy 59%\n",
      "Iteration 0; 8/469 \tMinibatch Loss 1.483  Accuracy 57%\n",
      "Iteration 0; 9/469 \tMinibatch Loss 1.423  Accuracy 56%\n",
      "Iteration 0; 10/469 \tMinibatch Loss 1.223  Accuracy 64%\n",
      "Iteration 0; 11/469 \tMinibatch Loss 1.117  Accuracy 80%\n",
      "Iteration 0; 12/469 \tMinibatch Loss 0.980  Accuracy 80%\n",
      "Iteration 0; 13/469 \tMinibatch Loss 0.936  Accuracy 72%\n",
      "Iteration 0; 14/469 \tMinibatch Loss 0.793  Accuracy 80%\n",
      "Iteration 0; 15/469 \tMinibatch Loss 0.638  Accuracy 81%\n",
      "Iteration 0; 16/469 \tMinibatch Loss 0.583  Accuracy 80%\n",
      "Iteration 0; 17/469 \tMinibatch Loss 0.526  Accuracy 82%\n",
      "Iteration 0; 18/469 \tMinibatch Loss 0.681  Accuracy 80%\n",
      "Iteration 0; 19/469 \tMinibatch Loss 0.530  Accuracy 87%\n",
      "Iteration 0; 20/469 \tMinibatch Loss 0.773  Accuracy 74%\n",
      "Iteration 0; 21/469 \tMinibatch Loss 0.446  Accuracy 84%\n",
      "Iteration 0; 22/469 \tMinibatch Loss 0.532  Accuracy 81%\n",
      "Iteration 0; 23/469 \tMinibatch Loss 0.452  Accuracy 84%\n",
      "Iteration 0; 24/469 \tMinibatch Loss 0.549  Accuracy 86%\n",
      "Iteration 0; 25/469 \tMinibatch Loss 0.564  Accuracy 84%\n",
      "Iteration 0; 26/469 \tMinibatch Loss 0.326  Accuracy 87%\n",
      "Iteration 0; 27/469 \tMinibatch Loss 0.374  Accuracy 92%\n",
      "Iteration 0; 28/469 \tMinibatch Loss 0.345  Accuracy 89%\n",
      "Iteration 0; 29/469 \tMinibatch Loss 0.686  Accuracy 83%\n",
      "Iteration 0; 30/469 \tMinibatch Loss 0.558  Accuracy 88%\n",
      "Iteration 0; 31/469 \tMinibatch Loss 0.430  Accuracy 88%\n",
      "Iteration 0; 32/469 \tMinibatch Loss 0.435  Accuracy 85%\n",
      "Iteration 0; 33/469 \tMinibatch Loss 0.457  Accuracy 88%\n",
      "Iteration 0; 34/469 \tMinibatch Loss 0.438  Accuracy 86%\n",
      "Iteration 0; 35/469 \tMinibatch Loss 0.389  Accuracy 88%\n",
      "Iteration 0; 36/469 \tMinibatch Loss 0.307  Accuracy 90%\n",
      "Iteration 0; 37/469 \tMinibatch Loss 0.545  Accuracy 83%\n",
      "Iteration 0; 38/469 \tMinibatch Loss 0.486  Accuracy 91%\n",
      "Iteration 0; 39/469 \tMinibatch Loss 0.315  Accuracy 91%\n",
      "Iteration 0; 40/469 \tMinibatch Loss 0.243  Accuracy 95%\n",
      "Iteration 0; 41/469 \tMinibatch Loss 0.267  Accuracy 92%\n",
      "Iteration 0; 42/469 \tMinibatch Loss 0.348  Accuracy 89%\n",
      "Iteration 0; 43/469 \tMinibatch Loss 0.275  Accuracy 90%\n",
      "Iteration 0; 44/469 \tMinibatch Loss 0.241  Accuracy 92%\n",
      "Iteration 0; 45/469 \tMinibatch Loss 0.370  Accuracy 88%\n",
      "Iteration 0; 46/469 \tMinibatch Loss 0.260  Accuracy 94%\n",
      "Iteration 0; 47/469 \tMinibatch Loss 0.348  Accuracy 91%\n",
      "Iteration 0; 48/469 \tMinibatch Loss 0.281  Accuracy 93%\n",
      "Iteration 0; 49/469 \tMinibatch Loss 0.302  Accuracy 93%\n",
      "Iteration 0; 50/469 \tMinibatch Loss 0.280  Accuracy 93%\n",
      "Iteration 0; 51/469 \tMinibatch Loss 0.345  Accuracy 91%\n",
      "Iteration 0; 52/469 \tMinibatch Loss 0.335  Accuracy 89%\n",
      "Iteration 0; 53/469 \tMinibatch Loss 0.417  Accuracy 85%\n",
      "Iteration 0; 54/469 \tMinibatch Loss 0.239  Accuracy 91%\n",
      "Iteration 0; 55/469 \tMinibatch Loss 0.310  Accuracy 92%\n",
      "Iteration 0; 56/469 \tMinibatch Loss 0.213  Accuracy 95%\n",
      "Iteration 0; 57/469 \tMinibatch Loss 0.228  Accuracy 93%\n",
      "Iteration 0; 58/469 \tMinibatch Loss 0.289  Accuracy 91%\n",
      "Iteration 0; 59/469 \tMinibatch Loss 0.377  Accuracy 91%\n",
      "Iteration 0; 60/469 \tMinibatch Loss 0.207  Accuracy 94%\n",
      "Iteration 0; 61/469 \tMinibatch Loss 0.133  Accuracy 96%\n",
      "Iteration 0; 62/469 \tMinibatch Loss 0.216  Accuracy 93%\n",
      "Iteration 0; 63/469 \tMinibatch Loss 0.293  Accuracy 94%\n",
      "Iteration 0; 64/469 \tMinibatch Loss 0.248  Accuracy 91%\n",
      "Iteration 0; 65/469 \tMinibatch Loss 0.176  Accuracy 95%\n",
      "Iteration 0; 66/469 \tMinibatch Loss 0.146  Accuracy 97%\n",
      "Iteration 0; 67/469 \tMinibatch Loss 0.231  Accuracy 91%\n",
      "Iteration 0; 68/469 \tMinibatch Loss 0.258  Accuracy 95%\n",
      "Iteration 0; 69/469 \tMinibatch Loss 0.221  Accuracy 94%\n",
      "Iteration 0; 70/469 \tMinibatch Loss 0.161  Accuracy 95%\n",
      "Iteration 0; 71/469 \tMinibatch Loss 0.184  Accuracy 94%\n",
      "Iteration 0; 72/469 \tMinibatch Loss 0.199  Accuracy 94%\n",
      "Iteration 0; 73/469 \tMinibatch Loss 0.214  Accuracy 93%\n",
      "Iteration 0; 74/469 \tMinibatch Loss 0.137  Accuracy 95%\n",
      "Iteration 0; 75/469 \tMinibatch Loss 0.161  Accuracy 96%\n",
      "Iteration 0; 76/469 \tMinibatch Loss 0.236  Accuracy 94%\n",
      "Iteration 0; 77/469 \tMinibatch Loss 0.187  Accuracy 92%\n",
      "Iteration 0; 78/469 \tMinibatch Loss 0.174  Accuracy 95%\n",
      "Iteration 0; 79/469 \tMinibatch Loss 0.134  Accuracy 96%\n",
      "Iteration 0; 80/469 \tMinibatch Loss 0.200  Accuracy 95%\n",
      "Iteration 0; 81/469 \tMinibatch Loss 0.099  Accuracy 98%\n",
      "Iteration 0; 82/469 \tMinibatch Loss 0.145  Accuracy 96%\n",
      "Iteration 0; 83/469 \tMinibatch Loss 0.251  Accuracy 92%\n",
      "Iteration 0; 84/469 \tMinibatch Loss 0.234  Accuracy 93%\n",
      "Iteration 0; 85/469 \tMinibatch Loss 0.111  Accuracy 96%\n",
      "Iteration 0; 86/469 \tMinibatch Loss 0.219  Accuracy 93%\n",
      "Iteration 0; 87/469 \tMinibatch Loss 0.174  Accuracy 95%\n",
      "Iteration 0; 88/469 \tMinibatch Loss 0.185  Accuracy 95%\n",
      "Iteration 0; 89/469 \tMinibatch Loss 0.196  Accuracy 93%\n",
      "Iteration 0; 90/469 \tMinibatch Loss 0.199  Accuracy 95%\n",
      "Iteration 0; 91/469 \tMinibatch Loss 0.180  Accuracy 93%\n",
      "Iteration 0; 92/469 \tMinibatch Loss 0.127  Accuracy 96%\n",
      "Iteration 0; 93/469 \tMinibatch Loss 0.209  Accuracy 94%\n",
      "Iteration 0; 94/469 \tMinibatch Loss 0.119  Accuracy 95%\n",
      "Iteration 0; 95/469 \tMinibatch Loss 0.116  Accuracy 96%\n",
      "Iteration 0; 96/469 \tMinibatch Loss 0.210  Accuracy 93%\n",
      "Iteration 0; 97/469 \tMinibatch Loss 0.087  Accuracy 98%\n",
      "Iteration 0; 98/469 \tMinibatch Loss 0.187  Accuracy 95%\n",
      "Iteration 0; 99/469 \tMinibatch Loss 0.139  Accuracy 95%\n",
      "Iteration 0; 100/469 \tMinibatch Loss 0.205  Accuracy 94%\n",
      "Iteration 0; 101/469 \tMinibatch Loss 0.128  Accuracy 96%\n",
      "Iteration 0; 102/469 \tMinibatch Loss 0.167  Accuracy 95%\n",
      "Iteration 0; 103/469 \tMinibatch Loss 0.109  Accuracy 97%\n",
      "Iteration 0; 104/469 \tMinibatch Loss 0.139  Accuracy 95%\n",
      "Iteration 0; 105/469 \tMinibatch Loss 0.147  Accuracy 95%\n",
      "Iteration 0; 106/469 \tMinibatch Loss 0.094  Accuracy 98%\n",
      "Iteration 0; 107/469 \tMinibatch Loss 0.177  Accuracy 96%\n",
      "Iteration 0; 108/469 \tMinibatch Loss 0.165  Accuracy 93%\n",
      "Iteration 0; 109/469 \tMinibatch Loss 0.111  Accuracy 97%\n",
      "Iteration 0; 110/469 \tMinibatch Loss 0.168  Accuracy 96%\n",
      "Iteration 0; 111/469 \tMinibatch Loss 0.275  Accuracy 94%\n",
      "Iteration 0; 112/469 \tMinibatch Loss 0.117  Accuracy 96%\n",
      "Iteration 0; 113/469 \tMinibatch Loss 0.110  Accuracy 95%\n",
      "Iteration 0; 114/469 \tMinibatch Loss 0.158  Accuracy 97%\n",
      "Iteration 0; 115/469 \tMinibatch Loss 0.076  Accuracy 98%\n",
      "Iteration 0; 116/469 \tMinibatch Loss 0.115  Accuracy 97%\n",
      "Iteration 0; 117/469 \tMinibatch Loss 0.112  Accuracy 98%\n",
      "Iteration 0; 118/469 \tMinibatch Loss 0.173  Accuracy 94%\n",
      "Iteration 0; 119/469 \tMinibatch Loss 0.139  Accuracy 96%\n",
      "Iteration 0; 120/469 \tMinibatch Loss 0.282  Accuracy 91%\n",
      "Iteration 0; 121/469 \tMinibatch Loss 0.125  Accuracy 97%\n",
      "Iteration 0; 122/469 \tMinibatch Loss 0.178  Accuracy 92%\n",
      "Iteration 0; 123/469 \tMinibatch Loss 0.100  Accuracy 98%\n",
      "Iteration 0; 124/469 \tMinibatch Loss 0.199  Accuracy 95%\n",
      "Iteration 0; 125/469 \tMinibatch Loss 0.254  Accuracy 91%\n",
      "Iteration 0; 126/469 \tMinibatch Loss 0.103  Accuracy 97%\n",
      "Iteration 0; 127/469 \tMinibatch Loss 0.076  Accuracy 98%\n",
      "Iteration 0; 128/469 \tMinibatch Loss 0.047  Accuracy 99%\n",
      "Iteration 0; 129/469 \tMinibatch Loss 0.174  Accuracy 95%\n",
      "Iteration 0; 130/469 \tMinibatch Loss 0.127  Accuracy 95%\n",
      "Iteration 0; 131/469 \tMinibatch Loss 0.113  Accuracy 95%\n",
      "Iteration 0; 132/469 \tMinibatch Loss 0.107  Accuracy 96%\n",
      "Iteration 0; 133/469 \tMinibatch Loss 0.256  Accuracy 91%\n",
      "Iteration 0; 134/469 \tMinibatch Loss 0.309  Accuracy 95%\n",
      "Iteration 0; 135/469 \tMinibatch Loss 0.164  Accuracy 96%\n",
      "Iteration 0; 136/469 \tMinibatch Loss 0.150  Accuracy 98%\n",
      "Iteration 0; 137/469 \tMinibatch Loss 0.098  Accuracy 98%\n",
      "Iteration 0; 138/469 \tMinibatch Loss 0.189  Accuracy 95%\n",
      "Iteration 0; 139/469 \tMinibatch Loss 0.157  Accuracy 94%\n",
      "Iteration 0; 140/469 \tMinibatch Loss 0.111  Accuracy 98%\n",
      "Iteration 0; 141/469 \tMinibatch Loss 0.079  Accuracy 97%\n",
      "Iteration 0; 142/469 \tMinibatch Loss 0.096  Accuracy 98%\n",
      "Iteration 0; 143/469 \tMinibatch Loss 0.116  Accuracy 98%\n",
      "Iteration 0; 144/469 \tMinibatch Loss 0.066  Accuracy 100%\n",
      "Iteration 0; 145/469 \tMinibatch Loss 0.210  Accuracy 95%\n",
      "Iteration 0; 146/469 \tMinibatch Loss 0.107  Accuracy 98%\n",
      "Iteration 0; 147/469 \tMinibatch Loss 0.178  Accuracy 95%\n",
      "Iteration 0; 148/469 \tMinibatch Loss 0.115  Accuracy 96%\n",
      "Iteration 0; 149/469 \tMinibatch Loss 0.099  Accuracy 96%\n",
      "Iteration 0; 150/469 \tMinibatch Loss 0.066  Accuracy 98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0; 151/469 \tMinibatch Loss 0.150  Accuracy 97%\n",
      "Iteration 0; 152/469 \tMinibatch Loss 0.098  Accuracy 98%\n",
      "Iteration 0; 153/469 \tMinibatch Loss 0.086  Accuracy 97%\n",
      "Iteration 0; 154/469 \tMinibatch Loss 0.155  Accuracy 97%\n",
      "Iteration 0; 155/469 \tMinibatch Loss 0.144  Accuracy 94%\n",
      "Iteration 0; 156/469 \tMinibatch Loss 0.070  Accuracy 98%\n",
      "Iteration 0; 157/469 \tMinibatch Loss 0.102  Accuracy 97%\n",
      "Iteration 0; 158/469 \tMinibatch Loss 0.120  Accuracy 97%\n",
      "Iteration 0; 159/469 \tMinibatch Loss 0.102  Accuracy 95%\n",
      "Iteration 0; 160/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 0; 161/469 \tMinibatch Loss 0.079  Accuracy 98%\n",
      "Iteration 0; 162/469 \tMinibatch Loss 0.125  Accuracy 96%\n",
      "Iteration 0; 163/469 \tMinibatch Loss 0.142  Accuracy 96%\n",
      "Iteration 0; 164/469 \tMinibatch Loss 0.134  Accuracy 96%\n",
      "Iteration 0; 165/469 \tMinibatch Loss 0.135  Accuracy 97%\n",
      "Iteration 0; 166/469 \tMinibatch Loss 0.043  Accuracy 99%\n",
      "Iteration 0; 167/469 \tMinibatch Loss 0.147  Accuracy 95%\n",
      "Iteration 0; 168/469 \tMinibatch Loss 0.073  Accuracy 97%\n",
      "Iteration 0; 169/469 \tMinibatch Loss 0.114  Accuracy 97%\n",
      "Iteration 0; 170/469 \tMinibatch Loss 0.080  Accuracy 98%\n",
      "Iteration 0; 171/469 \tMinibatch Loss 0.145  Accuracy 95%\n",
      "Iteration 0; 172/469 \tMinibatch Loss 0.113  Accuracy 98%\n",
      "Iteration 0; 173/469 \tMinibatch Loss 0.059  Accuracy 99%\n",
      "Iteration 0; 174/469 \tMinibatch Loss 0.105  Accuracy 97%\n",
      "Iteration 0; 175/469 \tMinibatch Loss 0.124  Accuracy 98%\n",
      "Iteration 0; 176/469 \tMinibatch Loss 0.080  Accuracy 97%\n",
      "Iteration 0; 177/469 \tMinibatch Loss 0.101  Accuracy 95%\n",
      "Iteration 0; 178/469 \tMinibatch Loss 0.113  Accuracy 98%\n",
      "Iteration 0; 179/469 \tMinibatch Loss 0.126  Accuracy 97%\n",
      "Iteration 0; 180/469 \tMinibatch Loss 0.076  Accuracy 97%\n",
      "Iteration 0; 181/469 \tMinibatch Loss 0.085  Accuracy 98%\n",
      "Iteration 0; 182/469 \tMinibatch Loss 0.098  Accuracy 98%\n",
      "Iteration 0; 183/469 \tMinibatch Loss 0.168  Accuracy 95%\n",
      "Iteration 0; 184/469 \tMinibatch Loss 0.106  Accuracy 96%\n",
      "Iteration 0; 185/469 \tMinibatch Loss 0.159  Accuracy 95%\n",
      "Iteration 0; 186/469 \tMinibatch Loss 0.088  Accuracy 97%\n",
      "Iteration 0; 187/469 \tMinibatch Loss 0.087  Accuracy 96%\n",
      "Iteration 0; 188/469 \tMinibatch Loss 0.104  Accuracy 96%\n",
      "Iteration 0; 189/469 \tMinibatch Loss 0.079  Accuracy 98%\n",
      "Iteration 0; 190/469 \tMinibatch Loss 0.094  Accuracy 95%\n",
      "Iteration 0; 191/469 \tMinibatch Loss 0.094  Accuracy 98%\n",
      "Iteration 0; 192/469 \tMinibatch Loss 0.071  Accuracy 97%\n",
      "Iteration 0; 193/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 0; 194/469 \tMinibatch Loss 0.068  Accuracy 98%\n",
      "Iteration 0; 195/469 \tMinibatch Loss 0.091  Accuracy 97%\n",
      "Iteration 0; 196/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 0; 197/469 \tMinibatch Loss 0.135  Accuracy 97%\n",
      "Iteration 0; 198/469 \tMinibatch Loss 0.079  Accuracy 99%\n",
      "Iteration 0; 199/469 \tMinibatch Loss 0.108  Accuracy 97%\n",
      "Iteration 0; 200/469 \tMinibatch Loss 0.042  Accuracy 99%\n",
      "Iteration 0; 201/469 \tMinibatch Loss 0.070  Accuracy 98%\n",
      "Iteration 0; 202/469 \tMinibatch Loss 0.075  Accuracy 97%\n",
      "Iteration 0; 203/469 \tMinibatch Loss 0.081  Accuracy 97%\n",
      "Iteration 0; 204/469 \tMinibatch Loss 0.076  Accuracy 97%\n",
      "Iteration 0; 205/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 0; 206/469 \tMinibatch Loss 0.191  Accuracy 94%\n",
      "Iteration 0; 207/469 \tMinibatch Loss 0.081  Accuracy 98%\n",
      "Iteration 0; 208/469 \tMinibatch Loss 0.035  Accuracy 100%\n",
      "Iteration 0; 209/469 \tMinibatch Loss 0.126  Accuracy 97%\n",
      "Iteration 0; 210/469 \tMinibatch Loss 0.106  Accuracy 95%\n",
      "Iteration 0; 211/469 \tMinibatch Loss 0.182  Accuracy 95%\n",
      "Iteration 0; 212/469 \tMinibatch Loss 0.253  Accuracy 98%\n",
      "Iteration 0; 213/469 \tMinibatch Loss 0.030  Accuracy 100%\n",
      "Iteration 0; 214/469 \tMinibatch Loss 0.049  Accuracy 99%\n",
      "Iteration 0; 215/469 \tMinibatch Loss 0.076  Accuracy 98%\n",
      "Iteration 0; 216/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 0; 217/469 \tMinibatch Loss 0.189  Accuracy 97%\n",
      "Iteration 0; 218/469 \tMinibatch Loss 0.159  Accuracy 96%\n",
      "Iteration 0; 219/469 \tMinibatch Loss 0.125  Accuracy 98%\n",
      "Iteration 0; 220/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 0; 221/469 \tMinibatch Loss 0.114  Accuracy 96%\n",
      "Iteration 0; 222/469 \tMinibatch Loss 0.049  Accuracy 100%\n",
      "Iteration 0; 223/469 \tMinibatch Loss 0.134  Accuracy 97%\n",
      "Iteration 0; 224/469 \tMinibatch Loss 0.113  Accuracy 96%\n",
      "Iteration 0; 225/469 \tMinibatch Loss 0.129  Accuracy 98%\n",
      "Iteration 0; 226/469 \tMinibatch Loss 0.115  Accuracy 97%\n",
      "Iteration 0; 227/469 \tMinibatch Loss 0.088  Accuracy 96%\n",
      "Iteration 0; 228/469 \tMinibatch Loss 0.067  Accuracy 98%\n",
      "Iteration 0; 229/469 \tMinibatch Loss 0.134  Accuracy 95%\n",
      "Iteration 0; 230/469 \tMinibatch Loss 0.100  Accuracy 96%\n",
      "Iteration 0; 231/469 \tMinibatch Loss 0.097  Accuracy 97%\n",
      "Iteration 0; 232/469 \tMinibatch Loss 0.099  Accuracy 95%\n",
      "Iteration 0; 233/469 \tMinibatch Loss 0.099  Accuracy 96%\n",
      "Iteration 0; 234/469 \tMinibatch Loss 0.119  Accuracy 97%\n",
      "Iteration 0; 235/469 \tMinibatch Loss 0.080  Accuracy 97%\n",
      "Iteration 0; 236/469 \tMinibatch Loss 0.038  Accuracy 99%\n",
      "Iteration 0; 237/469 \tMinibatch Loss 0.097  Accuracy 98%\n",
      "Iteration 0; 238/469 \tMinibatch Loss 0.057  Accuracy 99%\n",
      "Iteration 0; 239/469 \tMinibatch Loss 0.079  Accuracy 98%\n",
      "Iteration 0; 240/469 \tMinibatch Loss 0.108  Accuracy 98%\n",
      "Iteration 0; 241/469 \tMinibatch Loss 0.058  Accuracy 98%\n",
      "Iteration 0; 242/469 \tMinibatch Loss 0.179  Accuracy 95%\n",
      "Iteration 0; 243/469 \tMinibatch Loss 0.079  Accuracy 97%\n",
      "Iteration 0; 244/469 \tMinibatch Loss 0.075  Accuracy 96%\n",
      "Iteration 0; 245/469 \tMinibatch Loss 0.070  Accuracy 98%\n",
      "Iteration 0; 246/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 0; 247/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 0; 248/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 0; 249/469 \tMinibatch Loss 0.151  Accuracy 95%\n",
      "Iteration 0; 250/469 \tMinibatch Loss 0.101  Accuracy 95%\n",
      "Iteration 0; 251/469 \tMinibatch Loss 0.102  Accuracy 95%\n",
      "Iteration 0; 252/469 \tMinibatch Loss 0.169  Accuracy 97%\n",
      "Iteration 0; 253/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 0; 254/469 \tMinibatch Loss 0.099  Accuracy 95%\n",
      "Iteration 0; 255/469 \tMinibatch Loss 0.116  Accuracy 95%\n",
      "Iteration 0; 256/469 \tMinibatch Loss 0.085  Accuracy 96%\n",
      "Iteration 0; 257/469 \tMinibatch Loss 0.190  Accuracy 97%\n",
      "Iteration 0; 258/469 \tMinibatch Loss 0.084  Accuracy 98%\n",
      "Iteration 0; 259/469 \tMinibatch Loss 0.073  Accuracy 98%\n",
      "Iteration 0; 260/469 \tMinibatch Loss 0.147  Accuracy 96%\n",
      "Iteration 0; 261/469 \tMinibatch Loss 0.097  Accuracy 95%\n",
      "Iteration 0; 262/469 \tMinibatch Loss 0.090  Accuracy 97%\n",
      "Iteration 0; 263/469 \tMinibatch Loss 0.133  Accuracy 96%\n",
      "Iteration 0; 264/469 \tMinibatch Loss 0.088  Accuracy 98%\n",
      "Iteration 0; 265/469 \tMinibatch Loss 0.041  Accuracy 99%\n",
      "Iteration 0; 266/469 \tMinibatch Loss 0.139  Accuracy 97%\n",
      "Iteration 0; 267/469 \tMinibatch Loss 0.079  Accuracy 98%\n",
      "Iteration 0; 268/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 0; 269/469 \tMinibatch Loss 0.116  Accuracy 98%\n",
      "Iteration 0; 270/469 \tMinibatch Loss 0.115  Accuracy 97%\n",
      "Iteration 0; 271/469 \tMinibatch Loss 0.143  Accuracy 95%\n",
      "Iteration 0; 272/469 \tMinibatch Loss 0.067  Accuracy 98%\n",
      "Iteration 0; 273/469 \tMinibatch Loss 0.027  Accuracy 100%\n",
      "Iteration 0; 274/469 \tMinibatch Loss 0.086  Accuracy 98%\n",
      "Iteration 0; 275/469 \tMinibatch Loss 0.072  Accuracy 98%\n",
      "Iteration 0; 276/469 \tMinibatch Loss 0.086  Accuracy 97%\n",
      "Iteration 0; 277/469 \tMinibatch Loss 0.061  Accuracy 99%\n",
      "Iteration 0; 278/469 \tMinibatch Loss 0.055  Accuracy 99%\n",
      "Iteration 0; 279/469 \tMinibatch Loss 0.108  Accuracy 97%\n",
      "Iteration 0; 280/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 0; 281/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 0; 282/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 0; 283/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 0; 284/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 0; 285/469 \tMinibatch Loss 0.071  Accuracy 97%\n",
      "Iteration 0; 286/469 \tMinibatch Loss 0.062  Accuracy 97%\n",
      "Iteration 0; 287/469 \tMinibatch Loss 0.066  Accuracy 97%\n",
      "Iteration 0; 288/469 \tMinibatch Loss 0.115  Accuracy 97%\n",
      "Iteration 0; 289/469 \tMinibatch Loss 0.087  Accuracy 98%\n",
      "Iteration 0; 290/469 \tMinibatch Loss 0.073  Accuracy 98%\n",
      "Iteration 0; 291/469 \tMinibatch Loss 0.057  Accuracy 99%\n",
      "Iteration 0; 292/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 0; 293/469 \tMinibatch Loss 0.037  Accuracy 99%\n",
      "Iteration 0; 294/469 \tMinibatch Loss 0.054  Accuracy 99%\n",
      "Iteration 0; 295/469 \tMinibatch Loss 0.093  Accuracy 96%\n",
      "Iteration 0; 296/469 \tMinibatch Loss 0.039  Accuracy 99%\n",
      "Iteration 0; 297/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 0; 298/469 \tMinibatch Loss 0.041  Accuracy 99%\n",
      "Iteration 0; 299/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 0; 300/469 \tMinibatch Loss 0.072  Accuracy 97%\n",
      "Iteration 0; 301/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 0; 302/469 \tMinibatch Loss 0.107  Accuracy 95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0; 303/469 \tMinibatch Loss 0.100  Accuracy 98%\n",
      "Iteration 0; 304/469 \tMinibatch Loss 0.075  Accuracy 97%\n",
      "Iteration 0; 305/469 \tMinibatch Loss 0.118  Accuracy 95%\n",
      "Iteration 0; 306/469 \tMinibatch Loss 0.105  Accuracy 95%\n",
      "Iteration 0; 307/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 0; 308/469 \tMinibatch Loss 0.086  Accuracy 97%\n",
      "Iteration 0; 309/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 0; 310/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 0; 311/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 0; 312/469 \tMinibatch Loss 0.175  Accuracy 96%\n",
      "Iteration 0; 313/469 \tMinibatch Loss 0.091  Accuracy 98%\n",
      "Iteration 0; 314/469 \tMinibatch Loss 0.123  Accuracy 98%\n",
      "Iteration 0; 315/469 \tMinibatch Loss 0.045  Accuracy 99%\n",
      "Iteration 0; 316/469 \tMinibatch Loss 0.071  Accuracy 98%\n",
      "Iteration 0; 317/469 \tMinibatch Loss 0.070  Accuracy 98%\n",
      "Iteration 0; 318/469 \tMinibatch Loss 0.085  Accuracy 98%\n",
      "Iteration 0; 319/469 \tMinibatch Loss 0.071  Accuracy 97%\n",
      "Iteration 0; 320/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 0; 321/469 \tMinibatch Loss 0.086  Accuracy 98%\n",
      "Iteration 0; 322/469 \tMinibatch Loss 0.025  Accuracy 100%\n",
      "Iteration 0; 323/469 \tMinibatch Loss 0.043  Accuracy 99%\n",
      "Iteration 0; 324/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 0; 325/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 0; 326/469 \tMinibatch Loss 0.083  Accuracy 98%\n",
      "Iteration 0; 327/469 \tMinibatch Loss 0.061  Accuracy 97%\n",
      "Iteration 0; 328/469 \tMinibatch Loss 0.042  Accuracy 99%\n",
      "Iteration 0; 329/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 0; 330/469 \tMinibatch Loss 0.101  Accuracy 95%\n",
      "Iteration 0; 331/469 \tMinibatch Loss 0.037  Accuracy 99%\n",
      "Iteration 0; 332/469 \tMinibatch Loss 0.093  Accuracy 98%\n",
      "Iteration 0; 333/469 \tMinibatch Loss 0.197  Accuracy 95%\n",
      "Iteration 0; 334/469 \tMinibatch Loss 0.059  Accuracy 98%\n",
      "Iteration 0; 335/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 0; 336/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 0; 337/469 \tMinibatch Loss 0.151  Accuracy 95%\n",
      "Iteration 0; 338/469 \tMinibatch Loss 0.112  Accuracy 97%\n",
      "Iteration 0; 339/469 \tMinibatch Loss 0.087  Accuracy 98%\n",
      "Iteration 0; 340/469 \tMinibatch Loss 0.079  Accuracy 98%\n",
      "Iteration 0; 341/469 \tMinibatch Loss 0.035  Accuracy 98%\n",
      "Iteration 0; 342/469 \tMinibatch Loss 0.117  Accuracy 95%\n",
      "Iteration 0; 343/469 \tMinibatch Loss 0.084  Accuracy 96%\n",
      "Iteration 0; 344/469 \tMinibatch Loss 0.032  Accuracy 100%\n",
      "Iteration 0; 345/469 \tMinibatch Loss 0.097  Accuracy 97%\n",
      "Iteration 0; 346/469 \tMinibatch Loss 0.086  Accuracy 98%\n",
      "Iteration 0; 347/469 \tMinibatch Loss 0.086  Accuracy 97%\n",
      "Iteration 0; 348/469 \tMinibatch Loss 0.101  Accuracy 96%\n",
      "Iteration 0; 349/469 \tMinibatch Loss 0.146  Accuracy 96%\n",
      "Iteration 0; 350/469 \tMinibatch Loss 0.053  Accuracy 99%\n",
      "Iteration 0; 351/469 \tMinibatch Loss 0.026  Accuracy 100%\n",
      "Iteration 0; 352/469 \tMinibatch Loss 0.170  Accuracy 95%\n",
      "Iteration 0; 353/469 \tMinibatch Loss 0.049  Accuracy 99%\n",
      "Iteration 0; 354/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 0; 355/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 0; 356/469 \tMinibatch Loss 0.116  Accuracy 96%\n",
      "Iteration 0; 357/469 \tMinibatch Loss 0.077  Accuracy 98%\n",
      "Iteration 0; 358/469 \tMinibatch Loss 0.059  Accuracy 99%\n",
      "Iteration 0; 359/469 \tMinibatch Loss 0.068  Accuracy 98%\n",
      "Iteration 0; 360/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 0; 361/469 \tMinibatch Loss 0.147  Accuracy 95%\n",
      "Iteration 0; 362/469 \tMinibatch Loss 0.093  Accuracy 96%\n",
      "Iteration 0; 363/469 \tMinibatch Loss 0.071  Accuracy 98%\n",
      "Iteration 0; 364/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 0; 365/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 0; 366/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 0; 367/469 \tMinibatch Loss 0.128  Accuracy 98%\n",
      "Iteration 0; 368/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 0; 369/469 \tMinibatch Loss 0.098  Accuracy 96%\n",
      "Iteration 0; 370/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 0; 371/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 0; 372/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 0; 373/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 0; 374/469 \tMinibatch Loss 0.189  Accuracy 95%\n",
      "Iteration 0; 375/469 \tMinibatch Loss 0.054  Accuracy 97%\n",
      "Iteration 0; 376/469 \tMinibatch Loss 0.073  Accuracy 98%\n",
      "Iteration 0; 377/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 0; 378/469 \tMinibatch Loss 0.082  Accuracy 98%\n",
      "Iteration 0; 379/469 \tMinibatch Loss 0.073  Accuracy 98%\n",
      "Iteration 0; 380/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 0; 381/469 \tMinibatch Loss 0.120  Accuracy 95%\n",
      "Iteration 0; 382/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 0; 383/469 \tMinibatch Loss 0.158  Accuracy 95%\n",
      "Iteration 0; 384/469 \tMinibatch Loss 0.090  Accuracy 97%\n",
      "Iteration 0; 385/469 \tMinibatch Loss 0.059  Accuracy 97%\n",
      "Iteration 0; 386/469 \tMinibatch Loss 0.023  Accuracy 100%\n",
      "Iteration 0; 387/469 \tMinibatch Loss 0.061  Accuracy 98%\n",
      "Iteration 0; 388/469 \tMinibatch Loss 0.117  Accuracy 95%\n",
      "Iteration 0; 389/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 0; 390/469 \tMinibatch Loss 0.104  Accuracy 97%\n",
      "Iteration 0; 391/469 \tMinibatch Loss 0.092  Accuracy 99%\n",
      "Iteration 0; 392/469 \tMinibatch Loss 0.084  Accuracy 98%\n",
      "Iteration 0; 393/469 \tMinibatch Loss 0.082  Accuracy 97%\n",
      "Iteration 0; 394/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 0; 395/469 \tMinibatch Loss 0.046  Accuracy 99%\n",
      "Iteration 0; 396/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 0; 397/469 \tMinibatch Loss 0.075  Accuracy 98%\n",
      "Iteration 0; 398/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 0; 399/469 \tMinibatch Loss 0.090  Accuracy 96%\n",
      "Iteration 0; 400/469 \tMinibatch Loss 0.094  Accuracy 97%\n",
      "Iteration 0; 401/469 \tMinibatch Loss 0.041  Accuracy 99%\n",
      "Iteration 0; 402/469 \tMinibatch Loss 0.079  Accuracy 97%\n",
      "Iteration 0; 403/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 0; 404/469 \tMinibatch Loss 0.080  Accuracy 96%\n",
      "Iteration 0; 405/469 \tMinibatch Loss 0.097  Accuracy 98%\n",
      "Iteration 0; 406/469 \tMinibatch Loss 0.082  Accuracy 98%\n",
      "Iteration 0; 407/469 \tMinibatch Loss 0.084  Accuracy 98%\n",
      "Iteration 0; 408/469 \tMinibatch Loss 0.028  Accuracy 98%\n",
      "Iteration 0; 409/469 \tMinibatch Loss 0.076  Accuracy 97%\n",
      "Iteration 0; 410/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 0; 411/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 0; 412/469 \tMinibatch Loss 0.056  Accuracy 96%\n",
      "Iteration 0; 413/469 \tMinibatch Loss 0.076  Accuracy 99%\n",
      "Iteration 0; 414/469 \tMinibatch Loss 0.058  Accuracy 97%\n",
      "Iteration 0; 415/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 0; 416/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 0; 417/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 0; 418/469 \tMinibatch Loss 0.056  Accuracy 99%\n",
      "Iteration 0; 419/469 \tMinibatch Loss 0.093  Accuracy 98%\n",
      "Iteration 0; 420/469 \tMinibatch Loss 0.116  Accuracy 96%\n",
      "Iteration 0; 421/469 \tMinibatch Loss 0.110  Accuracy 95%\n",
      "Iteration 0; 422/469 \tMinibatch Loss 0.083  Accuracy 98%\n",
      "Iteration 0; 423/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 0; 424/469 \tMinibatch Loss 0.078  Accuracy 98%\n",
      "Iteration 0; 425/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 0; 426/469 \tMinibatch Loss 0.092  Accuracy 97%\n",
      "Iteration 0; 427/469 \tMinibatch Loss 0.088  Accuracy 98%\n",
      "Iteration 0; 428/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 0; 429/469 \tMinibatch Loss 0.123  Accuracy 95%\n",
      "Iteration 0; 430/469 \tMinibatch Loss 0.070  Accuracy 98%\n",
      "Iteration 0; 431/469 \tMinibatch Loss 0.074  Accuracy 98%\n",
      "Iteration 0; 432/469 \tMinibatch Loss 0.120  Accuracy 97%\n",
      "Iteration 0; 433/469 \tMinibatch Loss 0.086  Accuracy 96%\n",
      "Iteration 0; 434/469 \tMinibatch Loss 0.143  Accuracy 96%\n",
      "Iteration 0; 435/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 0; 436/469 \tMinibatch Loss 0.073  Accuracy 98%\n",
      "Iteration 0; 437/469 \tMinibatch Loss 0.101  Accuracy 97%\n",
      "Iteration 0; 438/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 0; 439/469 \tMinibatch Loss 0.073  Accuracy 98%\n",
      "Iteration 0; 440/469 \tMinibatch Loss 0.057  Accuracy 97%\n",
      "Iteration 0; 441/469 \tMinibatch Loss 0.023  Accuracy 100%\n",
      "Iteration 0; 442/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 0; 443/469 \tMinibatch Loss 0.022  Accuracy 100%\n",
      "Iteration 0; 444/469 \tMinibatch Loss 0.070  Accuracy 98%\n",
      "Iteration 0; 445/469 \tMinibatch Loss 0.078  Accuracy 96%\n",
      "Iteration 0; 446/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 0; 447/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 0; 448/469 \tMinibatch Loss 0.059  Accuracy 98%\n",
      "Iteration 0; 449/469 \tMinibatch Loss 0.039  Accuracy 99%\n",
      "Iteration 0; 450/469 \tMinibatch Loss 0.085  Accuracy 97%\n",
      "Iteration 0; 451/469 \tMinibatch Loss 0.040  Accuracy 99%\n",
      "Iteration 0; 452/469 \tMinibatch Loss 0.127  Accuracy 98%\n",
      "Iteration 0; 453/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 0; 454/469 \tMinibatch Loss 0.106  Accuracy 96%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0; 455/469 \tMinibatch Loss 0.093  Accuracy 97%\n",
      "Iteration 0; 456/469 \tMinibatch Loss 0.067  Accuracy 98%\n",
      "Iteration 0; 457/469 \tMinibatch Loss 0.089  Accuracy 98%\n",
      "Iteration 0; 458/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 0; 459/469 \tMinibatch Loss 0.049  Accuracy 97%\n",
      "Iteration 0; 460/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 0; 461/469 \tMinibatch Loss 0.044  Accuracy 99%\n",
      "Iteration 0; 462/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 0; 463/469 \tMinibatch Loss 0.083  Accuracy 96%\n",
      "Iteration 0; 464/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 0; 465/469 \tMinibatch Loss 0.079  Accuracy 95%\n",
      "Iteration 0; 466/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 0; 467/469 \tMinibatch Loss 0.047  Accuracy 99%\n",
      "Iteration 0; 468/469 \tMinibatch Loss 0.073  Accuracy 97%\n",
      "Iteration 1; 0/469 \tMinibatch Loss 0.045  Accuracy 99%\n",
      "Iteration 1; 1/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 1; 2/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 1; 3/469 \tMinibatch Loss 0.097  Accuracy 98%\n",
      "Iteration 1; 4/469 \tMinibatch Loss 0.046  Accuracy 99%\n",
      "Iteration 1; 5/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 1; 6/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 1; 7/469 \tMinibatch Loss 0.063  Accuracy 98%\n",
      "Iteration 1; 8/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 1; 9/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 1; 10/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 1; 11/469 \tMinibatch Loss 0.106  Accuracy 96%\n",
      "Iteration 1; 12/469 \tMinibatch Loss 0.059  Accuracy 98%\n",
      "Iteration 1; 13/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 1; 14/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 1; 15/469 \tMinibatch Loss 0.090  Accuracy 97%\n",
      "Iteration 1; 16/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 1; 17/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 1; 18/469 \tMinibatch Loss 0.067  Accuracy 98%\n",
      "Iteration 1; 19/469 \tMinibatch Loss 0.097  Accuracy 97%\n",
      "Iteration 1; 20/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 1; 21/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 1; 22/469 \tMinibatch Loss 0.076  Accuracy 98%\n",
      "Iteration 1; 23/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 1; 24/469 \tMinibatch Loss 0.035  Accuracy 98%\n",
      "Iteration 1; 25/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 1; 26/469 \tMinibatch Loss 0.024  Accuracy 100%\n",
      "Iteration 1; 27/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 1; 28/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 1; 29/469 \tMinibatch Loss 0.072  Accuracy 98%\n",
      "Iteration 1; 30/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 1; 31/469 \tMinibatch Loss 0.105  Accuracy 98%\n",
      "Iteration 1; 32/469 \tMinibatch Loss 0.063  Accuracy 97%\n",
      "Iteration 1; 33/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 1; 34/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 1; 35/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 1; 36/469 \tMinibatch Loss 0.060  Accuracy 97%\n",
      "Iteration 1; 37/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 1; 38/469 \tMinibatch Loss 0.059  Accuracy 98%\n",
      "Iteration 1; 39/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 1; 40/469 \tMinibatch Loss 0.071  Accuracy 98%\n",
      "Iteration 1; 41/469 \tMinibatch Loss 0.096  Accuracy 98%\n",
      "Iteration 1; 42/469 \tMinibatch Loss 0.045  Accuracy 99%\n",
      "Iteration 1; 43/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 1; 44/469 \tMinibatch Loss 0.111  Accuracy 98%\n",
      "Iteration 1; 45/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 1; 46/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 1; 47/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 1; 48/469 \tMinibatch Loss 0.031  Accuracy 100%\n",
      "Iteration 1; 49/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 1; 50/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 1; 51/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 1; 52/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 1; 53/469 \tMinibatch Loss 0.084  Accuracy 96%\n",
      "Iteration 1; 54/469 \tMinibatch Loss 0.071  Accuracy 98%\n",
      "Iteration 1; 55/469 \tMinibatch Loss 0.092  Accuracy 98%\n",
      "Iteration 1; 56/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 1; 57/469 \tMinibatch Loss 0.044  Accuracy 99%\n",
      "Iteration 1; 58/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 1; 59/469 \tMinibatch Loss 0.058  Accuracy 99%\n",
      "Iteration 1; 60/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 1; 61/469 \tMinibatch Loss 0.082  Accuracy 98%\n",
      "Iteration 1; 62/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 1; 63/469 \tMinibatch Loss 0.113  Accuracy 98%\n",
      "Iteration 1; 64/469 \tMinibatch Loss 0.056  Accuracy 97%\n",
      "Iteration 1; 65/469 \tMinibatch Loss 0.156  Accuracy 95%\n",
      "Iteration 1; 66/469 \tMinibatch Loss 0.080  Accuracy 98%\n",
      "Iteration 1; 67/469 \tMinibatch Loss 0.090  Accuracy 98%\n",
      "Iteration 1; 68/469 \tMinibatch Loss 0.051  Accuracy 97%\n",
      "Iteration 1; 69/469 \tMinibatch Loss 0.058  Accuracy 99%\n",
      "Iteration 1; 70/469 \tMinibatch Loss 0.106  Accuracy 95%\n",
      "Iteration 1; 71/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 1; 72/469 \tMinibatch Loss 0.078  Accuracy 97%\n",
      "Iteration 1; 73/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 1; 74/469 \tMinibatch Loss 0.084  Accuracy 97%\n",
      "Iteration 1; 75/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 1; 76/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 1; 77/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 1; 78/469 \tMinibatch Loss 0.068  Accuracy 98%\n",
      "Iteration 1; 79/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 1; 80/469 \tMinibatch Loss 0.150  Accuracy 96%\n",
      "Iteration 1; 81/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 1; 82/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 1; 83/469 \tMinibatch Loss 0.030  Accuracy 100%\n",
      "Iteration 1; 84/469 \tMinibatch Loss 0.021  Accuracy 100%\n",
      "Iteration 1; 85/469 \tMinibatch Loss 0.045  Accuracy 99%\n",
      "Iteration 1; 86/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 1; 87/469 \tMinibatch Loss 0.025  Accuracy 100%\n",
      "Iteration 1; 88/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 1; 89/469 \tMinibatch Loss 0.096  Accuracy 98%\n",
      "Iteration 1; 90/469 \tMinibatch Loss 0.098  Accuracy 97%\n",
      "Iteration 1; 91/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 1; 92/469 \tMinibatch Loss 0.019  Accuracy 100%\n",
      "Iteration 1; 93/469 \tMinibatch Loss 0.068  Accuracy 98%\n",
      "Iteration 1; 94/469 \tMinibatch Loss 0.063  Accuracy 98%\n",
      "Iteration 1; 95/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 1; 96/469 \tMinibatch Loss 0.038  Accuracy 99%\n",
      "Iteration 1; 97/469 \tMinibatch Loss 0.112  Accuracy 96%\n",
      "Iteration 1; 98/469 \tMinibatch Loss 0.103  Accuracy 97%\n",
      "Iteration 1; 99/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 1; 100/469 \tMinibatch Loss 0.058  Accuracy 98%\n",
      "Iteration 1; 101/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 1; 102/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 1; 103/469 \tMinibatch Loss 0.068  Accuracy 99%\n",
      "Iteration 1; 104/469 \tMinibatch Loss 0.096  Accuracy 98%\n",
      "Iteration 1; 105/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 1; 106/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 1; 107/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 1; 108/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 1; 109/469 \tMinibatch Loss 0.092  Accuracy 96%\n",
      "Iteration 1; 110/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 1; 111/469 \tMinibatch Loss 0.047  Accuracy 97%\n",
      "Iteration 1; 112/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 1; 113/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 1; 114/469 \tMinibatch Loss 0.019  Accuracy 98%\n",
      "Iteration 1; 115/469 \tMinibatch Loss 0.098  Accuracy 98%\n",
      "Iteration 1; 116/469 \tMinibatch Loss 0.074  Accuracy 98%\n",
      "Iteration 1; 117/469 \tMinibatch Loss 0.067  Accuracy 96%\n",
      "Iteration 1; 118/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 1; 119/469 \tMinibatch Loss 0.043  Accuracy 99%\n",
      "Iteration 1; 120/469 \tMinibatch Loss 0.048  Accuracy 99%\n",
      "Iteration 1; 121/469 \tMinibatch Loss 0.046  Accuracy 99%\n",
      "Iteration 1; 122/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 1; 123/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 1; 124/469 \tMinibatch Loss 0.020  Accuracy 100%\n",
      "Iteration 1; 125/469 \tMinibatch Loss 0.073  Accuracy 98%\n",
      "Iteration 1; 126/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 1; 127/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 1; 128/469 \tMinibatch Loss 0.043  Accuracy 98%\n",
      "Iteration 1; 129/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 1; 130/469 \tMinibatch Loss 0.113  Accuracy 95%\n",
      "Iteration 1; 131/469 \tMinibatch Loss 0.012  Accuracy 99%\n",
      "Iteration 1; 132/469 \tMinibatch Loss 0.045  Accuracy 99%\n",
      "Iteration 1; 133/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 1; 134/469 \tMinibatch Loss 0.044  Accuracy 99%\n",
      "Iteration 1; 135/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 1; 136/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 1; 137/469 \tMinibatch Loss 0.046  Accuracy 98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1; 138/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 1; 139/469 \tMinibatch Loss 0.081  Accuracy 98%\n",
      "Iteration 1; 140/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 1; 141/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 1; 142/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 1; 143/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 1; 144/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 1; 145/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 1; 146/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 1; 147/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 1; 148/469 \tMinibatch Loss 0.049  Accuracy 99%\n",
      "Iteration 1; 149/469 \tMinibatch Loss 0.077  Accuracy 98%\n",
      "Iteration 1; 150/469 \tMinibatch Loss 0.094  Accuracy 96%\n",
      "Iteration 1; 151/469 \tMinibatch Loss 0.075  Accuracy 98%\n",
      "Iteration 1; 152/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 1; 153/469 \tMinibatch Loss 0.061  Accuracy 98%\n",
      "Iteration 1; 154/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 1; 155/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 1; 156/469 \tMinibatch Loss 0.068  Accuracy 98%\n",
      "Iteration 1; 157/469 \tMinibatch Loss 0.097  Accuracy 98%\n",
      "Iteration 1; 158/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 1; 159/469 \tMinibatch Loss 0.074  Accuracy 98%\n",
      "Iteration 1; 160/469 \tMinibatch Loss 0.125  Accuracy 96%\n",
      "Iteration 1; 161/469 \tMinibatch Loss 0.023  Accuracy 100%\n",
      "Iteration 1; 162/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 1; 163/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 1; 164/469 \tMinibatch Loss 0.108  Accuracy 96%\n",
      "Iteration 1; 165/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 1; 166/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 1; 167/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 1; 168/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 1; 169/469 \tMinibatch Loss 0.027  Accuracy 98%\n",
      "Iteration 1; 170/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 1; 171/469 \tMinibatch Loss 0.062  Accuracy 99%\n",
      "Iteration 1; 172/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 1; 173/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 1; 174/469 \tMinibatch Loss 0.067  Accuracy 97%\n",
      "Iteration 1; 175/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 1; 176/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 1; 177/469 \tMinibatch Loss 0.081  Accuracy 98%\n",
      "Iteration 1; 178/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 1; 179/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 1; 180/469 \tMinibatch Loss 0.043  Accuracy 98%\n",
      "Iteration 1; 181/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 1; 182/469 \tMinibatch Loss 0.035  Accuracy 98%\n",
      "Iteration 1; 183/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 1; 184/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 1; 185/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 1; 186/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 1; 187/469 \tMinibatch Loss 0.048  Accuracy 99%\n",
      "Iteration 1; 188/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 1; 189/469 \tMinibatch Loss 0.037  Accuracy 98%\n",
      "Iteration 1; 190/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 1; 191/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 1; 192/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 1; 193/469 \tMinibatch Loss 0.068  Accuracy 97%\n",
      "Iteration 1; 194/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 1; 195/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 1; 196/469 \tMinibatch Loss 0.026  Accuracy 100%\n",
      "Iteration 1; 197/469 \tMinibatch Loss 0.054  Accuracy 99%\n",
      "Iteration 1; 198/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 1; 199/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 1; 200/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 1; 201/469 \tMinibatch Loss 0.161  Accuracy 95%\n",
      "Iteration 1; 202/469 \tMinibatch Loss 0.121  Accuracy 97%\n",
      "Iteration 1; 203/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 1; 204/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 1; 205/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 1; 206/469 \tMinibatch Loss 0.115  Accuracy 97%\n",
      "Iteration 1; 207/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 1; 208/469 \tMinibatch Loss 0.076  Accuracy 98%\n",
      "Iteration 1; 209/469 \tMinibatch Loss 0.024  Accuracy 100%\n",
      "Iteration 1; 210/469 \tMinibatch Loss 0.099  Accuracy 96%\n",
      "Iteration 1; 211/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 1; 212/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 1; 213/469 \tMinibatch Loss 0.072  Accuracy 98%\n",
      "Iteration 1; 214/469 \tMinibatch Loss 0.086  Accuracy 98%\n",
      "Iteration 1; 215/469 \tMinibatch Loss 0.089  Accuracy 98%\n",
      "Iteration 1; 216/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 1; 217/469 \tMinibatch Loss 0.036  Accuracy 98%\n",
      "Iteration 1; 218/469 \tMinibatch Loss 0.085  Accuracy 98%\n",
      "Iteration 1; 219/469 \tMinibatch Loss 0.023  Accuracy 100%\n",
      "Iteration 1; 220/469 \tMinibatch Loss 0.152  Accuracy 95%\n",
      "Iteration 1; 221/469 \tMinibatch Loss 0.098  Accuracy 98%\n",
      "Iteration 1; 222/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 1; 223/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 1; 224/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 1; 225/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 1; 226/469 \tMinibatch Loss 0.017  Accuracy 100%\n",
      "Iteration 1; 227/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 1; 228/469 \tMinibatch Loss 0.170  Accuracy 95%\n",
      "Iteration 1; 229/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 1; 230/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 1; 231/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 1; 232/469 \tMinibatch Loss 0.080  Accuracy 97%\n",
      "Iteration 1; 233/469 \tMinibatch Loss 0.115  Accuracy 98%\n",
      "Iteration 1; 234/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 1; 235/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 1; 236/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 1; 237/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 1; 238/469 \tMinibatch Loss 0.061  Accuracy 98%\n",
      "Iteration 1; 239/469 \tMinibatch Loss 0.022  Accuracy 100%\n",
      "Iteration 1; 240/469 \tMinibatch Loss 0.126  Accuracy 95%\n",
      "Iteration 1; 241/469 \tMinibatch Loss 0.225  Accuracy 98%\n",
      "Iteration 1; 242/469 \tMinibatch Loss 0.109  Accuracy 96%\n",
      "Iteration 1; 243/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 1; 244/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 1; 245/469 \tMinibatch Loss 0.082  Accuracy 98%\n",
      "Iteration 1; 246/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 1; 247/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 1; 248/469 \tMinibatch Loss 0.054  Accuracy 97%\n",
      "Iteration 1; 249/469 \tMinibatch Loss 0.148  Accuracy 98%\n",
      "Iteration 1; 250/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 1; 251/469 \tMinibatch Loss 0.089  Accuracy 98%\n",
      "Iteration 1; 252/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 1; 253/469 \tMinibatch Loss 0.036  Accuracy 98%\n",
      "Iteration 1; 254/469 \tMinibatch Loss 0.034  Accuracy 100%\n",
      "Iteration 1; 255/469 \tMinibatch Loss 0.063  Accuracy 99%\n",
      "Iteration 1; 256/469 \tMinibatch Loss 0.092  Accuracy 97%\n",
      "Iteration 1; 257/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 1; 258/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 1; 259/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 1; 260/469 \tMinibatch Loss 0.077  Accuracy 98%\n",
      "Iteration 1; 261/469 \tMinibatch Loss 0.085  Accuracy 98%\n",
      "Iteration 1; 262/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 1; 263/469 \tMinibatch Loss 0.027  Accuracy 98%\n",
      "Iteration 1; 264/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 1; 265/469 \tMinibatch Loss 0.022  Accuracy 100%\n",
      "Iteration 1; 266/469 \tMinibatch Loss 0.020  Accuracy 100%\n",
      "Iteration 1; 267/469 \tMinibatch Loss 0.097  Accuracy 98%\n",
      "Iteration 1; 268/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 1; 269/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 1; 270/469 \tMinibatch Loss 0.070  Accuracy 98%\n",
      "Iteration 1; 271/469 \tMinibatch Loss 0.067  Accuracy 97%\n",
      "Iteration 1; 272/469 \tMinibatch Loss 0.062  Accuracy 97%\n",
      "Iteration 1; 273/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 1; 274/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 1; 275/469 \tMinibatch Loss 0.110  Accuracy 96%\n",
      "Iteration 1; 276/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 1; 277/469 \tMinibatch Loss 0.099  Accuracy 98%\n",
      "Iteration 1; 278/469 \tMinibatch Loss 0.045  Accuracy 99%\n",
      "Iteration 1; 279/469 \tMinibatch Loss 0.131  Accuracy 97%\n",
      "Iteration 1; 280/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 1; 281/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 1; 282/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 1; 283/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 1; 284/469 \tMinibatch Loss 0.079  Accuracy 97%\n",
      "Iteration 1; 285/469 \tMinibatch Loss 0.125  Accuracy 98%\n",
      "Iteration 1; 286/469 \tMinibatch Loss 0.025  Accuracy 100%\n",
      "Iteration 1; 287/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 1; 288/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 1; 289/469 \tMinibatch Loss 0.075  Accuracy 99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1; 290/469 \tMinibatch Loss 0.036  Accuracy 98%\n",
      "Iteration 1; 291/469 \tMinibatch Loss 0.083  Accuracy 98%\n",
      "Iteration 1; 292/469 \tMinibatch Loss 0.045  Accuracy 99%\n",
      "Iteration 1; 293/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 1; 294/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 1; 295/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 1; 296/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 1; 297/469 \tMinibatch Loss 0.086  Accuracy 95%\n",
      "Iteration 1; 298/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 1; 299/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 1; 300/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 1; 301/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 1; 302/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 1; 303/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 1; 304/469 \tMinibatch Loss 0.121  Accuracy 95%\n",
      "Iteration 1; 305/469 \tMinibatch Loss 0.035  Accuracy 98%\n",
      "Iteration 1; 306/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 1; 307/469 \tMinibatch Loss 0.058  Accuracy 99%\n",
      "Iteration 1; 308/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 1; 309/469 \tMinibatch Loss 0.025  Accuracy 98%\n",
      "Iteration 1; 310/469 \tMinibatch Loss 0.030  Accuracy 100%\n",
      "Iteration 1; 311/469 \tMinibatch Loss 0.124  Accuracy 97%\n",
      "Iteration 1; 312/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 1; 313/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 1; 314/469 \tMinibatch Loss 0.113  Accuracy 98%\n",
      "Iteration 1; 315/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 1; 316/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 1; 317/469 \tMinibatch Loss 0.024  Accuracy 100%\n",
      "Iteration 1; 318/469 \tMinibatch Loss 0.076  Accuracy 98%\n",
      "Iteration 1; 319/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 1; 320/469 \tMinibatch Loss 0.020  Accuracy 100%\n",
      "Iteration 1; 321/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 1; 322/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 1; 323/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 1; 324/469 \tMinibatch Loss 0.017  Accuracy 100%\n",
      "Iteration 1; 325/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 1; 326/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 1; 327/469 \tMinibatch Loss 0.068  Accuracy 98%\n",
      "Iteration 1; 328/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 1; 329/469 \tMinibatch Loss 0.083  Accuracy 98%\n",
      "Iteration 1; 330/469 \tMinibatch Loss 0.102  Accuracy 97%\n",
      "Iteration 1; 331/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 1; 332/469 \tMinibatch Loss 0.035  Accuracy 98%\n",
      "Iteration 1; 333/469 \tMinibatch Loss 0.095  Accuracy 97%\n",
      "Iteration 1; 334/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 1; 335/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 1; 336/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 1; 337/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 1; 338/469 \tMinibatch Loss 0.102  Accuracy 98%\n",
      "Iteration 1; 339/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 1; 340/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 1; 341/469 \tMinibatch Loss 0.058  Accuracy 97%\n",
      "Iteration 1; 342/469 \tMinibatch Loss 0.042  Accuracy 99%\n",
      "Iteration 1; 343/469 \tMinibatch Loss 0.076  Accuracy 98%\n",
      "Iteration 1; 344/469 \tMinibatch Loss 0.067  Accuracy 97%\n",
      "Iteration 1; 345/469 \tMinibatch Loss 0.077  Accuracy 98%\n",
      "Iteration 1; 346/469 \tMinibatch Loss 0.002  Accuracy 100%\n",
      "Iteration 1; 347/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 1; 348/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 1; 349/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 1; 350/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 1; 351/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 1; 352/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 1; 353/469 \tMinibatch Loss 0.093  Accuracy 98%\n",
      "Iteration 1; 354/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 1; 355/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 1; 356/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 1; 357/469 \tMinibatch Loss 0.030  Accuracy 100%\n",
      "Iteration 1; 358/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 1; 359/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 1; 360/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 1; 361/469 \tMinibatch Loss 0.114  Accuracy 97%\n",
      "Iteration 1; 362/469 \tMinibatch Loss 0.175  Accuracy 97%\n",
      "Iteration 1; 363/469 \tMinibatch Loss 0.108  Accuracy 98%\n",
      "Iteration 1; 364/469 \tMinibatch Loss 0.076  Accuracy 97%\n",
      "Iteration 1; 365/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 1; 366/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 1; 367/469 \tMinibatch Loss 0.084  Accuracy 98%\n",
      "Iteration 1; 368/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 1; 369/469 \tMinibatch Loss 0.087  Accuracy 98%\n",
      "Iteration 1; 370/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 1; 371/469 \tMinibatch Loss 0.080  Accuracy 97%\n",
      "Iteration 1; 372/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 1; 373/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 1; 374/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 1; 375/469 \tMinibatch Loss 0.127  Accuracy 95%\n",
      "Iteration 1; 376/469 \tMinibatch Loss 0.100  Accuracy 98%\n",
      "Iteration 1; 377/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 1; 378/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 1; 379/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 1; 380/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 1; 381/469 \tMinibatch Loss 0.068  Accuracy 98%\n",
      "Iteration 1; 382/469 \tMinibatch Loss 0.020  Accuracy 100%\n",
      "Iteration 1; 383/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 1; 384/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 1; 385/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 1; 386/469 \tMinibatch Loss 0.067  Accuracy 97%\n",
      "Iteration 1; 387/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 1; 388/469 \tMinibatch Loss 0.023  Accuracy 100%\n",
      "Iteration 1; 389/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 1; 390/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 1; 391/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 1; 392/469 \tMinibatch Loss 0.063  Accuracy 98%\n",
      "Iteration 1; 393/469 \tMinibatch Loss 0.104  Accuracy 98%\n",
      "Iteration 1; 394/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 1; 395/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 1; 396/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 1; 397/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 1; 398/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 1; 399/469 \tMinibatch Loss 0.038  Accuracy 99%\n",
      "Iteration 1; 400/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 1; 401/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 1; 402/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 1; 403/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 1; 404/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 1; 405/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 1; 406/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 1; 407/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 1; 408/469 \tMinibatch Loss 0.025  Accuracy 100%\n",
      "Iteration 1; 409/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 1; 410/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 1; 411/469 \tMinibatch Loss 0.061  Accuracy 98%\n",
      "Iteration 1; 412/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 1; 413/469 \tMinibatch Loss 0.082  Accuracy 98%\n",
      "Iteration 1; 414/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 1; 415/469 \tMinibatch Loss 0.082  Accuracy 98%\n",
      "Iteration 1; 416/469 \tMinibatch Loss 0.058  Accuracy 98%\n",
      "Iteration 1; 417/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 1; 418/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 1; 419/469 \tMinibatch Loss 0.083  Accuracy 97%\n",
      "Iteration 1; 420/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 1; 421/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 1; 422/469 \tMinibatch Loss 0.025  Accuracy 100%\n",
      "Iteration 1; 423/469 \tMinibatch Loss 0.034  Accuracy 100%\n",
      "Iteration 1; 424/469 \tMinibatch Loss 0.129  Accuracy 97%\n",
      "Iteration 1; 425/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 1; 426/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 1; 427/469 \tMinibatch Loss 0.065  Accuracy 99%\n",
      "Iteration 1; 428/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 1; 429/469 \tMinibatch Loss 0.043  Accuracy 99%\n",
      "Iteration 1; 430/469 \tMinibatch Loss 0.041  Accuracy 99%\n",
      "Iteration 1; 431/469 \tMinibatch Loss 0.071  Accuracy 98%\n",
      "Iteration 1; 432/469 \tMinibatch Loss 0.037  Accuracy 98%\n",
      "Iteration 1; 433/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 1; 434/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 1; 435/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 1; 436/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 1; 437/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 1; 438/469 \tMinibatch Loss 0.043  Accuracy 98%\n",
      "Iteration 1; 439/469 \tMinibatch Loss 0.076  Accuracy 98%\n",
      "Iteration 1; 440/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 1; 441/469 \tMinibatch Loss 0.008  Accuracy 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1; 442/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 1; 443/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 1; 444/469 \tMinibatch Loss 0.081  Accuracy 97%\n",
      "Iteration 1; 445/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 1; 446/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 1; 447/469 \tMinibatch Loss 0.042  Accuracy 99%\n",
      "Iteration 1; 448/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 1; 449/469 \tMinibatch Loss 0.128  Accuracy 97%\n",
      "Iteration 1; 450/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 1; 451/469 \tMinibatch Loss 0.047  Accuracy 97%\n",
      "Iteration 1; 452/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 1; 453/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 1; 454/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 1; 455/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 1; 456/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 1; 457/469 \tMinibatch Loss 0.078  Accuracy 98%\n",
      "Iteration 1; 458/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 1; 459/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 1; 460/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 1; 461/469 \tMinibatch Loss 0.071  Accuracy 98%\n",
      "Iteration 1; 462/469 \tMinibatch Loss 0.075  Accuracy 97%\n",
      "Iteration 1; 463/469 \tMinibatch Loss 0.044  Accuracy 99%\n",
      "Iteration 1; 464/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 1; 465/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 1; 466/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 1; 467/469 \tMinibatch Loss 0.111  Accuracy 98%\n",
      "Iteration 1; 468/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 2; 0/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 2; 1/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 2; 2/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 2; 3/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 2; 4/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 2; 5/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 2; 6/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 2; 7/469 \tMinibatch Loss 0.039  Accuracy 99%\n",
      "Iteration 2; 8/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 2; 9/469 \tMinibatch Loss 0.109  Accuracy 97%\n",
      "Iteration 2; 10/469 \tMinibatch Loss 0.017  Accuracy 100%\n",
      "Iteration 2; 11/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 2; 12/469 \tMinibatch Loss 0.106  Accuracy 97%\n",
      "Iteration 2; 13/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 2; 14/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 2; 15/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 2; 16/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 2; 17/469 \tMinibatch Loss 0.033  Accuracy 100%\n",
      "Iteration 2; 18/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 2; 19/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 2; 20/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 2; 21/469 \tMinibatch Loss 0.048  Accuracy 99%\n",
      "Iteration 2; 22/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 2; 23/469 \tMinibatch Loss 0.078  Accuracy 96%\n",
      "Iteration 2; 24/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 2; 25/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 2; 26/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 2; 27/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 2; 28/469 \tMinibatch Loss 0.078  Accuracy 98%\n",
      "Iteration 2; 29/469 \tMinibatch Loss 0.048  Accuracy 99%\n",
      "Iteration 2; 30/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 2; 31/469 \tMinibatch Loss 0.024  Accuracy 100%\n",
      "Iteration 2; 32/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 2; 33/469 \tMinibatch Loss 0.068  Accuracy 98%\n",
      "Iteration 2; 34/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 2; 35/469 \tMinibatch Loss 0.013  Accuracy 99%\n",
      "Iteration 2; 36/469 \tMinibatch Loss 0.027  Accuracy 98%\n",
      "Iteration 2; 37/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 2; 38/469 \tMinibatch Loss 0.082  Accuracy 98%\n",
      "Iteration 2; 39/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 2; 40/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 2; 41/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 2; 42/469 \tMinibatch Loss 0.078  Accuracy 98%\n",
      "Iteration 2; 43/469 \tMinibatch Loss 0.050  Accuracy 99%\n",
      "Iteration 2; 44/469 \tMinibatch Loss 0.024  Accuracy 100%\n",
      "Iteration 2; 45/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 2; 46/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 2; 47/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 2; 48/469 \tMinibatch Loss 0.037  Accuracy 99%\n",
      "Iteration 2; 49/469 \tMinibatch Loss 0.068  Accuracy 98%\n",
      "Iteration 2; 50/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 2; 51/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 2; 52/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 2; 53/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 2; 54/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 2; 55/469 \tMinibatch Loss 0.054  Accuracy 99%\n",
      "Iteration 2; 56/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 2; 57/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 2; 58/469 \tMinibatch Loss 0.039  Accuracy 99%\n",
      "Iteration 2; 59/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 2; 60/469 \tMinibatch Loss 0.050  Accuracy 97%\n",
      "Iteration 2; 61/469 \tMinibatch Loss 0.020  Accuracy 100%\n",
      "Iteration 2; 62/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 2; 63/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 2; 64/469 \tMinibatch Loss 0.126  Accuracy 97%\n",
      "Iteration 2; 65/469 \tMinibatch Loss 0.081  Accuracy 97%\n",
      "Iteration 2; 66/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 2; 67/469 \tMinibatch Loss 0.017  Accuracy 100%\n",
      "Iteration 2; 68/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 2; 69/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 2; 70/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 2; 71/469 \tMinibatch Loss 0.021  Accuracy 100%\n",
      "Iteration 2; 72/469 \tMinibatch Loss 0.037  Accuracy 98%\n",
      "Iteration 2; 73/469 \tMinibatch Loss 0.023  Accuracy 100%\n",
      "Iteration 2; 74/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 2; 75/469 \tMinibatch Loss 0.022  Accuracy 98%\n",
      "Iteration 2; 76/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 2; 77/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 2; 78/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 2; 79/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 2; 80/469 \tMinibatch Loss 0.076  Accuracy 98%\n",
      "Iteration 2; 81/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 2; 82/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 2; 83/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 2; 84/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 2; 85/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 2; 86/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 2; 87/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 2; 88/469 \tMinibatch Loss 0.131  Accuracy 98%\n",
      "Iteration 2; 89/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 2; 90/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 2; 91/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 2; 92/469 \tMinibatch Loss 0.217  Accuracy 98%\n",
      "Iteration 2; 93/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 2; 94/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 2; 95/469 \tMinibatch Loss 0.070  Accuracy 97%\n",
      "Iteration 2; 96/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 2; 97/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 2; 98/469 \tMinibatch Loss 0.097  Accuracy 98%\n",
      "Iteration 2; 99/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 2; 100/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 2; 101/469 \tMinibatch Loss 0.067  Accuracy 98%\n",
      "Iteration 2; 102/469 \tMinibatch Loss 0.113  Accuracy 97%\n",
      "Iteration 2; 103/469 \tMinibatch Loss 0.058  Accuracy 98%\n",
      "Iteration 2; 104/469 \tMinibatch Loss 0.030  Accuracy 100%\n",
      "Iteration 2; 105/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 2; 106/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 2; 107/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 2; 108/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 2; 109/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 2; 110/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 2; 111/469 \tMinibatch Loss 0.063  Accuracy 99%\n",
      "Iteration 2; 112/469 \tMinibatch Loss 0.091  Accuracy 98%\n",
      "Iteration 2; 113/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 2; 114/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 2; 115/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 2; 116/469 \tMinibatch Loss 0.028  Accuracy 100%\n",
      "Iteration 2; 117/469 \tMinibatch Loss 0.074  Accuracy 97%\n",
      "Iteration 2; 118/469 \tMinibatch Loss 0.081  Accuracy 98%\n",
      "Iteration 2; 119/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 2; 120/469 \tMinibatch Loss 0.046  Accuracy 99%\n",
      "Iteration 2; 121/469 \tMinibatch Loss 0.073  Accuracy 98%\n",
      "Iteration 2; 122/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 2; 123/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 2; 124/469 \tMinibatch Loss 0.004  Accuracy 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2; 125/469 \tMinibatch Loss 0.063  Accuracy 98%\n",
      "Iteration 2; 126/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 2; 127/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 2; 128/469 \tMinibatch Loss 0.137  Accuracy 96%\n",
      "Iteration 2; 129/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 2; 130/469 \tMinibatch Loss 0.043  Accuracy 99%\n",
      "Iteration 2; 131/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 2; 132/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 2; 133/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 2; 134/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 2; 135/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 2; 136/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 2; 137/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 2; 138/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 2; 139/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 2; 140/469 \tMinibatch Loss 0.030  Accuracy 100%\n",
      "Iteration 2; 141/469 \tMinibatch Loss 0.079  Accuracy 98%\n",
      "Iteration 2; 142/469 \tMinibatch Loss 0.061  Accuracy 98%\n",
      "Iteration 2; 143/469 \tMinibatch Loss 0.064  Accuracy 99%\n",
      "Iteration 2; 144/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 2; 145/469 \tMinibatch Loss 0.106  Accuracy 99%\n",
      "Iteration 2; 146/469 \tMinibatch Loss 0.096  Accuracy 98%\n",
      "Iteration 2; 147/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 2; 148/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 2; 149/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 2; 150/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 2; 151/469 \tMinibatch Loss 0.048  Accuracy 97%\n",
      "Iteration 2; 152/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 2; 153/469 \tMinibatch Loss 0.087  Accuracy 98%\n",
      "Iteration 2; 154/469 \tMinibatch Loss 0.037  Accuracy 99%\n",
      "Iteration 2; 155/469 \tMinibatch Loss 0.077  Accuracy 96%\n",
      "Iteration 2; 156/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 2; 157/469 \tMinibatch Loss 0.076  Accuracy 97%\n",
      "Iteration 2; 158/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 2; 159/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 2; 160/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 2; 161/469 \tMinibatch Loss 0.063  Accuracy 98%\n",
      "Iteration 2; 162/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 2; 163/469 \tMinibatch Loss 0.128  Accuracy 97%\n",
      "Iteration 2; 164/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 2; 165/469 \tMinibatch Loss 0.078  Accuracy 98%\n",
      "Iteration 2; 166/469 \tMinibatch Loss 0.092  Accuracy 98%\n",
      "Iteration 2; 167/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 2; 168/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 2; 169/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 2; 170/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 2; 171/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 2; 172/469 \tMinibatch Loss 0.084  Accuracy 97%\n",
      "Iteration 2; 173/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 2; 174/469 \tMinibatch Loss 0.077  Accuracy 98%\n",
      "Iteration 2; 175/469 \tMinibatch Loss 0.038  Accuracy 99%\n",
      "Iteration 2; 176/469 \tMinibatch Loss 0.028  Accuracy 100%\n",
      "Iteration 2; 177/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 2; 178/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 2; 179/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 2; 180/469 \tMinibatch Loss 0.118  Accuracy 97%\n",
      "Iteration 2; 181/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 2; 182/469 \tMinibatch Loss 0.061  Accuracy 98%\n",
      "Iteration 2; 183/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 2; 184/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 2; 185/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 2; 186/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 2; 187/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 2; 188/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 2; 189/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 2; 190/469 \tMinibatch Loss 0.021  Accuracy 100%\n",
      "Iteration 2; 191/469 \tMinibatch Loss 0.012  Accuracy 99%\n",
      "Iteration 2; 192/469 \tMinibatch Loss 0.125  Accuracy 97%\n",
      "Iteration 2; 193/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 2; 194/469 \tMinibatch Loss 0.091  Accuracy 98%\n",
      "Iteration 2; 195/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 2; 196/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 2; 197/469 \tMinibatch Loss 0.078  Accuracy 98%\n",
      "Iteration 2; 198/469 \tMinibatch Loss 0.122  Accuracy 98%\n",
      "Iteration 2; 199/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 2; 200/469 \tMinibatch Loss 0.059  Accuracy 99%\n",
      "Iteration 2; 201/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 2; 202/469 \tMinibatch Loss 0.039  Accuracy 99%\n",
      "Iteration 2; 203/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 2; 204/469 \tMinibatch Loss 0.044  Accuracy 99%\n",
      "Iteration 2; 205/469 \tMinibatch Loss 0.070  Accuracy 98%\n",
      "Iteration 2; 206/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 2; 207/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 2; 208/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 2; 209/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 2; 210/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 2; 211/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 2; 212/469 \tMinibatch Loss 0.102  Accuracy 98%\n",
      "Iteration 2; 213/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 2; 214/469 \tMinibatch Loss 0.045  Accuracy 99%\n",
      "Iteration 2; 215/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 2; 216/469 \tMinibatch Loss 0.055  Accuracy 99%\n",
      "Iteration 2; 217/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 2; 218/469 \tMinibatch Loss 0.026  Accuracy 98%\n",
      "Iteration 2; 219/469 \tMinibatch Loss 0.075  Accuracy 98%\n",
      "Iteration 2; 220/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 2; 221/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 2; 222/469 \tMinibatch Loss 0.036  Accuracy 98%\n",
      "Iteration 2; 223/469 \tMinibatch Loss 0.025  Accuracy 98%\n",
      "Iteration 2; 224/469 \tMinibatch Loss 0.019  Accuracy 100%\n",
      "Iteration 2; 225/469 \tMinibatch Loss 0.106  Accuracy 97%\n",
      "Iteration 2; 226/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 2; 227/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 2; 228/469 \tMinibatch Loss 0.017  Accuracy 100%\n",
      "Iteration 2; 229/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 2; 230/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 2; 231/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 2; 232/469 \tMinibatch Loss 0.037  Accuracy 98%\n",
      "Iteration 2; 233/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 2; 234/469 \tMinibatch Loss 0.071  Accuracy 98%\n",
      "Iteration 2; 235/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 2; 236/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 2; 237/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 2; 238/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 2; 239/469 \tMinibatch Loss 0.096  Accuracy 98%\n",
      "Iteration 2; 240/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 2; 241/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 2; 242/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 2; 243/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 2; 244/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 2; 245/469 \tMinibatch Loss 0.111  Accuracy 96%\n",
      "Iteration 2; 246/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 2; 247/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 2; 248/469 \tMinibatch Loss 0.101  Accuracy 97%\n",
      "Iteration 2; 249/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 2; 250/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 2; 251/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 2; 252/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 2; 253/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 2; 254/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 2; 255/469 \tMinibatch Loss 0.077  Accuracy 97%\n",
      "Iteration 2; 256/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 2; 257/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 2; 258/469 \tMinibatch Loss 0.104  Accuracy 98%\n",
      "Iteration 2; 259/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 2; 260/469 \tMinibatch Loss 0.037  Accuracy 98%\n",
      "Iteration 2; 261/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 2; 262/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 2; 263/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 2; 264/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 2; 265/469 \tMinibatch Loss 0.114  Accuracy 98%\n",
      "Iteration 2; 266/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 2; 267/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 2; 268/469 \tMinibatch Loss 0.101  Accuracy 96%\n",
      "Iteration 2; 269/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 2; 270/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 2; 271/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 2; 272/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 2; 273/469 \tMinibatch Loss 0.020  Accuracy 98%\n",
      "Iteration 2; 274/469 \tMinibatch Loss 0.105  Accuracy 98%\n",
      "Iteration 2; 275/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 2; 276/469 \tMinibatch Loss 0.071  Accuracy 98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2; 277/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 2; 278/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 2; 279/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 2; 280/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 2; 281/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 2; 282/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 2; 283/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 2; 284/469 \tMinibatch Loss 0.067  Accuracy 98%\n",
      "Iteration 2; 285/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 2; 286/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 2; 287/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 2; 288/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 2; 289/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 2; 290/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 2; 291/469 \tMinibatch Loss 0.068  Accuracy 98%\n",
      "Iteration 2; 292/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 2; 293/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 2; 294/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 2; 295/469 \tMinibatch Loss 0.039  Accuracy 99%\n",
      "Iteration 2; 296/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 2; 297/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 2; 298/469 \tMinibatch Loss 0.026  Accuracy 98%\n",
      "Iteration 2; 299/469 \tMinibatch Loss 0.043  Accuracy 98%\n",
      "Iteration 2; 300/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 2; 301/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 2; 302/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 2; 303/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 2; 304/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 2; 305/469 \tMinibatch Loss 0.042  Accuracy 97%\n",
      "Iteration 2; 306/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 2; 307/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 2; 308/469 \tMinibatch Loss 0.102  Accuracy 97%\n",
      "Iteration 2; 309/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 2; 310/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 2; 311/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 2; 312/469 \tMinibatch Loss 0.066  Accuracy 97%\n",
      "Iteration 2; 313/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 2; 314/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 2; 315/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 2; 316/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 2; 317/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 2; 318/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 2; 319/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 2; 320/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 2; 321/469 \tMinibatch Loss 0.084  Accuracy 98%\n",
      "Iteration 2; 322/469 \tMinibatch Loss 0.136  Accuracy 96%\n",
      "Iteration 2; 323/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 2; 324/469 \tMinibatch Loss 0.059  Accuracy 99%\n",
      "Iteration 2; 325/469 \tMinibatch Loss 0.104  Accuracy 96%\n",
      "Iteration 2; 326/469 \tMinibatch Loss 0.086  Accuracy 98%\n",
      "Iteration 2; 327/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 2; 328/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 2; 329/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 2; 330/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 2; 331/469 \tMinibatch Loss 0.058  Accuracy 98%\n",
      "Iteration 2; 332/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 2; 333/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 2; 334/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 2; 335/469 \tMinibatch Loss 0.128  Accuracy 95%\n",
      "Iteration 2; 336/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 2; 337/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 2; 338/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 2; 339/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 2; 340/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 2; 341/469 \tMinibatch Loss 0.026  Accuracy 98%\n",
      "Iteration 2; 342/469 \tMinibatch Loss 0.078  Accuracy 98%\n",
      "Iteration 2; 343/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 2; 344/469 \tMinibatch Loss 0.072  Accuracy 98%\n",
      "Iteration 2; 345/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 2; 346/469 \tMinibatch Loss 0.094  Accuracy 98%\n",
      "Iteration 2; 347/469 \tMinibatch Loss 0.089  Accuracy 98%\n",
      "Iteration 2; 348/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 2; 349/469 \tMinibatch Loss 0.094  Accuracy 97%\n",
      "Iteration 2; 350/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 2; 351/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 2; 352/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 2; 353/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 2; 354/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 2; 355/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 2; 356/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 2; 357/469 \tMinibatch Loss 0.058  Accuracy 98%\n",
      "Iteration 2; 358/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 2; 359/469 \tMinibatch Loss 0.081  Accuracy 97%\n",
      "Iteration 2; 360/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 2; 361/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 2; 362/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 2; 363/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 2; 364/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 2; 365/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 2; 366/469 \tMinibatch Loss 0.065  Accuracy 97%\n",
      "Iteration 2; 367/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 2; 368/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 2; 369/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 2; 370/469 \tMinibatch Loss 0.086  Accuracy 98%\n",
      "Iteration 2; 371/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 2; 372/469 \tMinibatch Loss 0.073  Accuracy 98%\n",
      "Iteration 2; 373/469 \tMinibatch Loss 0.012  Accuracy 99%\n",
      "Iteration 2; 374/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 2; 375/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 2; 376/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 2; 377/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 2; 378/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 2; 379/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 2; 380/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 2; 381/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 2; 382/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 2; 383/469 \tMinibatch Loss 0.070  Accuracy 98%\n",
      "Iteration 2; 384/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 2; 385/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 2; 386/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 2; 387/469 \tMinibatch Loss 0.013  Accuracy 99%\n",
      "Iteration 2; 388/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 2; 389/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 2; 390/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 2; 391/469 \tMinibatch Loss 0.038  Accuracy 99%\n",
      "Iteration 2; 392/469 \tMinibatch Loss 0.108  Accuracy 97%\n",
      "Iteration 2; 393/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 2; 394/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 2; 395/469 \tMinibatch Loss 0.003  Accuracy 100%\n",
      "Iteration 2; 396/469 \tMinibatch Loss 0.057  Accuracy 97%\n",
      "Iteration 2; 397/469 \tMinibatch Loss 0.028  Accuracy 98%\n",
      "Iteration 2; 398/469 \tMinibatch Loss 0.071  Accuracy 98%\n",
      "Iteration 2; 399/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 2; 400/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 2; 401/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 2; 402/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 2; 403/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 2; 404/469 \tMinibatch Loss 0.037  Accuracy 99%\n",
      "Iteration 2; 405/469 \tMinibatch Loss 0.051  Accuracy 99%\n",
      "Iteration 2; 406/469 \tMinibatch Loss 0.024  Accuracy 100%\n",
      "Iteration 2; 407/469 \tMinibatch Loss 0.058  Accuracy 99%\n",
      "Iteration 2; 408/469 \tMinibatch Loss 0.044  Accuracy 97%\n",
      "Iteration 2; 409/469 \tMinibatch Loss 0.037  Accuracy 98%\n",
      "Iteration 2; 410/469 \tMinibatch Loss 0.041  Accuracy 99%\n",
      "Iteration 2; 411/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 2; 412/469 \tMinibatch Loss 0.060  Accuracy 97%\n",
      "Iteration 2; 413/469 \tMinibatch Loss 0.022  Accuracy 98%\n",
      "Iteration 2; 414/469 \tMinibatch Loss 0.077  Accuracy 98%\n",
      "Iteration 2; 415/469 \tMinibatch Loss 0.037  Accuracy 99%\n",
      "Iteration 2; 416/469 \tMinibatch Loss 0.080  Accuracy 99%\n",
      "Iteration 2; 417/469 \tMinibatch Loss 0.132  Accuracy 97%\n",
      "Iteration 2; 418/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 2; 419/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 2; 420/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 2; 421/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 2; 422/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 2; 423/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 2; 424/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 2; 425/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 2; 426/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 2; 427/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 2; 428/469 \tMinibatch Loss 0.033  Accuracy 99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2; 429/469 \tMinibatch Loss 0.078  Accuracy 97%\n",
      "Iteration 2; 430/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 2; 431/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 2; 432/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 2; 433/469 \tMinibatch Loss 0.079  Accuracy 98%\n",
      "Iteration 2; 434/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 2; 435/469 \tMinibatch Loss 0.146  Accuracy 95%\n",
      "Iteration 2; 436/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 2; 437/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 2; 438/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 2; 439/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 2; 440/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 2; 441/469 \tMinibatch Loss 0.088  Accuracy 97%\n",
      "Iteration 2; 442/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 2; 443/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 2; 444/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 2; 445/469 \tMinibatch Loss 0.096  Accuracy 95%\n",
      "Iteration 2; 446/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 2; 447/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 2; 448/469 \tMinibatch Loss 0.064  Accuracy 99%\n",
      "Iteration 2; 449/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 2; 450/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 2; 451/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 2; 452/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 2; 453/469 \tMinibatch Loss 0.039  Accuracy 99%\n",
      "Iteration 2; 454/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 2; 455/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 2; 456/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 2; 457/469 \tMinibatch Loss 0.040  Accuracy 99%\n",
      "Iteration 2; 458/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 2; 459/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 2; 460/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 2; 461/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 2; 462/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 2; 463/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 2; 464/469 \tMinibatch Loss 0.025  Accuracy 98%\n",
      "Iteration 2; 465/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 2; 466/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 2; 467/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 2; 468/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 3; 0/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 3; 1/469 \tMinibatch Loss 0.018  Accuracy 98%\n",
      "Iteration 3; 2/469 \tMinibatch Loss 0.061  Accuracy 98%\n",
      "Iteration 3; 3/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 3; 4/469 \tMinibatch Loss 0.023  Accuracy 98%\n",
      "Iteration 3; 5/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 3; 6/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 3; 7/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 3; 8/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 3; 9/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 3; 10/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 3; 11/469 \tMinibatch Loss 0.043  Accuracy 98%\n",
      "Iteration 3; 12/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 3; 13/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 3; 14/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 3; 15/469 \tMinibatch Loss 0.045  Accuracy 99%\n",
      "Iteration 3; 16/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 3; 17/469 \tMinibatch Loss 0.003  Accuracy 100%\n",
      "Iteration 3; 18/469 \tMinibatch Loss 0.071  Accuracy 97%\n",
      "Iteration 3; 19/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 3; 20/469 \tMinibatch Loss 0.038  Accuracy 99%\n",
      "Iteration 3; 21/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 3; 22/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 3; 23/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 3; 24/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 3; 25/469 \tMinibatch Loss 0.059  Accuracy 97%\n",
      "Iteration 3; 26/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 3; 27/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 3; 28/469 \tMinibatch Loss 0.089  Accuracy 98%\n",
      "Iteration 3; 29/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 3; 30/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 3; 31/469 \tMinibatch Loss 0.043  Accuracy 99%\n",
      "Iteration 3; 32/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 3; 33/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 3; 34/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 3; 35/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 3; 36/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 3; 37/469 \tMinibatch Loss 0.068  Accuracy 96%\n",
      "Iteration 3; 38/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 3; 39/469 \tMinibatch Loss 0.076  Accuracy 97%\n",
      "Iteration 3; 40/469 \tMinibatch Loss 0.020  Accuracy 98%\n",
      "Iteration 3; 41/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 3; 42/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 3; 43/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 3; 44/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 3; 45/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 3; 46/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 3; 47/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 3; 48/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 3; 49/469 \tMinibatch Loss 0.076  Accuracy 98%\n",
      "Iteration 3; 50/469 \tMinibatch Loss 0.023  Accuracy 100%\n",
      "Iteration 3; 51/469 \tMinibatch Loss 0.040  Accuracy 99%\n",
      "Iteration 3; 52/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 3; 53/469 \tMinibatch Loss 0.085  Accuracy 98%\n",
      "Iteration 3; 54/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 3; 55/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 3; 56/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 3; 57/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 3; 58/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 3; 59/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 3; 60/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 3; 61/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 3; 62/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 3; 63/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 3; 64/469 \tMinibatch Loss 0.043  Accuracy 97%\n",
      "Iteration 3; 65/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 3; 66/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 3; 67/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 3; 68/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 3; 69/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 3; 70/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 3; 71/469 \tMinibatch Loss 0.071  Accuracy 99%\n",
      "Iteration 3; 72/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 3; 73/469 \tMinibatch Loss 0.021  Accuracy 100%\n",
      "Iteration 3; 74/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 3; 75/469 \tMinibatch Loss 0.098  Accuracy 98%\n",
      "Iteration 3; 76/469 \tMinibatch Loss 0.020  Accuracy 100%\n",
      "Iteration 3; 77/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 3; 78/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 3; 79/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 3; 80/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 3; 81/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 3; 82/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 3; 83/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 3; 84/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 3; 85/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 3; 86/469 \tMinibatch Loss 0.174  Accuracy 98%\n",
      "Iteration 3; 87/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 3; 88/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 3; 89/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 3; 90/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 3; 91/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 3; 92/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 3; 93/469 \tMinibatch Loss 0.053  Accuracy 99%\n",
      "Iteration 3; 94/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 3; 95/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 3; 96/469 \tMinibatch Loss 0.059  Accuracy 98%\n",
      "Iteration 3; 97/469 \tMinibatch Loss 0.060  Accuracy 96%\n",
      "Iteration 3; 98/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 3; 99/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 3; 100/469 \tMinibatch Loss 0.070  Accuracy 98%\n",
      "Iteration 3; 101/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 3; 102/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 3; 103/469 \tMinibatch Loss 0.077  Accuracy 98%\n",
      "Iteration 3; 104/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 3; 105/469 \tMinibatch Loss 0.053  Accuracy 99%\n",
      "Iteration 3; 106/469 \tMinibatch Loss 0.026  Accuracy 98%\n",
      "Iteration 3; 107/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 3; 108/469 \tMinibatch Loss 0.037  Accuracy 98%\n",
      "Iteration 3; 109/469 \tMinibatch Loss 0.080  Accuracy 99%\n",
      "Iteration 3; 110/469 \tMinibatch Loss 0.059  Accuracy 98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3; 111/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 3; 112/469 \tMinibatch Loss 0.021  Accuracy 98%\n",
      "Iteration 3; 113/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 3; 114/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 3; 115/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 3; 116/469 \tMinibatch Loss 0.027  Accuracy 98%\n",
      "Iteration 3; 117/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 3; 118/469 \tMinibatch Loss 0.067  Accuracy 98%\n",
      "Iteration 3; 119/469 \tMinibatch Loss 0.043  Accuracy 98%\n",
      "Iteration 3; 120/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 3; 121/469 \tMinibatch Loss 0.041  Accuracy 99%\n",
      "Iteration 3; 122/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 3; 123/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 3; 124/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 3; 125/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 3; 126/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 3; 127/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 3; 128/469 \tMinibatch Loss 0.020  Accuracy 100%\n",
      "Iteration 3; 129/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 3; 130/469 \tMinibatch Loss 0.068  Accuracy 98%\n",
      "Iteration 3; 131/469 \tMinibatch Loss 0.071  Accuracy 98%\n",
      "Iteration 3; 132/469 \tMinibatch Loss 0.050  Accuracy 97%\n",
      "Iteration 3; 133/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 3; 134/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 3; 135/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 3; 136/469 \tMinibatch Loss 0.027  Accuracy 98%\n",
      "Iteration 3; 137/469 \tMinibatch Loss 0.069  Accuracy 97%\n",
      "Iteration 3; 138/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 3; 139/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 3; 140/469 \tMinibatch Loss 0.083  Accuracy 98%\n",
      "Iteration 3; 141/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 3; 142/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 3; 143/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 3; 144/469 \tMinibatch Loss 0.023  Accuracy 100%\n",
      "Iteration 3; 145/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 3; 146/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 3; 147/469 \tMinibatch Loss 0.035  Accuracy 98%\n",
      "Iteration 3; 148/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 3; 149/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 3; 150/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 3; 151/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 3; 152/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 3; 153/469 \tMinibatch Loss 0.026  Accuracy 98%\n",
      "Iteration 3; 154/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 3; 155/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 3; 156/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 3; 157/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 3; 158/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 3; 159/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 3; 160/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 3; 161/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 3; 162/469 \tMinibatch Loss 0.012  Accuracy 99%\n",
      "Iteration 3; 163/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 3; 164/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 3; 165/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 3; 166/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 3; 167/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 3; 168/469 \tMinibatch Loss 0.022  Accuracy 98%\n",
      "Iteration 3; 169/469 \tMinibatch Loss 0.020  Accuracy 100%\n",
      "Iteration 3; 170/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 3; 171/469 \tMinibatch Loss 0.013  Accuracy 99%\n",
      "Iteration 3; 172/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 3; 173/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 3; 174/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 3; 175/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 3; 176/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 3; 177/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 3; 178/469 \tMinibatch Loss 0.012  Accuracy 99%\n",
      "Iteration 3; 179/469 \tMinibatch Loss 0.052  Accuracy 99%\n",
      "Iteration 3; 180/469 \tMinibatch Loss 0.020  Accuracy 100%\n",
      "Iteration 3; 181/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 3; 182/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 3; 183/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 3; 184/469 \tMinibatch Loss 0.003  Accuracy 100%\n",
      "Iteration 3; 185/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 3; 186/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 3; 187/469 \tMinibatch Loss 0.042  Accuracy 99%\n",
      "Iteration 3; 188/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 3; 189/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 3; 190/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 3; 191/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 3; 192/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 3; 193/469 \tMinibatch Loss 0.037  Accuracy 98%\n",
      "Iteration 3; 194/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 3; 195/469 \tMinibatch Loss 0.170  Accuracy 95%\n",
      "Iteration 3; 196/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 3; 197/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 3; 198/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 3; 199/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 3; 200/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 3; 201/469 \tMinibatch Loss 0.071  Accuracy 98%\n",
      "Iteration 3; 202/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 3; 203/469 \tMinibatch Loss 0.081  Accuracy 98%\n",
      "Iteration 3; 204/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 3; 205/469 \tMinibatch Loss 0.011  Accuracy 99%\n",
      "Iteration 3; 206/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 3; 207/469 \tMinibatch Loss 0.078  Accuracy 97%\n",
      "Iteration 3; 208/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 3; 209/469 \tMinibatch Loss 0.028  Accuracy 98%\n",
      "Iteration 3; 210/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 3; 211/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 3; 212/469 \tMinibatch Loss 0.012  Accuracy 99%\n",
      "Iteration 3; 213/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 3; 214/469 \tMinibatch Loss 0.058  Accuracy 97%\n",
      "Iteration 3; 215/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 3; 216/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 3; 217/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 3; 218/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 3; 219/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 3; 220/469 \tMinibatch Loss 0.092  Accuracy 98%\n",
      "Iteration 3; 221/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 3; 222/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 3; 223/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 3; 224/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 3; 225/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 3; 226/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 3; 227/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 3; 228/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 3; 229/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 3; 230/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 3; 231/469 \tMinibatch Loss 0.074  Accuracy 99%\n",
      "Iteration 3; 232/469 \tMinibatch Loss 0.083  Accuracy 97%\n",
      "Iteration 3; 233/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 3; 234/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 3; 235/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 3; 236/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 3; 237/469 \tMinibatch Loss 0.037  Accuracy 98%\n",
      "Iteration 3; 238/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 3; 239/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 3; 240/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 3; 241/469 \tMinibatch Loss 0.050  Accuracy 99%\n",
      "Iteration 3; 242/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 3; 243/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 3; 244/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 3; 245/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 3; 246/469 \tMinibatch Loss 0.061  Accuracy 98%\n",
      "Iteration 3; 247/469 \tMinibatch Loss 0.072  Accuracy 99%\n",
      "Iteration 3; 248/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 3; 249/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 3; 250/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 3; 251/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 3; 252/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 3; 253/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 3; 254/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 3; 255/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 3; 256/469 \tMinibatch Loss 0.043  Accuracy 98%\n",
      "Iteration 3; 257/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 3; 258/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 3; 259/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 3; 260/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 3; 261/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 3; 262/469 \tMinibatch Loss 0.077  Accuracy 98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3; 263/469 \tMinibatch Loss 0.043  Accuracy 98%\n",
      "Iteration 3; 264/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 3; 265/469 \tMinibatch Loss 0.100  Accuracy 95%\n",
      "Iteration 3; 266/469 \tMinibatch Loss 0.020  Accuracy 100%\n",
      "Iteration 3; 267/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 3; 268/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 3; 269/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 3; 270/469 \tMinibatch Loss 0.022  Accuracy 98%\n",
      "Iteration 3; 271/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 3; 272/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 3; 273/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 3; 274/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 3; 275/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 3; 276/469 \tMinibatch Loss 0.025  Accuracy 98%\n",
      "Iteration 3; 277/469 \tMinibatch Loss 0.101  Accuracy 96%\n",
      "Iteration 3; 278/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 3; 279/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 3; 280/469 \tMinibatch Loss 0.062  Accuracy 97%\n",
      "Iteration 3; 281/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 3; 282/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 3; 283/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 3; 284/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 3; 285/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 3; 286/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 3; 287/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 3; 288/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 3; 289/469 \tMinibatch Loss 0.003  Accuracy 100%\n",
      "Iteration 3; 290/469 \tMinibatch Loss 0.071  Accuracy 97%\n",
      "Iteration 3; 291/469 \tMinibatch Loss 0.089  Accuracy 98%\n",
      "Iteration 3; 292/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 3; 293/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 3; 294/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 3; 295/469 \tMinibatch Loss 0.022  Accuracy 98%\n",
      "Iteration 3; 296/469 \tMinibatch Loss 0.082  Accuracy 98%\n",
      "Iteration 3; 297/469 \tMinibatch Loss 0.074  Accuracy 98%\n",
      "Iteration 3; 298/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 3; 299/469 \tMinibatch Loss 0.048  Accuracy 99%\n",
      "Iteration 3; 300/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 3; 301/469 \tMinibatch Loss 0.063  Accuracy 98%\n",
      "Iteration 3; 302/469 \tMinibatch Loss 0.025  Accuracy 98%\n",
      "Iteration 3; 303/469 \tMinibatch Loss 0.059  Accuracy 98%\n",
      "Iteration 3; 304/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 3; 305/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 3; 306/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 3; 307/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 3; 308/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 3; 309/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 3; 310/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 3; 311/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 3; 312/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 3; 313/469 \tMinibatch Loss 0.046  Accuracy 99%\n",
      "Iteration 3; 314/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 3; 315/469 \tMinibatch Loss 0.045  Accuracy 99%\n",
      "Iteration 3; 316/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 3; 317/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 3; 318/469 \tMinibatch Loss 0.084  Accuracy 98%\n",
      "Iteration 3; 319/469 \tMinibatch Loss 0.052  Accuracy 97%\n",
      "Iteration 3; 320/469 \tMinibatch Loss 0.071  Accuracy 98%\n",
      "Iteration 3; 321/469 \tMinibatch Loss 0.065  Accuracy 97%\n",
      "Iteration 3; 322/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 3; 323/469 \tMinibatch Loss 0.036  Accuracy 98%\n",
      "Iteration 3; 324/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 3; 325/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 3; 326/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 3; 327/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 3; 328/469 \tMinibatch Loss 0.017  Accuracy 100%\n",
      "Iteration 3; 329/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 3; 330/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 3; 331/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 3; 332/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 3; 333/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 3; 334/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 3; 335/469 \tMinibatch Loss 0.072  Accuracy 98%\n",
      "Iteration 3; 336/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 3; 337/469 \tMinibatch Loss 0.043  Accuracy 98%\n",
      "Iteration 3; 338/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 3; 339/469 \tMinibatch Loss 0.069  Accuracy 97%\n",
      "Iteration 3; 340/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 3; 341/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 3; 342/469 \tMinibatch Loss 0.020  Accuracy 100%\n",
      "Iteration 3; 343/469 \tMinibatch Loss 0.024  Accuracy 98%\n",
      "Iteration 3; 344/469 \tMinibatch Loss 0.013  Accuracy 99%\n",
      "Iteration 3; 345/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 3; 346/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 3; 347/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 3; 348/469 \tMinibatch Loss 0.079  Accuracy 98%\n",
      "Iteration 3; 349/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 3; 350/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 3; 351/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 3; 352/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 3; 353/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 3; 354/469 \tMinibatch Loss 0.047  Accuracy 99%\n",
      "Iteration 3; 355/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 3; 356/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 3; 357/469 \tMinibatch Loss 0.051  Accuracy 99%\n",
      "Iteration 3; 358/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 3; 359/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 3; 360/469 \tMinibatch Loss 0.002  Accuracy 100%\n",
      "Iteration 3; 361/469 \tMinibatch Loss 0.089  Accuracy 97%\n",
      "Iteration 3; 362/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 3; 363/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 3; 364/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 3; 365/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 3; 366/469 \tMinibatch Loss 0.092  Accuracy 98%\n",
      "Iteration 3; 367/469 \tMinibatch Loss 0.038  Accuracy 99%\n",
      "Iteration 3; 368/469 \tMinibatch Loss 0.097  Accuracy 98%\n",
      "Iteration 3; 369/469 \tMinibatch Loss 0.079  Accuracy 97%\n",
      "Iteration 3; 370/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 3; 371/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 3; 372/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 3; 373/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 3; 374/469 \tMinibatch Loss 0.083  Accuracy 97%\n",
      "Iteration 3; 375/469 \tMinibatch Loss 0.099  Accuracy 96%\n",
      "Iteration 3; 376/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 3; 377/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 3; 378/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 3; 379/469 \tMinibatch Loss 0.062  Accuracy 97%\n",
      "Iteration 3; 380/469 \tMinibatch Loss 0.096  Accuracy 98%\n",
      "Iteration 3; 381/469 \tMinibatch Loss 0.021  Accuracy 100%\n",
      "Iteration 3; 382/469 \tMinibatch Loss 0.096  Accuracy 98%\n",
      "Iteration 3; 383/469 \tMinibatch Loss 0.058  Accuracy 98%\n",
      "Iteration 3; 384/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 3; 385/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 3; 386/469 \tMinibatch Loss 0.063  Accuracy 98%\n",
      "Iteration 3; 387/469 \tMinibatch Loss 0.057  Accuracy 99%\n",
      "Iteration 3; 388/469 \tMinibatch Loss 0.128  Accuracy 98%\n",
      "Iteration 3; 389/469 \tMinibatch Loss 0.040  Accuracy 99%\n",
      "Iteration 3; 390/469 \tMinibatch Loss 0.061  Accuracy 98%\n",
      "Iteration 3; 391/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 3; 392/469 \tMinibatch Loss 0.021  Accuracy 100%\n",
      "Iteration 3; 393/469 \tMinibatch Loss 0.075  Accuracy 96%\n",
      "Iteration 3; 394/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 3; 395/469 \tMinibatch Loss 0.090  Accuracy 96%\n",
      "Iteration 3; 396/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 3; 397/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 3; 398/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 3; 399/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 3; 400/469 \tMinibatch Loss 0.091  Accuracy 96%\n",
      "Iteration 3; 401/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 3; 402/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 3; 403/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 3; 404/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 3; 405/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 3; 406/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 3; 407/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 3; 408/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 3; 409/469 \tMinibatch Loss 0.086  Accuracy 98%\n",
      "Iteration 3; 410/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 3; 411/469 \tMinibatch Loss 0.058  Accuracy 98%\n",
      "Iteration 3; 412/469 \tMinibatch Loss 0.075  Accuracy 98%\n",
      "Iteration 3; 413/469 \tMinibatch Loss 0.067  Accuracy 97%\n",
      "Iteration 3; 414/469 \tMinibatch Loss 0.057  Accuracy 98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3; 415/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 3; 416/469 \tMinibatch Loss 0.075  Accuracy 98%\n",
      "Iteration 3; 417/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 3; 418/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 3; 419/469 \tMinibatch Loss 0.038  Accuracy 99%\n",
      "Iteration 3; 420/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 3; 421/469 \tMinibatch Loss 0.042  Accuracy 99%\n",
      "Iteration 3; 422/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 3; 423/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 3; 424/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 3; 425/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 3; 426/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 3; 427/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 3; 428/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 3; 429/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 3; 430/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 3; 431/469 \tMinibatch Loss 0.085  Accuracy 95%\n",
      "Iteration 3; 432/469 \tMinibatch Loss 0.023  Accuracy 100%\n",
      "Iteration 3; 433/469 \tMinibatch Loss 0.027  Accuracy 98%\n",
      "Iteration 3; 434/469 \tMinibatch Loss 0.043  Accuracy 99%\n",
      "Iteration 3; 435/469 \tMinibatch Loss 0.071  Accuracy 97%\n",
      "Iteration 3; 436/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 3; 437/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 3; 438/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 3; 439/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 3; 440/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 3; 441/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 3; 442/469 \tMinibatch Loss 0.027  Accuracy 98%\n",
      "Iteration 3; 443/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 3; 444/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 3; 445/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 3; 446/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 3; 447/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 3; 448/469 \tMinibatch Loss 0.047  Accuracy 99%\n",
      "Iteration 3; 449/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 3; 450/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 3; 451/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 3; 452/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 3; 453/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 3; 454/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 3; 455/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 3; 456/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 3; 457/469 \tMinibatch Loss 0.065  Accuracy 97%\n",
      "Iteration 3; 458/469 \tMinibatch Loss 0.048  Accuracy 99%\n",
      "Iteration 3; 459/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 3; 460/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 3; 461/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 3; 462/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 3; 463/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 3; 464/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 3; 465/469 \tMinibatch Loss 0.046  Accuracy 99%\n",
      "Iteration 3; 466/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 3; 467/469 \tMinibatch Loss 0.083  Accuracy 98%\n",
      "Iteration 3; 468/469 \tMinibatch Loss 0.061  Accuracy 98%\n",
      "Iteration 4; 0/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 4; 1/469 \tMinibatch Loss 0.026  Accuracy 98%\n",
      "Iteration 4; 2/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 4; 3/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 4; 4/469 \tMinibatch Loss 0.058  Accuracy 97%\n",
      "Iteration 4; 5/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 4; 6/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 4; 7/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 4; 8/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 4; 9/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 4; 10/469 \tMinibatch Loss 0.080  Accuracy 98%\n",
      "Iteration 4; 11/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 4; 12/469 \tMinibatch Loss 0.071  Accuracy 98%\n",
      "Iteration 4; 13/469 \tMinibatch Loss 0.048  Accuracy 99%\n",
      "Iteration 4; 14/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 4; 15/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 4; 16/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 4; 17/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 4; 18/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 4; 19/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 4; 20/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 4; 21/469 \tMinibatch Loss 0.041  Accuracy 99%\n",
      "Iteration 4; 22/469 \tMinibatch Loss 0.025  Accuracy 98%\n",
      "Iteration 4; 23/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 4; 24/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 4; 25/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 4; 26/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 4; 27/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 4; 28/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 4; 29/469 \tMinibatch Loss 0.017  Accuracy 100%\n",
      "Iteration 4; 30/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 4; 31/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 4; 32/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 4; 33/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 4; 34/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 4; 35/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 4; 36/469 \tMinibatch Loss 0.010  Accuracy 99%\n",
      "Iteration 4; 37/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 4; 38/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 4; 39/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 4; 40/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 4; 41/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 4; 42/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 4; 43/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 4; 44/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 4; 45/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 4; 46/469 \tMinibatch Loss 0.024  Accuracy 98%\n",
      "Iteration 4; 47/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 4; 48/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 4; 49/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 4; 50/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 4; 51/469 \tMinibatch Loss 0.036  Accuracy 98%\n",
      "Iteration 4; 52/469 \tMinibatch Loss 0.059  Accuracy 98%\n",
      "Iteration 4; 53/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 4; 54/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 4; 55/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 4; 56/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 4; 57/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 4; 58/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 4; 59/469 \tMinibatch Loss 0.013  Accuracy 99%\n",
      "Iteration 4; 60/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 4; 61/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 4; 62/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 4; 63/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 4; 64/469 \tMinibatch Loss 0.037  Accuracy 99%\n",
      "Iteration 4; 65/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 4; 66/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 4; 67/469 \tMinibatch Loss 0.097  Accuracy 95%\n",
      "Iteration 4; 68/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 4; 69/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 4; 70/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 4; 71/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 4; 72/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 4; 73/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 4; 74/469 \tMinibatch Loss 0.043  Accuracy 98%\n",
      "Iteration 4; 75/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 4; 76/469 \tMinibatch Loss 0.023  Accuracy 98%\n",
      "Iteration 4; 77/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 4; 78/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 4; 79/469 \tMinibatch Loss 0.071  Accuracy 98%\n",
      "Iteration 4; 80/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 4; 81/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 4; 82/469 \tMinibatch Loss 0.058  Accuracy 97%\n",
      "Iteration 4; 83/469 \tMinibatch Loss 0.020  Accuracy 98%\n",
      "Iteration 4; 84/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 4; 85/469 \tMinibatch Loss 0.037  Accuracy 98%\n",
      "Iteration 4; 86/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 4; 87/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 4; 88/469 \tMinibatch Loss 0.028  Accuracy 98%\n",
      "Iteration 4; 89/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 4; 90/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 4; 91/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 4; 92/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 4; 93/469 \tMinibatch Loss 0.068  Accuracy 98%\n",
      "Iteration 4; 94/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 4; 95/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 4; 96/469 \tMinibatch Loss 0.085  Accuracy 97%\n",
      "Iteration 4; 97/469 \tMinibatch Loss 0.008  Accuracy 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4; 98/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 4; 99/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 4; 100/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 4; 101/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 4; 102/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 4; 103/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 4; 104/469 \tMinibatch Loss 0.035  Accuracy 98%\n",
      "Iteration 4; 105/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 4; 106/469 \tMinibatch Loss 0.012  Accuracy 99%\n",
      "Iteration 4; 107/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 4; 108/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 4; 109/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 4; 110/469 \tMinibatch Loss 0.023  Accuracy 98%\n",
      "Iteration 4; 111/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 4; 112/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 4; 113/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 4; 114/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 4; 115/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 4; 116/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 4; 117/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 4; 118/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 4; 119/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 4; 120/469 \tMinibatch Loss 0.002  Accuracy 100%\n",
      "Iteration 4; 121/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 4; 122/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 4; 123/469 \tMinibatch Loss 0.072  Accuracy 97%\n",
      "Iteration 4; 124/469 \tMinibatch Loss 0.058  Accuracy 99%\n",
      "Iteration 4; 125/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 4; 126/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 4; 127/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 4; 128/469 \tMinibatch Loss 0.010  Accuracy 99%\n",
      "Iteration 4; 129/469 \tMinibatch Loss 0.048  Accuracy 99%\n",
      "Iteration 4; 130/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 4; 131/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 4; 132/469 \tMinibatch Loss 0.068  Accuracy 98%\n",
      "Iteration 4; 133/469 \tMinibatch Loss 0.019  Accuracy 100%\n",
      "Iteration 4; 134/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 4; 135/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 4; 136/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 4; 137/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 4; 138/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 4; 139/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 4; 140/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 4; 141/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 4; 142/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 4; 143/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 4; 144/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 4; 145/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 4; 146/469 \tMinibatch Loss 0.089  Accuracy 98%\n",
      "Iteration 4; 147/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 4; 148/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 4; 149/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 4; 150/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 4; 151/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 4; 152/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 4; 153/469 \tMinibatch Loss 0.059  Accuracy 98%\n",
      "Iteration 4; 154/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 4; 155/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 4; 156/469 \tMinibatch Loss 0.019  Accuracy 100%\n",
      "Iteration 4; 157/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 4; 158/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 4; 159/469 \tMinibatch Loss 0.023  Accuracy 98%\n",
      "Iteration 4; 160/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 4; 161/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 4; 162/469 \tMinibatch Loss 0.018  Accuracy 98%\n",
      "Iteration 4; 163/469 \tMinibatch Loss 0.092  Accuracy 98%\n",
      "Iteration 4; 164/469 \tMinibatch Loss 0.020  Accuracy 98%\n",
      "Iteration 4; 165/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 4; 166/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 4; 167/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 4; 168/469 \tMinibatch Loss 0.070  Accuracy 98%\n",
      "Iteration 4; 169/469 \tMinibatch Loss 0.040  Accuracy 99%\n",
      "Iteration 4; 170/469 \tMinibatch Loss 0.121  Accuracy 95%\n",
      "Iteration 4; 171/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 4; 172/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 4; 173/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 4; 174/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 4; 175/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 4; 176/469 \tMinibatch Loss 0.127  Accuracy 96%\n",
      "Iteration 4; 177/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 4; 178/469 \tMinibatch Loss 0.017  Accuracy 100%\n",
      "Iteration 4; 179/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 4; 180/469 \tMinibatch Loss 0.083  Accuracy 99%\n",
      "Iteration 4; 181/469 \tMinibatch Loss 0.035  Accuracy 98%\n",
      "Iteration 4; 182/469 \tMinibatch Loss 0.055  Accuracy 99%\n",
      "Iteration 4; 183/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 4; 184/469 \tMinibatch Loss 0.012  Accuracy 99%\n",
      "Iteration 4; 185/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 4; 186/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 4; 187/469 \tMinibatch Loss 0.019  Accuracy 100%\n",
      "Iteration 4; 188/469 \tMinibatch Loss 0.039  Accuracy 99%\n",
      "Iteration 4; 189/469 \tMinibatch Loss 0.028  Accuracy 98%\n",
      "Iteration 4; 190/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 4; 191/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 4; 192/469 \tMinibatch Loss 0.057  Accuracy 97%\n",
      "Iteration 4; 193/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 4; 194/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 4; 195/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 4; 196/469 \tMinibatch Loss 0.069  Accuracy 99%\n",
      "Iteration 4; 197/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 4; 198/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 4; 199/469 \tMinibatch Loss 0.026  Accuracy 98%\n",
      "Iteration 4; 200/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 4; 201/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 4; 202/469 \tMinibatch Loss 0.043  Accuracy 99%\n",
      "Iteration 4; 203/469 \tMinibatch Loss 0.039  Accuracy 99%\n",
      "Iteration 4; 204/469 \tMinibatch Loss 0.026  Accuracy 98%\n",
      "Iteration 4; 205/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 4; 206/469 \tMinibatch Loss 0.078  Accuracy 98%\n",
      "Iteration 4; 207/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 4; 208/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 4; 209/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 4; 210/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 4; 211/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 4; 212/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 4; 213/469 \tMinibatch Loss 0.026  Accuracy 100%\n",
      "Iteration 4; 214/469 \tMinibatch Loss 0.067  Accuracy 97%\n",
      "Iteration 4; 215/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 4; 216/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 4; 217/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 4; 218/469 \tMinibatch Loss 0.003  Accuracy 100%\n",
      "Iteration 4; 219/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 4; 220/469 \tMinibatch Loss 0.078  Accuracy 98%\n",
      "Iteration 4; 221/469 \tMinibatch Loss 0.009  Accuracy 99%\n",
      "Iteration 4; 222/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 4; 223/469 \tMinibatch Loss 0.041  Accuracy 99%\n",
      "Iteration 4; 224/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 4; 225/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 4; 226/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 4; 227/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 4; 228/469 \tMinibatch Loss 0.027  Accuracy 98%\n",
      "Iteration 4; 229/469 \tMinibatch Loss 0.118  Accuracy 98%\n",
      "Iteration 4; 230/469 \tMinibatch Loss 0.066  Accuracy 97%\n",
      "Iteration 4; 231/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 4; 232/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 4; 233/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 4; 234/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 4; 235/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 4; 236/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 4; 237/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 4; 238/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 4; 239/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 4; 240/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 4; 241/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 4; 242/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 4; 243/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 4; 244/469 \tMinibatch Loss 0.039  Accuracy 99%\n",
      "Iteration 4; 245/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 4; 246/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 4; 247/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 4; 248/469 \tMinibatch Loss 0.037  Accuracy 98%\n",
      "Iteration 4; 249/469 \tMinibatch Loss 0.047  Accuracy 99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4; 250/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 4; 251/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 4; 252/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 4; 253/469 \tMinibatch Loss 0.065  Accuracy 97%\n",
      "Iteration 4; 254/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 4; 255/469 \tMinibatch Loss 0.093  Accuracy 97%\n",
      "Iteration 4; 256/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 4; 257/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 4; 258/469 \tMinibatch Loss 0.089  Accuracy 95%\n",
      "Iteration 4; 259/469 \tMinibatch Loss 0.092  Accuracy 98%\n",
      "Iteration 4; 260/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 4; 261/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 4; 262/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 4; 263/469 \tMinibatch Loss 0.067  Accuracy 98%\n",
      "Iteration 4; 264/469 \tMinibatch Loss 0.010  Accuracy 99%\n",
      "Iteration 4; 265/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 4; 266/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 4; 267/469 \tMinibatch Loss 0.067  Accuracy 96%\n",
      "Iteration 4; 268/469 \tMinibatch Loss 0.035  Accuracy 98%\n",
      "Iteration 4; 269/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 4; 270/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 4; 271/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 4; 272/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 4; 273/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 4; 274/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 4; 275/469 \tMinibatch Loss 0.013  Accuracy 99%\n",
      "Iteration 4; 276/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 4; 277/469 \tMinibatch Loss 0.140  Accuracy 95%\n",
      "Iteration 4; 278/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 4; 279/469 \tMinibatch Loss 0.088  Accuracy 97%\n",
      "Iteration 4; 280/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 4; 281/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 4; 282/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 4; 283/469 \tMinibatch Loss 0.075  Accuracy 99%\n",
      "Iteration 4; 284/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 4; 285/469 \tMinibatch Loss 0.098  Accuracy 98%\n",
      "Iteration 4; 286/469 \tMinibatch Loss 0.020  Accuracy 100%\n",
      "Iteration 4; 287/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 4; 288/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 4; 289/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 4; 290/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 4; 291/469 \tMinibatch Loss 0.047  Accuracy 99%\n",
      "Iteration 4; 292/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 4; 293/469 \tMinibatch Loss 0.028  Accuracy 98%\n",
      "Iteration 4; 294/469 \tMinibatch Loss 0.073  Accuracy 98%\n",
      "Iteration 4; 295/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 4; 296/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 4; 297/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 4; 298/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 4; 299/469 \tMinibatch Loss 0.083  Accuracy 98%\n",
      "Iteration 4; 300/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 4; 301/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 4; 302/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 4; 303/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 4; 304/469 \tMinibatch Loss 0.037  Accuracy 98%\n",
      "Iteration 4; 305/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 4; 306/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 4; 307/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 4; 308/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 4; 309/469 \tMinibatch Loss 0.040  Accuracy 99%\n",
      "Iteration 4; 310/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 4; 311/469 \tMinibatch Loss 0.103  Accuracy 98%\n",
      "Iteration 4; 312/469 \tMinibatch Loss 0.025  Accuracy 100%\n",
      "Iteration 4; 313/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 4; 314/469 \tMinibatch Loss 0.038  Accuracy 99%\n",
      "Iteration 4; 315/469 \tMinibatch Loss 0.009  Accuracy 99%\n",
      "Iteration 4; 316/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 4; 317/469 \tMinibatch Loss 0.028  Accuracy 98%\n",
      "Iteration 4; 318/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 4; 319/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 4; 320/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 4; 321/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 4; 322/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 4; 323/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 4; 324/469 \tMinibatch Loss 0.039  Accuracy 99%\n",
      "Iteration 4; 325/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 4; 326/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 4; 327/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 4; 328/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 4; 329/469 \tMinibatch Loss 0.025  Accuracy 98%\n",
      "Iteration 4; 330/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 4; 331/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 4; 332/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 4; 333/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 4; 334/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 4; 335/469 \tMinibatch Loss 0.017  Accuracy 100%\n",
      "Iteration 4; 336/469 \tMinibatch Loss 0.063  Accuracy 99%\n",
      "Iteration 4; 337/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 4; 338/469 \tMinibatch Loss 0.068  Accuracy 98%\n",
      "Iteration 4; 339/469 \tMinibatch Loss 0.028  Accuracy 98%\n",
      "Iteration 4; 340/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 4; 341/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 4; 342/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 4; 343/469 \tMinibatch Loss 0.043  Accuracy 98%\n",
      "Iteration 4; 344/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 4; 345/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 4; 346/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 4; 347/469 \tMinibatch Loss 0.013  Accuracy 99%\n",
      "Iteration 4; 348/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 4; 349/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 4; 350/469 \tMinibatch Loss 0.003  Accuracy 100%\n",
      "Iteration 4; 351/469 \tMinibatch Loss 0.018  Accuracy 98%\n",
      "Iteration 4; 352/469 \tMinibatch Loss 0.055  Accuracy 97%\n",
      "Iteration 4; 353/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 4; 354/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 4; 355/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 4; 356/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 4; 357/469 \tMinibatch Loss 0.133  Accuracy 97%\n",
      "Iteration 4; 358/469 \tMinibatch Loss 0.085  Accuracy 98%\n",
      "Iteration 4; 359/469 \tMinibatch Loss 0.003  Accuracy 100%\n",
      "Iteration 4; 360/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 4; 361/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 4; 362/469 \tMinibatch Loss 0.012  Accuracy 99%\n",
      "Iteration 4; 363/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 4; 364/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 4; 365/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 4; 366/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 4; 367/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 4; 368/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 4; 369/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 4; 370/469 \tMinibatch Loss 0.002  Accuracy 100%\n",
      "Iteration 4; 371/469 \tMinibatch Loss 0.036  Accuracy 98%\n",
      "Iteration 4; 372/469 \tMinibatch Loss 0.089  Accuracy 98%\n",
      "Iteration 4; 373/469 \tMinibatch Loss 0.078  Accuracy 98%\n",
      "Iteration 4; 374/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 4; 375/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 4; 376/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 4; 377/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 4; 378/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 4; 379/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 4; 380/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 4; 381/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 4; 382/469 \tMinibatch Loss 0.019  Accuracy 98%\n",
      "Iteration 4; 383/469 \tMinibatch Loss 0.037  Accuracy 98%\n",
      "Iteration 4; 384/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 4; 385/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 4; 386/469 \tMinibatch Loss 0.077  Accuracy 98%\n",
      "Iteration 4; 387/469 \tMinibatch Loss 0.021  Accuracy 100%\n",
      "Iteration 4; 388/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 4; 389/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 4; 390/469 \tMinibatch Loss 0.038  Accuracy 99%\n",
      "Iteration 4; 391/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 4; 392/469 \tMinibatch Loss 0.041  Accuracy 99%\n",
      "Iteration 4; 393/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 4; 394/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 4; 395/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 4; 396/469 \tMinibatch Loss 0.109  Accuracy 97%\n",
      "Iteration 4; 397/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 4; 398/469 \tMinibatch Loss 0.067  Accuracy 98%\n",
      "Iteration 4; 399/469 \tMinibatch Loss 0.013  Accuracy 99%\n",
      "Iteration 4; 400/469 \tMinibatch Loss 0.017  Accuracy 100%\n",
      "Iteration 4; 401/469 \tMinibatch Loss 0.007  Accuracy 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4; 402/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 4; 403/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 4; 404/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 4; 405/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 4; 406/469 \tMinibatch Loss 0.028  Accuracy 98%\n",
      "Iteration 4; 407/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 4; 408/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 4; 409/469 \tMinibatch Loss 0.043  Accuracy 99%\n",
      "Iteration 4; 410/469 \tMinibatch Loss 0.067  Accuracy 99%\n",
      "Iteration 4; 411/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 4; 412/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 4; 413/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 4; 414/469 \tMinibatch Loss 0.058  Accuracy 98%\n",
      "Iteration 4; 415/469 \tMinibatch Loss 0.027  Accuracy 98%\n",
      "Iteration 4; 416/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 4; 417/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 4; 418/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 4; 419/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 4; 420/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 4; 421/469 \tMinibatch Loss 0.028  Accuracy 98%\n",
      "Iteration 4; 422/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 4; 423/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 4; 424/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 4; 425/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 4; 426/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 4; 427/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 4; 428/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 4; 429/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 4; 430/469 \tMinibatch Loss 0.076  Accuracy 98%\n",
      "Iteration 4; 431/469 \tMinibatch Loss 0.017  Accuracy 100%\n",
      "Iteration 4; 432/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 4; 433/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 4; 434/469 \tMinibatch Loss 0.076  Accuracy 98%\n",
      "Iteration 4; 435/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 4; 436/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 4; 437/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 4; 438/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 4; 439/469 \tMinibatch Loss 0.067  Accuracy 98%\n",
      "Iteration 4; 440/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 4; 441/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 4; 442/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 4; 443/469 \tMinibatch Loss 0.067  Accuracy 97%\n",
      "Iteration 4; 444/469 \tMinibatch Loss 0.037  Accuracy 99%\n",
      "Iteration 4; 445/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 4; 446/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 4; 447/469 \tMinibatch Loss 0.094  Accuracy 95%\n",
      "Iteration 4; 448/469 \tMinibatch Loss 0.035  Accuracy 98%\n",
      "Iteration 4; 449/469 \tMinibatch Loss 0.088  Accuracy 98%\n",
      "Iteration 4; 450/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 4; 451/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 4; 452/469 \tMinibatch Loss 0.196  Accuracy 98%\n",
      "Iteration 4; 453/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 4; 454/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 4; 455/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 4; 456/469 \tMinibatch Loss 0.098  Accuracy 95%\n",
      "Iteration 4; 457/469 \tMinibatch Loss 0.021  Accuracy 100%\n",
      "Iteration 4; 458/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 4; 459/469 \tMinibatch Loss 0.028  Accuracy 98%\n",
      "Iteration 4; 460/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 4; 461/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 4; 462/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 4; 463/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 4; 464/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 4; 465/469 \tMinibatch Loss 0.021  Accuracy 100%\n",
      "Iteration 4; 466/469 \tMinibatch Loss 0.037  Accuracy 99%\n",
      "Iteration 4; 467/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 4; 468/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 5; 0/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 5; 1/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 5; 2/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 5; 3/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 5; 4/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 5; 5/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 5; 6/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 5; 7/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 5; 8/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 5; 9/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 5; 10/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 5; 11/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 5; 12/469 \tMinibatch Loss 0.059  Accuracy 98%\n",
      "Iteration 5; 13/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 14/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 5; 15/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 5; 16/469 \tMinibatch Loss 0.002  Accuracy 100%\n",
      "Iteration 5; 17/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 5; 18/469 \tMinibatch Loss 0.073  Accuracy 98%\n",
      "Iteration 5; 19/469 \tMinibatch Loss 0.041  Accuracy 97%\n",
      "Iteration 5; 20/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 5; 21/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 5; 22/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 5; 23/469 \tMinibatch Loss 0.008  Accuracy 99%\n",
      "Iteration 5; 24/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 25/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 5; 26/469 \tMinibatch Loss 0.011  Accuracy 99%\n",
      "Iteration 5; 27/469 \tMinibatch Loss 0.019  Accuracy 100%\n",
      "Iteration 5; 28/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 5; 29/469 \tMinibatch Loss 0.045  Accuracy 99%\n",
      "Iteration 5; 30/469 \tMinibatch Loss 0.035  Accuracy 98%\n",
      "Iteration 5; 31/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 5; 32/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 5; 33/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 5; 34/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 35/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 5; 36/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 5; 37/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 5; 38/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 5; 39/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 5; 40/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 5; 41/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 5; 42/469 \tMinibatch Loss 0.039  Accuracy 99%\n",
      "Iteration 5; 43/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 5; 44/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 5; 45/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 5; 46/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 5; 47/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 5; 48/469 \tMinibatch Loss 0.058  Accuracy 97%\n",
      "Iteration 5; 49/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 5; 50/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 5; 51/469 \tMinibatch Loss 0.048  Accuracy 99%\n",
      "Iteration 5; 52/469 \tMinibatch Loss 0.048  Accuracy 99%\n",
      "Iteration 5; 53/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 5; 54/469 \tMinibatch Loss 0.056  Accuracy 99%\n",
      "Iteration 5; 55/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 5; 56/469 \tMinibatch Loss 0.035  Accuracy 98%\n",
      "Iteration 5; 57/469 \tMinibatch Loss 0.028  Accuracy 98%\n",
      "Iteration 5; 58/469 \tMinibatch Loss 0.017  Accuracy 100%\n",
      "Iteration 5; 59/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 60/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 61/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 5; 62/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 5; 63/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 5; 64/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 5; 65/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 66/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 5; 67/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 5; 68/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 5; 69/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 5; 70/469 \tMinibatch Loss 0.016  Accuracy 98%\n",
      "Iteration 5; 71/469 \tMinibatch Loss 0.077  Accuracy 97%\n",
      "Iteration 5; 72/469 \tMinibatch Loss 0.008  Accuracy 99%\n",
      "Iteration 5; 73/469 \tMinibatch Loss 0.051  Accuracy 99%\n",
      "Iteration 5; 74/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 5; 75/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 5; 76/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 5; 77/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 5; 78/469 \tMinibatch Loss 0.007  Accuracy 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5; 79/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 5; 80/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 5; 81/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 5; 82/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 5; 83/469 \tMinibatch Loss 0.075  Accuracy 98%\n",
      "Iteration 5; 84/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 5; 85/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 86/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 5; 87/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 5; 88/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 5; 89/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 5; 90/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 5; 91/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 5; 92/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 5; 93/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 5; 94/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 5; 95/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 5; 96/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 5; 97/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 5; 98/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 5; 99/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 5; 100/469 \tMinibatch Loss 0.036  Accuracy 98%\n",
      "Iteration 5; 101/469 \tMinibatch Loss 0.090  Accuracy 98%\n",
      "Iteration 5; 102/469 \tMinibatch Loss 0.113  Accuracy 97%\n",
      "Iteration 5; 103/469 \tMinibatch Loss 0.017  Accuracy 100%\n",
      "Iteration 5; 104/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 5; 105/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 5; 106/469 \tMinibatch Loss 0.017  Accuracy 100%\n",
      "Iteration 5; 107/469 \tMinibatch Loss 0.070  Accuracy 98%\n",
      "Iteration 5; 108/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 5; 109/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 5; 110/469 \tMinibatch Loss 0.068  Accuracy 97%\n",
      "Iteration 5; 111/469 \tMinibatch Loss 0.038  Accuracy 99%\n",
      "Iteration 5; 112/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 113/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 5; 114/469 \tMinibatch Loss 0.019  Accuracy 100%\n",
      "Iteration 5; 115/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 5; 116/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 117/469 \tMinibatch Loss 0.043  Accuracy 99%\n",
      "Iteration 5; 118/469 \tMinibatch Loss 0.042  Accuracy 99%\n",
      "Iteration 5; 119/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 5; 120/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 5; 121/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 5; 122/469 \tMinibatch Loss 0.027  Accuracy 98%\n",
      "Iteration 5; 123/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 124/469 \tMinibatch Loss 0.037  Accuracy 99%\n",
      "Iteration 5; 125/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 5; 126/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 5; 127/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 5; 128/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 5; 129/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 5; 130/469 \tMinibatch Loss 0.057  Accuracy 98%\n",
      "Iteration 5; 131/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 132/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 5; 133/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 5; 134/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 5; 135/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 5; 136/469 \tMinibatch Loss 0.101  Accuracy 96%\n",
      "Iteration 5; 137/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 5; 138/469 \tMinibatch Loss 0.012  Accuracy 99%\n",
      "Iteration 5; 139/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 140/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 5; 141/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 5; 142/469 \tMinibatch Loss 0.036  Accuracy 98%\n",
      "Iteration 5; 143/469 \tMinibatch Loss 0.077  Accuracy 98%\n",
      "Iteration 5; 144/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 5; 145/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 5; 146/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 5; 147/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 5; 148/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 149/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 5; 150/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 5; 151/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 5; 152/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 5; 153/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 5; 154/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 5; 155/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 5; 156/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 5; 157/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 5; 158/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 5; 159/469 \tMinibatch Loss 0.055  Accuracy 99%\n",
      "Iteration 5; 160/469 \tMinibatch Loss 0.046  Accuracy 99%\n",
      "Iteration 5; 161/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 5; 162/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 5; 163/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 5; 164/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 5; 165/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 5; 166/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 5; 167/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 5; 168/469 \tMinibatch Loss 0.067  Accuracy 99%\n",
      "Iteration 5; 169/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 5; 170/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 5; 171/469 \tMinibatch Loss 0.103  Accuracy 97%\n",
      "Iteration 5; 172/469 \tMinibatch Loss 0.029  Accuracy 99%\n",
      "Iteration 5; 173/469 \tMinibatch Loss 0.052  Accuracy 97%\n",
      "Iteration 5; 174/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 5; 175/469 \tMinibatch Loss 0.062  Accuracy 99%\n",
      "Iteration 5; 176/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 5; 177/469 \tMinibatch Loss 0.056  Accuracy 97%\n",
      "Iteration 5; 178/469 \tMinibatch Loss 0.038  Accuracy 99%\n",
      "Iteration 5; 179/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 5; 180/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 181/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 5; 182/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 5; 183/469 \tMinibatch Loss 0.020  Accuracy 100%\n",
      "Iteration 5; 184/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 5; 185/469 \tMinibatch Loss 0.059  Accuracy 99%\n",
      "Iteration 5; 186/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 5; 187/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 5; 188/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 5; 189/469 \tMinibatch Loss 0.071  Accuracy 97%\n",
      "Iteration 5; 190/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 5; 191/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 5; 192/469 \tMinibatch Loss 0.041  Accuracy 99%\n",
      "Iteration 5; 193/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 5; 194/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 5; 195/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 5; 196/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 5; 197/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 198/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 5; 199/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 5; 200/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 5; 201/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 5; 202/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 5; 203/469 \tMinibatch Loss 0.043  Accuracy 98%\n",
      "Iteration 5; 204/469 \tMinibatch Loss 0.091  Accuracy 97%\n",
      "Iteration 5; 205/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 5; 206/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 5; 207/469 \tMinibatch Loss 0.037  Accuracy 99%\n",
      "Iteration 5; 208/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 5; 209/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 5; 210/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 5; 211/469 \tMinibatch Loss 0.142  Accuracy 97%\n",
      "Iteration 5; 212/469 \tMinibatch Loss 0.023  Accuracy 98%\n",
      "Iteration 5; 213/469 \tMinibatch Loss 0.021  Accuracy 100%\n",
      "Iteration 5; 214/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 5; 215/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 5; 216/469 \tMinibatch Loss 0.060  Accuracy 97%\n",
      "Iteration 5; 217/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 5; 218/469 \tMinibatch Loss 0.035  Accuracy 98%\n",
      "Iteration 5; 219/469 \tMinibatch Loss 0.043  Accuracy 98%\n",
      "Iteration 5; 220/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 5; 221/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 222/469 \tMinibatch Loss 0.061  Accuracy 98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5; 223/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 5; 224/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 5; 225/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 5; 226/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 5; 227/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 5; 228/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 5; 229/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 5; 230/469 \tMinibatch Loss 0.041  Accuracy 99%\n",
      "Iteration 5; 231/469 \tMinibatch Loss 0.045  Accuracy 99%\n",
      "Iteration 5; 232/469 \tMinibatch Loss 0.026  Accuracy 98%\n",
      "Iteration 5; 233/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 5; 234/469 \tMinibatch Loss 0.020  Accuracy 98%\n",
      "Iteration 5; 235/469 \tMinibatch Loss 0.064  Accuracy 99%\n",
      "Iteration 5; 236/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 5; 237/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 5; 238/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 239/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 5; 240/469 \tMinibatch Loss 0.012  Accuracy 99%\n",
      "Iteration 5; 241/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 5; 242/469 \tMinibatch Loss 0.011  Accuracy 99%\n",
      "Iteration 5; 243/469 \tMinibatch Loss 0.073  Accuracy 98%\n",
      "Iteration 5; 244/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 5; 245/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 5; 246/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 5; 247/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 5; 248/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 5; 249/469 \tMinibatch Loss 0.020  Accuracy 98%\n",
      "Iteration 5; 250/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 5; 251/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 5; 252/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 5; 253/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 5; 254/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 5; 255/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 256/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 5; 257/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 258/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 259/469 \tMinibatch Loss 0.002  Accuracy 100%\n",
      "Iteration 5; 260/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 261/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 5; 262/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 5; 263/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 5; 264/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 5; 265/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 5; 266/469 \tMinibatch Loss 0.016  Accuracy 99%\n",
      "Iteration 5; 267/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 5; 268/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 5; 269/469 \tMinibatch Loss 0.055  Accuracy 99%\n",
      "Iteration 5; 270/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 5; 271/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 5; 272/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 5; 273/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 5; 274/469 \tMinibatch Loss 0.042  Accuracy 99%\n",
      "Iteration 5; 275/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 5; 276/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 5; 277/469 \tMinibatch Loss 0.074  Accuracy 98%\n",
      "Iteration 5; 278/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 279/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 5; 280/469 \tMinibatch Loss 0.058  Accuracy 99%\n",
      "Iteration 5; 281/469 \tMinibatch Loss 0.059  Accuracy 98%\n",
      "Iteration 5; 282/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 5; 283/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 284/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 5; 285/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 5; 286/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 5; 287/469 \tMinibatch Loss 0.059  Accuracy 97%\n",
      "Iteration 5; 288/469 \tMinibatch Loss 0.046  Accuracy 98%\n",
      "Iteration 5; 289/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 290/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 5; 291/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 5; 292/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 5; 293/469 \tMinibatch Loss 0.077  Accuracy 98%\n",
      "Iteration 5; 294/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 5; 295/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 5; 296/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 5; 297/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 5; 298/469 \tMinibatch Loss 0.011  Accuracy 99%\n",
      "Iteration 5; 299/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 5; 300/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 5; 301/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 5; 302/469 \tMinibatch Loss 0.034  Accuracy 100%\n",
      "Iteration 5; 303/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 5; 304/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 5; 305/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 306/469 \tMinibatch Loss 0.026  Accuracy 100%\n",
      "Iteration 5; 307/469 \tMinibatch Loss 0.017  Accuracy 100%\n",
      "Iteration 5; 308/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 5; 309/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 5; 310/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 5; 311/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 5; 312/469 \tMinibatch Loss 0.067  Accuracy 98%\n",
      "Iteration 5; 313/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 5; 314/469 \tMinibatch Loss 0.047  Accuracy 98%\n",
      "Iteration 5; 315/469 \tMinibatch Loss 0.026  Accuracy 99%\n",
      "Iteration 5; 316/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 317/469 \tMinibatch Loss 0.124  Accuracy 98%\n",
      "Iteration 5; 318/469 \tMinibatch Loss 0.002  Accuracy 100%\n",
      "Iteration 5; 319/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 5; 320/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 5; 321/469 \tMinibatch Loss 0.076  Accuracy 98%\n",
      "Iteration 5; 322/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 5; 323/469 \tMinibatch Loss 0.011  Accuracy 99%\n",
      "Iteration 5; 324/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 325/469 \tMinibatch Loss 0.098  Accuracy 96%\n",
      "Iteration 5; 326/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 5; 327/469 \tMinibatch Loss 0.073  Accuracy 97%\n",
      "Iteration 5; 328/469 \tMinibatch Loss 0.037  Accuracy 98%\n",
      "Iteration 5; 329/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 5; 330/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 5; 331/469 \tMinibatch Loss 0.106  Accuracy 98%\n",
      "Iteration 5; 332/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 5; 333/469 \tMinibatch Loss 0.045  Accuracy 97%\n",
      "Iteration 5; 334/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 5; 335/469 \tMinibatch Loss 0.081  Accuracy 96%\n",
      "Iteration 5; 336/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 5; 337/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 5; 338/469 \tMinibatch Loss 0.054  Accuracy 97%\n",
      "Iteration 5; 339/469 \tMinibatch Loss 0.077  Accuracy 98%\n",
      "Iteration 5; 340/469 \tMinibatch Loss 0.052  Accuracy 98%\n",
      "Iteration 5; 341/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 342/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 5; 343/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 5; 344/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 5; 345/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 5; 346/469 \tMinibatch Loss 0.054  Accuracy 97%\n",
      "Iteration 5; 347/469 \tMinibatch Loss 0.064  Accuracy 96%\n",
      "Iteration 5; 348/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 5; 349/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 5; 350/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 5; 351/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 5; 352/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 5; 353/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 5; 354/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 5; 355/469 \tMinibatch Loss 0.148  Accuracy 96%\n",
      "Iteration 5; 356/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 5; 357/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 5; 358/469 \tMinibatch Loss 0.024  Accuracy 98%\n",
      "Iteration 5; 359/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 5; 360/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 5; 361/469 \tMinibatch Loss 0.054  Accuracy 99%\n",
      "Iteration 5; 362/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 363/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 5; 364/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 5; 365/469 \tMinibatch Loss 0.027  Accuracy 98%\n",
      "Iteration 5; 366/469 \tMinibatch Loss 0.032  Accuracy 98%\n",
      "Iteration 5; 367/469 \tMinibatch Loss 0.047  Accuracy 98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5; 368/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 5; 369/469 \tMinibatch Loss 0.023  Accuracy 100%\n",
      "Iteration 5; 370/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 5; 371/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 5; 372/469 \tMinibatch Loss 0.055  Accuracy 99%\n",
      "Iteration 5; 373/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 5; 374/469 \tMinibatch Loss 0.036  Accuracy 98%\n",
      "Iteration 5; 375/469 \tMinibatch Loss 0.041  Accuracy 99%\n",
      "Iteration 5; 376/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 5; 377/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 5; 378/469 \tMinibatch Loss 0.077  Accuracy 97%\n",
      "Iteration 5; 379/469 \tMinibatch Loss 0.027  Accuracy 98%\n",
      "Iteration 5; 380/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 5; 381/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 5; 382/469 \tMinibatch Loss 0.066  Accuracy 97%\n",
      "Iteration 5; 383/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 5; 384/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 5; 385/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 5; 386/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 5; 387/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 5; 388/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 5; 389/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 5; 390/469 \tMinibatch Loss 0.021  Accuracy 98%\n",
      "Iteration 5; 391/469 \tMinibatch Loss 0.019  Accuracy 99%\n",
      "Iteration 5; 392/469 \tMinibatch Loss 0.012  Accuracy 99%\n",
      "Iteration 5; 393/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 5; 394/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 5; 395/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 5; 396/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 5; 397/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 5; 398/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 5; 399/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 5; 400/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 5; 401/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 402/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 5; 403/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 5; 404/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 5; 405/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 5; 406/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 5; 407/469 \tMinibatch Loss 0.035  Accuracy 99%\n",
      "Iteration 5; 408/469 \tMinibatch Loss 0.004  Accuracy 100%\n",
      "Iteration 5; 409/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 5; 410/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 5; 411/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 5; 412/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 413/469 \tMinibatch Loss 0.001  Accuracy 100%\n",
      "Iteration 5; 414/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 5; 415/469 \tMinibatch Loss 0.174  Accuracy 99%\n",
      "Iteration 5; 416/469 \tMinibatch Loss 0.084  Accuracy 98%\n",
      "Iteration 5; 417/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 5; 418/469 \tMinibatch Loss 0.076  Accuracy 98%\n",
      "Iteration 5; 419/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 5; 420/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 5; 421/469 \tMinibatch Loss 0.060  Accuracy 97%\n",
      "Iteration 5; 422/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 5; 423/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 5; 424/469 \tMinibatch Loss 0.020  Accuracy 98%\n",
      "Iteration 5; 425/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 5; 426/469 \tMinibatch Loss 0.028  Accuracy 98%\n",
      "Iteration 5; 427/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 5; 428/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 5; 429/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 5; 430/469 \tMinibatch Loss 0.025  Accuracy 100%\n",
      "Iteration 5; 431/469 \tMinibatch Loss 0.044  Accuracy 98%\n",
      "Iteration 5; 432/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 5; 433/469 \tMinibatch Loss 0.082  Accuracy 98%\n",
      "Iteration 5; 434/469 \tMinibatch Loss 0.012  Accuracy 100%\n",
      "Iteration 5; 435/469 \tMinibatch Loss 0.020  Accuracy 100%\n",
      "Iteration 5; 436/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 5; 437/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 5; 438/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 5; 439/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 5; 440/469 \tMinibatch Loss 0.050  Accuracy 99%\n",
      "Iteration 5; 441/469 \tMinibatch Loss 0.030  Accuracy 98%\n",
      "Iteration 5; 442/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 5; 443/469 \tMinibatch Loss 0.040  Accuracy 99%\n",
      "Iteration 5; 444/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 5; 445/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 5; 446/469 \tMinibatch Loss 0.103  Accuracy 96%\n",
      "Iteration 5; 447/469 \tMinibatch Loss 0.017  Accuracy 99%\n",
      "Iteration 5; 448/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 5; 449/469 \tMinibatch Loss 0.005  Accuracy 100%\n",
      "Iteration 5; 450/469 \tMinibatch Loss 0.014  Accuracy 99%\n",
      "Iteration 5; 451/469 \tMinibatch Loss 0.034  Accuracy 99%\n",
      "Iteration 5; 452/469 \tMinibatch Loss 0.035  Accuracy 98%\n",
      "Iteration 5; 453/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 5; 454/469 \tMinibatch Loss 0.021  Accuracy 98%\n",
      "Iteration 5; 455/469 \tMinibatch Loss 0.065  Accuracy 99%\n",
      "Iteration 5; 456/469 \tMinibatch Loss 0.024  Accuracy 98%\n",
      "Iteration 5; 457/469 \tMinibatch Loss 0.110  Accuracy 97%\n",
      "Iteration 5; 458/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 5; 459/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 460/469 \tMinibatch Loss 0.020  Accuracy 100%\n",
      "Iteration 5; 461/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 5; 462/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 5; 463/469 \tMinibatch Loss 0.007  Accuracy 100%\n",
      "Iteration 5; 464/469 \tMinibatch Loss 0.018  Accuracy 100%\n",
      "Iteration 5; 465/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 5; 466/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 5; 467/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 5; 468/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "saving model at: weights/mnist_test_6iter_10c_simpleCNN_256.pth\n"
     ]
    }
   ],
   "source": [
    "train(mnist_model, mnist_train_loader, mnist_train_optimizer, MAX_ITER_MNIST, MNIST_PATH, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from: weights/mnist_test_6iter_10c_simpleCNN_256.pth\n",
      "Batch 0/79 \tAccuracy 100%\n",
      "Batch 10/79 \tAccuracy 98%\n",
      "Batch 20/79 \tAccuracy 98%\n",
      "Batch 30/79 \tAccuracy 99%\n",
      "Batch 40/79 \tAccuracy 100%\n",
      "Batch 50/79 \tAccuracy 98%\n",
      "Batch 60/79 \tAccuracy 100%\n",
      "Batch 70/79 \tAccuracy 97%\n",
      "overall test accuracy on MNIST: 98.95 %\n"
     ]
    }
   ],
   "source": [
    "#predict in distribution\n",
    "MNIST_PATH = \"weights/mnist_test_6iter_10c_simpleCNN_256.pth\"\n",
    "\n",
    "#mnist_model = LPADirNN(x=100)\n",
    "mnist_model = LPADirNN(num_LL=256).cuda()\n",
    "print(\"loading model from: {}\".format(MNIST_PATH))\n",
    "mnist_model.load_state_dict(torch.load(MNIST_PATH))\n",
    "mnist_model.eval()\n",
    "\n",
    "acc = []\n",
    "\n",
    "max_len = len(mnist_test_loader)\n",
    "for batch_idx, (x, y) in enumerate(mnist_test_loader):\n",
    "\n",
    "    x, y = x.cuda(), y.cuda()\n",
    "    output = mnist_model(x)\n",
    "\n",
    "    accuracy = get_accuracy(output, y)\n",
    "    if batch_idx % 10 == 0:\n",
    "        print(\n",
    "            \"Batch {}/{} \\t\".format(batch_idx, max_len) + \n",
    "            \"Accuracy %.0f\" % (accuracy * 100) + \"%\"\n",
    "        )\n",
    "    acc.append(accuracy)\n",
    "\n",
    "avg_acc = np.mean(acc)\n",
    "print('overall test accuracy on MNIST: {:.02f} %'.format(avg_acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## play around with Backpack\n",
    "def get_Hessian_NN(model, train_loader, var0, device='cpu', verbose=True):\n",
    "    lossfunc = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    extend(lossfunc, debug=False)\n",
    "    extend(model, debug=False)\n",
    "\n",
    "    Hessian_diag = []\n",
    "    for param in mnist_model.parameters():\n",
    "        ps = param.size()\n",
    "        print(\"parameter size: \", ps)\n",
    "        Hessian_diag.append(torch.zeros(ps, device=device))\n",
    "        #print(param.numel())\n",
    "\n",
    "    tau = 1/var0\n",
    "    max_len = len(train_loader)\n",
    "\n",
    "    with backpack(DiagHessian()):\n",
    "\n",
    "        for batch_idx, (x, y) in enumerate(train_loader):\n",
    "\n",
    "            if device == 'cuda':\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss = lossfunc(model(x), y)\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Hessian of weight\n",
    "                for idx, param in enumerate(model.parameters()):\n",
    "\n",
    "                    H_ = param.diag_h\n",
    "                    #add bias here\n",
    "                    H_ += tau * torch.ones(H_.size(), device=device)\n",
    "\n",
    "                    rho = min(1-1/(batch_idx+1), 0.995)\n",
    "\n",
    "                    Hessian_diag[idx] = rho*Hessian_diag[idx] + (1-rho)*H_\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Batch: {}/{}\".format(batch_idx, max_len))\n",
    "\n",
    "    #combine all elements of the Hessian to one big vector\n",
    "    Hessian_diag = torch.cat([el.view(-1) for el in Hessian_diag])\n",
    "    print(\"Hessian_size: \", Hessian_diag.size())\n",
    "    num_params = np.sum([p.numel() for p in model.parameters()])\n",
    "    assert(num_params == Hessian_diag.size(-1))\n",
    "    return(Hessian_diag)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter size:  torch.Size([32, 1, 5, 5])\n",
      "parameter size:  torch.Size([32])\n",
      "parameter size:  torch.Size([64, 32, 5, 5])\n",
      "parameter size:  torch.Size([64])\n",
      "parameter size:  torch.Size([256, 1024])\n",
      "parameter size:  torch.Size([256])\n",
      "parameter size:  torch.Size([10, 256])\n",
      "parameter size:  torch.Size([10])\n",
      "Hessian_size:  torch.Size([317066])\n"
     ]
    }
   ],
   "source": [
    "Hessian_MNIST = get_Hessian_NN(model=mnist_model, train_loader=mnist_train_loader, var0=200, verbose=False, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0057, 0.0060, 0.0068,  ..., 0.0067, 0.0073, 0.0071], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(Hessian_MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jacobians_with_backpack(model, x, y, lossfunc):\n",
    "    \"\"\"\n",
    "    Returns the jacobians of the network\n",
    "\n",
    "    The output is a list. Each element in the list is a tensor\n",
    "    corresponding to the model.parameters().\n",
    "\n",
    "    The tensor are of the form [N, *, C] where N is the batch dimension,\n",
    "    C is the number of classes (output size of the network)\n",
    "    and * is the shape of the model parameters\n",
    "    \"\"\"\n",
    "    loss = lossfunc(model(x), y)\n",
    "\n",
    "    with backpack(NetJac()):\n",
    "        loss.backward()\n",
    "\n",
    "    jacs = []\n",
    "    for p in model.parameters():\n",
    "        jacs.append(p.netjacs.data.detach())\n",
    "    return jacs\n",
    "\n",
    "def transform2full_jac(backpack_jacobian):\n",
    "\n",
    "    jac_full = []\n",
    "    #batch_size\n",
    "    N = backpack_jacobian[0].size(0)\n",
    "    #num classes\n",
    "    k = backpack_jacobian[0].size(-1)\n",
    "    for j in backpack_jacobian:\n",
    "        jac_full.append(j.view(N, -1, k).permute(0,2,1))\n",
    "    jac_full = torch.cat(jac_full, dim=-1)\n",
    "    return(jac_full)\n",
    "\n",
    "def get_Jacobian(model, x, y, lossfunc):\n",
    "    return(transform2full_jac(compute_jacobians_with_backpack(model, x, y, lossfunc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_Diagonal_full(model, test_loader, Hessian, verbose=True, num_samples=100, cuda=False, timing=False):\n",
    "    \n",
    "    lossfunc = torch.nn.CrossEntropyLoss()\n",
    "    extend(lossfunc, debug=False)\n",
    "    \n",
    "    py = []\n",
    "    if timing:\n",
    "        time_sum = 0\n",
    "    \n",
    "    max_len = len(test_loader)\n",
    "    for batch_idx, (x, y) in enumerate(test_loader):\n",
    "        \n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        \n",
    "        J = get_Jacobian(model, x, y, lossfunc)\n",
    "        J = J.detach()\n",
    "        batch_size = J.size(0)\n",
    "        num_classes = J.size(1)\n",
    "        Cov_pred = torch.bmm(J * Hessian, J.permute(0, 2, 1))\n",
    "        Cov_pred = Cov_pred.detach()\n",
    "        if verbose:\n",
    "            print(\"Jacobian size: \", J.size())\n",
    "            print(\"cov pred size: \", Cov_pred.size())\n",
    "        \n",
    "        mu_pred = model(x).detach()\n",
    "        post_pred = MultivariateNormal(mu_pred, Cov_pred)\n",
    "\n",
    "        # MC-integral\n",
    "        t0 = time.time()\n",
    "        py_ = 0\n",
    "\n",
    "        for _ in range(num_samples):\n",
    "            f_s = post_pred.rsample()\n",
    "            py_ += torch.softmax(f_s, 1)\n",
    "\n",
    "\n",
    "        py_ /= num_samples\n",
    "        py_ = py_.detach()\n",
    "\n",
    "        py.append(py_)\n",
    "        t1 = time.time()\n",
    "        if timing:\n",
    "            time_sum += (t1-t0)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Batch: {}/{}\".format(batch_idx, max_len))\n",
    "    \n",
    "    if timing:\n",
    "        print(\"total time used for transform: {:.05f}\".format(time_sum))\n",
    "\n",
    "    return torch.cat(py, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TEST_FMNIST = 128\n",
    "BATCH_SIZE_TEST_KMNIST = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FMNIST_test = torchvision.datasets.FashionMNIST(\n",
    "        '~/data/fmnist', train=False, download=True,\n",
    "        transform=MNIST_transform)   #torchvision.transforms.ToTensor())\n",
    "\n",
    "FMNIST_test_loader = torch.utils.data.DataLoader(\n",
    "    FMNIST_test,\n",
    "    batch_size=BATCH_SIZE_TEST_FMNIST, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "KMNIST_test = torchvision.datasets.KMNIST(\n",
    "        '~/data/kmnist', train=False, download=True,\n",
    "        transform=MNIST_transform)\n",
    "\n",
    "KMNIST_test_loader = torch.utils.data.DataLoader(\n",
    "    KMNIST_test,\n",
    "    batch_size=BATCH_SIZE_TEST_KMNIST, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load notMNIST\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from matplotlib.pyplot import imread\n",
    "from torch import Tensor\n",
    "\n",
    "\"\"\"\n",
    "Loads the train/test set. \n",
    "Every image in the dataset is 28x28 pixels and the labels are numbered from 0-9\n",
    "for A-J respectively.\n",
    "Set root to point to the Train/Test folders.\n",
    "\"\"\"\n",
    "\n",
    "# Creating a sub class of torch.utils.data.dataset.Dataset\n",
    "class notMNIST(Dataset):\n",
    "\n",
    "    # The init method is called when this class will be instantiated\n",
    "    def __init__(self, root, transform):\n",
    "        \n",
    "        #super(notMNIST, self).__init__(root, transform=transform)\n",
    "\n",
    "        self.transform = transform\n",
    "        \n",
    "        Images, Y = [], []\n",
    "        folders = os.listdir(root)\n",
    "\n",
    "        for folder in folders:\n",
    "            folder_path = os.path.join(root, folder)\n",
    "            for ims in os.listdir(folder_path):\n",
    "                try:\n",
    "                    img_path = os.path.join(folder_path, ims)\n",
    "                    Images.append(np.array(imread(img_path)))\n",
    "                    Y.append(ord(folder) - 65)  # Folders are A-J so labels will be 0-9\n",
    "                except:\n",
    "                    # Some images in the dataset are damaged\n",
    "                    print(\"File {}/{} is broken\".format(folder, ims))\n",
    "        data = [(x, y) for x, y in zip(Images, Y)]\n",
    "        self.data = data\n",
    "        self.targets = torch.Tensor(Y)\n",
    "\n",
    "    # The number of items in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # The Dataloader is a generator that repeatedly calls the getitem method.\n",
    "    # getitem is supposed to return (X, Y) for the specified index.\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index][0]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        # Input for Conv2D should be Channels x Height x Width\n",
    "        img_tensor = Tensor(img).view(1, 28, 28).float()\n",
    "        label = self.data[index][1]\n",
    "        return (img_tensor, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png is broken\n",
      "File A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png is broken\n"
     ]
    }
   ],
   "source": [
    "#root = os.path.abspath('~/data')\n",
    "root = os.path.expanduser('~/data')\n",
    "\n",
    "# Instantiating the notMNIST dataset class we created\n",
    "notMNIST_test = notMNIST(root=os.path.join(root, 'notMNIST_small'),\n",
    "                               transform=MNIST_transform)\n",
    "\n",
    "# Creating a dataloader\n",
    "not_mnist_test_loader = torch.utils.data.dataloader.DataLoader(\n",
    "                            dataset=notMNIST_test,\n",
    "                            batch_size=BATCH_SIZE_TEST_KMNIST,\n",
    "                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_in_dist_values(py_in, targets):\n",
    "    acc_in = np.mean(np.argmax(py_in, 1) == targets)\n",
    "    prob_correct = np.choose(targets, py_in.T).mean()\n",
    "    average_entropy = -np.sum(py_in*np.log(py_in+1e-8), axis=1).mean()\n",
    "    MMC = py_in.max(1).mean()\n",
    "    return(acc_in, prob_correct, average_entropy, MMC)\n",
    "    \n",
    "def get_out_dist_values(py_in, py_out, targets):\n",
    "    average_entropy = -np.sum(py_out*np.log(py_out+1e-8), axis=1).mean()\n",
    "    acc_out = np.mean(np.argmax(py_out, 1) == targets)\n",
    "    prob_correct = np.choose(targets, py_out.T).mean()\n",
    "    labels = np.zeros(len(py_in)+len(py_out), dtype='int32')\n",
    "    labels[:len(py_in)] = 1\n",
    "    examples = np.concatenate([py_in.max(1), py_out.max(1)])\n",
    "    auroc = roc_auc_score(labels, examples)\n",
    "    MMC = py_out.max(1).mean()\n",
    "    return(acc_out, prob_correct, average_entropy, MMC, auroc)\n",
    "\n",
    "def print_in_dist_values(acc_in, prob_correct, average_entropy, MMC, train='mnist', method='LLLA-KF'):\n",
    "    \n",
    "    print(f'[In, {method}, {train}] Accuracy: {acc_in:.3f}; average entropy: {average_entropy:.3f}; \\\n",
    "    MMC: {MMC:.3f}; Prob @ correct: {prob_correct:.3f}')\n",
    "\n",
    "\n",
    "def print_out_dist_values(acc_out, prob_correct, average_entropy, MMC, auroc, train='mnist', test='FMNIST', method='LLLA-KF'):\n",
    "   \n",
    "    print(f'[Out-{test}, {method}, {train}] Accuracy: {acc_out:.3f}; Average entropy: {average_entropy:.3f};\\\n",
    "    MMC: {MMC:.3f}; AUROC: {auroc:.3f}; Prob @ correct: {prob_correct:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = MNIST_test.targets.numpy()\n",
    "targets_FMNIST = FMNIST_test.targets.numpy()\n",
    "targets_notMNIST = notMNIST_test.targets.numpy().astype(int)\n",
    "targets_KMNIST = KMNIST_test.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test_in_MAP = predict_MAP(mnist_model, mnist_test_loader, cuda=True).cpu().numpy()\n",
    "mnist_test_out_fmnist_MAP = predict_MAP(mnist_model, FMNIST_test_loader, cuda=True).cpu().numpy()\n",
    "mnist_test_out_notMNIST_MAP = predict_MAP(mnist_model, not_mnist_test_loader, cuda=True).cpu().numpy()\n",
    "mnist_test_out_KMNIST_MAP = predict_MAP(mnist_model, KMNIST_test_loader, cuda=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP = get_in_dist_values(mnist_test_in_MAP, targets)\n",
    "acc_out_FMNIST_MAP, prob_correct_out_FMNIST_MAP, ent_out_FMNIST_MAP, MMC_out_FMNIST_MAP, auroc_out_FMNIST_MAP = get_out_dist_values(mnist_test_in_MAP, mnist_test_out_fmnist_MAP, targets_FMNIST)\n",
    "acc_out_notMNIST_MAP, prob_correct_out_notMNIST_MAP, ent_out_notMNIST_MAP, MMC_out_notMNIST_MAP, auroc_out_notMNIST_MAP = get_out_dist_values(mnist_test_in_MAP, mnist_test_out_notMNIST_MAP, targets_notMNIST)\n",
    "acc_out_KMNIST_MAP, prob_correct_out_KMNIST_MAP, ent_out_KMNIST_MAP, MMC_out_KMNIST_MAP, auroc_out_KMNIST_MAP = get_out_dist_values(mnist_test_in_MAP, mnist_test_out_KMNIST_MAP, targets_KMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, MAP, mnist] Accuracy: 0.989; average entropy: 0.035;     MMC: 0.989; Prob @ correct: 0.984\n",
      "[Out-MAP, LLLA-KF, FMNIST] Accuracy: 0.099; Average entropy: 1.392;    MMC: 0.513; AUROC: 0.992; Prob @ correct: 0.107\n",
      "[Out-MAP, LLLA-KF, notMNIST] Accuracy: 0.110; Average entropy: 0.807;    MMC: 0.709; AUROC: 0.952; Prob @ correct: 0.114\n",
      "[Out-MAP, LLLA-KF, KMNIST] Accuracy: 0.085; Average entropy: 0.867;    MMC: 0.687; AUROC: 0.974; Prob @ correct: 0.086\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP, 'mnist', 'MAP')\n",
    "print_out_dist_values(acc_out_FMNIST_MAP, prob_correct_out_FMNIST_MAP, ent_out_FMNIST_MAP, MMC_out_FMNIST_MAP, auroc_out_FMNIST_MAP, 'FMNIST', 'MAP')\n",
    "print_out_dist_values(acc_out_notMNIST_MAP, prob_correct_out_notMNIST_MAP, ent_out_notMNIST_MAP, MMC_out_notMNIST_MAP, auroc_out_notMNIST_MAP, 'notMNIST', 'MAP')\n",
    "print_out_dist_values(acc_out_KMNIST_MAP, prob_correct_out_KMNIST_MAP, ent_out_KMNIST_MAP, MMC_out_KMNIST_MAP, auroc_out_KMNIST_MAP, 'KMNIST', 'MAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.990 with std 0.002\n",
      "MMC in: 0.989 with std 0.001\n",
      "MMC out fmnist: 0.538 with std 0.022\n",
      "MMC out notmnist: 0.706 with std 0.014\n",
      "MMC out kmnist: 0.684 with std 0.015\n",
      "AUROC out fmnist: 0.990 with std 0.001\n",
      "AUROC out notmnist: 0.954 with std 0.007\n",
      "AUROC out kmnist: 0.974 with std 0.005\n"
     ]
    }
   ],
   "source": [
    "#MAP estimate\n",
    "#seeds are 123,124,125,126,127\n",
    "acc_in = [0.991, 0.990, 0.993, 0.988, 0.989]\n",
    "mmc_in = [0.988, 0.990, 0.989, 0.989, 0.989]\n",
    "mmc_out_fmnist = [0.516, 0.571, 0.534, 0.554, 0.513]\n",
    "mmc_out_notmnist = [0.692, 0.731, 0.696, 0.702, 0.709]\n",
    "mmc_out_kmnist = [0.678, 0.697, 0.659, 0.700, 0.687]\n",
    "\n",
    "auroc_out_fmnist = [0.989, 0.990, 0.990, 0.989, 0.992]\n",
    "auroc_out_notmnist = [0.964, 0.942, 0.959, 0.952, 0.952]\n",
    "auroc_out_kmnist = [0.970, 0.977, 0.980, 0.967, 0.974]\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out fmnist: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_fmnist), np.std(mmc_out_fmnist)))\n",
    "print(\"MMC out notmnist: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_notmnist), np.std(mmc_out_notmnist)))\n",
    "print(\"MMC out kmnist: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_kmnist), np.std(mmc_out_kmnist)))\n",
    "\n",
    "print(\"AUROC out fmnist: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_fmnist), np.std(auroc_out_fmnist)))\n",
    "print(\"AUROC out notmnist: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_notmnist), np.std(auroc_out_notmnist)))\n",
    "print(\"AUROC out kmnist: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_kmnist), np.std(auroc_out_kmnist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diag Hessian Sampling estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used for transform: 6.67633\n",
      "total time used for transform: 6.67161\n",
      "total time used for transform: 12.42572\n",
      "total time used for transform: 6.68149\n"
     ]
    }
   ],
   "source": [
    "mnist_test_in_D = predict_Diagonal_full(mnist_model, mnist_test_loader, Hessian_MNIST, verbose=False, cuda=True, timing=True, num_samples=1000).cpu().numpy()\n",
    "mnist_test_out_FMNIST_D = predict_Diagonal_full(mnist_model, FMNIST_test_loader, Hessian_MNIST, verbose=False, cuda=True, timing=True, num_samples=1000).cpu().numpy()\n",
    "mnist_test_out_notMNIST_D = predict_Diagonal_full(mnist_model, not_mnist_test_loader, Hessian_MNIST, verbose=False, cuda=True, timing=True, num_samples=1000).cpu().numpy()\n",
    "mnist_test_out_KMNIST_D = predict_Diagonal_full(mnist_model, KMNIST_test_loader, Hessian_MNIST, verbose=False, cuda=True, timing=True, num_samples=1000).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D = get_in_dist_values(mnist_test_in_D, targets)\n",
    "acc_out_FMNIST_D, prob_correct_out_FMNIST_D, ent_out_FMNIST_D, MMC_out_FMNIST_D, auroc_out_FMNIST_D = get_out_dist_values(mnist_test_in_D, mnist_test_out_FMNIST_D, targets_FMNIST)\n",
    "acc_out_notMNIST_D, prob_correct_out_notMNIST_D, ent_out_notMNIST_D, MMC_out_notMNIST_D, auroc_out_notMNIST_D = get_out_dist_values(mnist_test_in_D, mnist_test_out_notMNIST_D, targets_notMNIST)\n",
    "acc_out_KMNIST_D, prob_correct_out_KMNIST_D, ent_out_KMNIST_D, MMC_out_KMNIST_D, auroc_out_KMNIST_D = get_out_dist_values(mnist_test_in_D, mnist_test_out_KMNIST_D, targets_KMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, Diag, mnist] Accuracy: 0.990; average entropy: 0.224;     MMC: 0.942; Prob @ correct: 0.939\n",
      "[Out-fmnist, Diag, mnist] Accuracy: 0.102; Average entropy: 1.701;    MMC: 0.401; AUROC: 0.992; Prob @ correct: 0.111\n",
      "[Out-notMNIST, Diag, mnist] Accuracy: 0.108; Average entropy: 1.283;    MMC: 0.544; AUROC: 0.959; Prob @ correct: 0.116\n",
      "[Out-KMNIST, Diag, mnist] Accuracy: 0.086; Average entropy: 1.337;    MMC: 0.512; AUROC: 0.975; Prob @ correct: 0.086\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D, 'mnist', 'Diag')\n",
    "print_out_dist_values(acc_out_FMNIST_D, prob_correct_out_FMNIST_D, ent_out_FMNIST_D, MMC_out_FMNIST_D, auroc_out_FMNIST_D, test='fmnist', method='Diag')\n",
    "print_out_dist_values(acc_out_notMNIST_D, prob_correct_out_notMNIST_D, ent_out_notMNIST_D, MMC_out_notMNIST_D, auroc_out_notMNIST_D, test='notMNIST', method='Diag')\n",
    "print_out_dist_values(acc_out_KMNIST_D, prob_correct_out_KMNIST_D, ent_out_KMNIST_D, MMC_out_KMNIST_D, auroc_out_KMNIST_D, test='KMNIST', method='Diag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Bridge time in: 6.619 with std 0.122\n",
      "Sampling Bridge time out fmnist: 6.602 with std 0.123\n",
      "Sampling Bridge time out notmnist: 12.331 with std 0.254\n",
      "Sampling Bridge time out kmnist: 6.626 with std 0.138\n",
      "accuracy: 0.990 with std 0.002\n",
      "MMC in: 0.752 with std 0.355\n",
      "MMC out fmnist: 0.407 with std 0.010\n",
      "MMC out notmnist: 0.535 with std 0.018\n",
      "MMC out kmnist: 0.500 with std 0.014\n",
      "AUROC out fmnist: 0.989 with std 0.002\n",
      "AUROC out notmnist: 0.958 with std 0.006\n",
      "AUROC out kmnist: 0.974 with std 0.005\n"
     ]
    }
   ],
   "source": [
    "#Diag Sampling\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [6.78413, 6.67228, 6.51112,6.44895, 6.67633]\n",
    "time_lpb_out_fmnist = [6.77055, 6.64844, 6.47705,6.44392,6.67161]\n",
    "time_lpb_out_notmnist = [12.65939, 12.49839, 11.99764, 12.07371, 12.42572]\n",
    "time_lpb_out_kmnist = [6.79133, 6.73237, 6.46135, 6.46563, 6.68149]\n",
    "\n",
    "acc_in = [0.991, 0.990, 0.993, 0.988, 0.990]\n",
    "mmc_in = [0.928, 0.938, 0.927, 0.924, 0.042]\n",
    "mmc_out_fmnist = [0.397, 0.426, 0.406, 0.406, 0.401]\n",
    "mmc_out_notmnist = [0.517, 0.560, 0.526, 0.518, 0.554]\n",
    "mmc_out_kmnist = [0.514, 0.503, 0.475, 0.497, 0.512]\n",
    "\n",
    "auroc_out_fmnist = [0.986, 0.990, 0.988, 0.990, 0.992]\n",
    "auroc_out_notmnist = [0.968, 0.948, 0.959, 0.958, 0.959]\n",
    "auroc_out_kmnist = [0.967, 0.978, 0.980, 0.970, 0.975]\n",
    "\n",
    "print(\"Sampling Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Sampling Bridge time out fmnist: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_fmnist), np.std(time_lpb_out_fmnist)))\n",
    "print(\"Sampling Bridge time out notmnist: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_notmnist), np.std(time_lpb_out_notmnist)))\n",
    "print(\"Sampling Bridge time out kmnist: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_kmnist), np.std(time_lpb_out_kmnist)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out fmnist: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_fmnist), np.std(mmc_out_fmnist)))\n",
    "print(\"MMC out notmnist: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_notmnist), np.std(mmc_out_notmnist)))\n",
    "print(\"MMC out kmnist: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_kmnist), np.std(mmc_out_kmnist)))\n",
    "\n",
    "print(\"AUROC out fmnist: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_fmnist), np.std(auroc_out_fmnist)))\n",
    "print(\"AUROC out notmnist: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_notmnist), np.std(auroc_out_notmnist)))\n",
    "print(\"AUROC out kmnist: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_kmnist), np.std(auroc_out_kmnist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet Laplace Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha_from_Normal(mu, Sigma):\n",
    "    batch_size, K = mu.size(0), mu.size(-1)\n",
    "    Sigma_d = torch.diagonal(Sigma, dim1=1, dim2=2)\n",
    "    sum_exp = torch.sum(torch.exp(-1*mu), dim=1).view(-1,1)\n",
    "    alpha = 1/Sigma_d * (1 - 2/K + torch.exp(mu)/K**2 * sum_exp)\n",
    "    \n",
    "    assert(alpha.size() == mu.size())\n",
    "    \n",
    "    return(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_DIR_LPA(model, test_loader, Hessian, verbose=True, cuda=False, timing=False):\n",
    "\n",
    "    lossfunc = torch.nn.CrossEntropyLoss()\n",
    "    extend(lossfunc, debug=False)\n",
    "    \n",
    "    alphas = []\n",
    "    if timing:\n",
    "        time_sum = 0\n",
    "\n",
    "    max_len = len(test_loader)\n",
    "    for batch_idx, (x, y) in enumerate(test_loader):\n",
    "        \n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        J = get_Jacobian(model, x, y, lossfunc)\n",
    "        J = J.detach()\n",
    "        batch_size = J.size(0)\n",
    "        num_classes = J.size(1)\n",
    "        Cov_pred = torch.bmm(J * Hessian, J.permute(0, 2, 1))\n",
    "        Cov_pred = Cov_pred.detach()\n",
    "        \n",
    "        mu_pred = model(x).detach()\n",
    "        \n",
    "        t0 = time.time()\n",
    "        alpha = get_alpha_from_Normal(mu_pred, Cov_pred)\n",
    "        t1 = time.time()\n",
    "        alpha = alpha.detach()\n",
    "        if timing:\n",
    "            time_sum += (t1 - t0)\n",
    "\n",
    "        alphas.append(alpha)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Batch: {}/{}\".format(batch_idx, max_len))\n",
    "    \n",
    "    if timing:\n",
    "        print(\"total time used for transform: {:.05f}\".format(time_sum))\n",
    "\n",
    "    return(torch.cat(alphas, dim = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used for transform: 0.01609\n",
      "total time used for transform: 0.01563\n",
      "total time used for transform: 0.02892\n",
      "total time used for transform: 0.01547\n"
     ]
    }
   ],
   "source": [
    "mnist_test_in_DIR_LPA = predict_DIR_LPA(mnist_model, mnist_test_loader, Hessian_MNIST, verbose=False, cuda=True, timing=True).cpu().numpy()\n",
    "mnist_test_out_FMNIST_DIR_LPA = predict_DIR_LPA(mnist_model, FMNIST_test_loader, Hessian_MNIST, verbose=False, cuda=True, timing=True).cpu().numpy()\n",
    "mnist_test_out_notMNIST_DIR_LPA = predict_DIR_LPA(mnist_model, not_mnist_test_loader, Hessian_MNIST, verbose=False, cuda=True, timing=True).cpu().numpy()\n",
    "mnist_test_out_KMNIST_DIR_LPA = predict_DIR_LPA(mnist_model, KMNIST_test_loader, Hessian_MNIST, verbose=False, cuda=True, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test_in_DIR_LPAn = mnist_test_in_DIR_LPA/mnist_test_in_DIR_LPA.sum(1).reshape(-1,1)\n",
    "mnist_test_out_FMNIST_DIR_LPAn = mnist_test_out_FMNIST_DIR_LPA/mnist_test_out_FMNIST_DIR_LPA.sum(1).reshape(-1,1)\n",
    "mnist_test_out_notMNIST_DIR_LPAn = mnist_test_out_notMNIST_DIR_LPA/mnist_test_out_notMNIST_DIR_LPA.sum(1).reshape(-1,1)\n",
    "mnist_test_out_KMNIST_DIR_LPAn = mnist_test_out_KMNIST_DIR_LPA/mnist_test_out_KMNIST_DIR_LPA.sum(1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_DIR_LPAn, prob_correct_in_DIR_LPAn, ent_in_DIR_LPAn, MMC_in_DIR_LPAn = get_in_dist_values(mnist_test_in_DIR_LPAn, targets)\n",
    "acc_out_FMNIST_DIR_LPAn, prob_correct_out_FMNIST_DIR_LPAn, ent_out_FMNIST_DIR_LPAn, MMC_out_FMNIST_DIR_LPAn, auroc_out_FMNIST_DIR_LPAn = get_out_dist_values(mnist_test_in_DIR_LPAn, mnist_test_out_FMNIST_DIR_LPAn, targets_FMNIST)\n",
    "acc_out_notMNIST_DIR_LPAn, prob_correct_out_notMNIST_DIR_LPAn, ent_out_notMNIST_DIR_LPAn, MMC_out_notMNIST_DIR_LPAn, auroc_out_notMNIST_DIR_LPAn = get_out_dist_values(mnist_test_in_DIR_LPAn, mnist_test_out_notMNIST_DIR_LPAn, targets_notMNIST)\n",
    "acc_out_KMNIST_DIR_LPAn, prob_correct_out_KMNIST_DIR_LPAn, ent_out_KMNIST_DIR_LPAn, MMC_out_KMNIST_DIR_LPAn, auroc_out_KMNIST_DIR_LPAn = get_out_dist_values(mnist_test_in_DIR_LPAn, mnist_test_out_KMNIST_DIR_LPAn, targets_KMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, DIR_LPAn, mnist] Accuracy: 0.989; average entropy: 0.044;     MMC: 0.987; Prob @ correct: 0.982\n",
      "[Out-fmnist, DIR_LPAn, mnist] Accuracy: 0.080; Average entropy: 1.811;    MMC: 0.364; AUROC: 0.995; Prob @ correct: 0.095\n",
      "[Out-notMNIST, DIR_LPAn, mnist] Accuracy: 0.122; Average entropy: 1.038;    MMC: 0.644; AUROC: 0.958; Prob @ correct: 0.123\n",
      "[Out-KMNIST, DIR_LPAn, mnist] Accuracy: 0.086; Average entropy: 1.061;    MMC: 0.633; AUROC: 0.974; Prob @ correct: 0.086\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_DIR_LPAn, prob_correct_in_DIR_LPAn, ent_in_DIR_LPAn, MMC_in_DIR_LPAn, 'mnist', 'DIR_LPAn')\n",
    "print_out_dist_values(acc_out_FMNIST_DIR_LPAn, prob_correct_out_FMNIST_DIR_LPAn, ent_out_FMNIST_DIR_LPAn, MMC_out_FMNIST_DIR_LPAn, auroc_out_FMNIST_DIR_LPAn, test='fmnist', method='DIR_LPAn')\n",
    "print_out_dist_values(acc_out_notMNIST_DIR_LPAn, prob_correct_out_notMNIST_DIR_LPAn, ent_out_notMNIST_DIR_LPAn, MMC_out_notMNIST_DIR_LPAn, auroc_out_notMNIST_DIR_LPAn, test='notMNIST', method='DIR_LPAn')\n",
    "print_out_dist_values(acc_out_KMNIST_DIR_LPAn, prob_correct_out_KMNIST_DIR_LPAn, ent_out_KMNIST_DIR_LPAn, MMC_out_KMNIST_DIR_LPAn, auroc_out_KMNIST_DIR_LPAn, test='KMNIST', method='DIR_LPAn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplace Bridge time in: 0.016 with std 0.000\n",
      "Laplace Bridge time out fmnist: 0.016 with std 0.000\n",
      "Laplace Bridge time out notmnist: 0.029 with std 0.000\n",
      "Laplace Bridge time out kmnist: 0.016 with std 0.000\n",
      "accuracy: 0.990 with std 0.002\n",
      "MMC in: 0.987 with std 0.001\n",
      "MMC out fmnist: 0.377 with std 0.019\n",
      "MMC out notmnist: 0.644 with std 0.018\n",
      "MMC out kmnist: 0.630 with std 0.018\n",
      "AUROC out fmnist: 0.994 with std 0.002\n",
      "AUROC out notmnist: 0.962 with std 0.007\n",
      "AUROC out kmnist: 0.975 with std 0.004\n"
     ]
    }
   ],
   "source": [
    "#Laplace Bridge\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [0.01622, 0.01575, 0.01573, 0.01557, 0.01609]\n",
    "time_lpb_out_fmnist = [0.01598, 0.01579, 0.01562, 0.01549, 0.01563]\n",
    "time_lpb_out_notmnist = [0.02956, 0.02926, 0.02902, 0.02869, 0.02892]\n",
    "time_lpb_out_kmnist = [0.01596, 0.01571, 0.01557, 0.01550, 0.01547]\n",
    "\n",
    "acc_in = [0.991, 0.990, 0.993, 0.988, 0.989]\n",
    "mmc_in = [0.984, 0.988, 0.987, 0.988, 0.987]\n",
    "mmc_out_fmnist = [0.368, 0.413, 0.363, 0.378, 0.364]\n",
    "mmc_out_notmnist = [0.626, 0.678, 0.636, 0.638, 0.644]\n",
    "mmc_out_kmnist = [0.628, 0.652, 0.598, 0.639, 0.633]\n",
    "\n",
    "auroc_out_fmnist = [0.991, 0.994, 0.995, 0.995, 0.995]\n",
    "auroc_out_notmnist = [0.970, 0.951, 0.966, 0.963, 0.958]\n",
    "auroc_out_kmnist = [0.969, 0.977, 0.981, 0.972, 0.974]\n",
    "\n",
    "print(\"Laplace Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Laplace Bridge time out fmnist: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_fmnist), np.std(time_lpb_out_fmnist)))\n",
    "print(\"Laplace Bridge time out notmnist: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_notmnist), np.std(time_lpb_out_notmnist)))\n",
    "print(\"Laplace Bridge time out kmnist: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_kmnist), np.std(time_lpb_out_kmnist)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out fmnist: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_fmnist), np.std(mmc_out_fmnist)))\n",
    "print(\"MMC out notmnist: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_notmnist), np.std(mmc_out_notmnist)))\n",
    "print(\"MMC out kmnist: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_kmnist), np.std(mmc_out_kmnist)))\n",
    "\n",
    "print(\"AUROC out fmnist: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_fmnist), np.std(auroc_out_fmnist)))\n",
    "print(\"AUROC out notmnist: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_notmnist), np.std(auroc_out_notmnist)))\n",
    "print(\"AUROC out kmnist: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_kmnist), np.std(auroc_out_kmnist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# additional Calculations for the Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import digamma, loggamma\n",
    "\n",
    "def beta_function(alpha):\n",
    "    return(np.exp(np.sum([loggamma(a_i) for a_i in alpha]) - loggamma(np.sum(alpha))))\n",
    "\n",
    "def alphas_norm(alphas):\n",
    "    alphas = np.array(alphas)\n",
    "    return(alphas/alphas.sum(axis=1).reshape(-1,1))\n",
    "\n",
    "def alphas_variance(alphas):\n",
    "    alphas = np.array(alphas)\n",
    "    norm = alphas_norm(alphas)\n",
    "    nom = norm * (1 - norm)\n",
    "    den = alphas.sum(axis=1).reshape(-1,1) + 1\n",
    "    return(nom/den)\n",
    "\n",
    "def log_beta_function(alpha):\n",
    "    return(np.sum([loggamma(a_i) for a_i in alpha]) - loggamma(np.sum(alpha)))\n",
    "\n",
    "def alphas_entropy(alphas):\n",
    "    K = len(alphas[0])\n",
    "    alphas = np.array(alphas)\n",
    "    entropy = []\n",
    "    for x in alphas:\n",
    "        B = log_beta_function(x)\n",
    "        alpha_0 = np.sum(x)\n",
    "        C = (alpha_0 - K)*digamma(alpha_0)\n",
    "        D = np.sum((x-1)*digamma(x))\n",
    "        entropy.append(B + C - D)\n",
    "    \n",
    "    return(np.array(entropy))\n",
    "        \n",
    "\n",
    "def alphas_log_prob(alphas):\n",
    "    alphas = np.array(alphas)\n",
    "    dig_sum = digamma(alphas.sum(axis=1).reshape(-1,1))\n",
    "    log_prob = digamma(alphas) - dig_sum\n",
    "    return(log_prob)\n",
    "\n",
    "def auroc_entropy(alphas_in, alphas_out):\n",
    "    \n",
    "    entropy_in = alphas_entropy(alphas_in)\n",
    "    entropy_out = alphas_entropy(alphas_out)\n",
    "    labels = np.zeros(len(entropy_in)+len(entropy_out), dtype='int32')\n",
    "    labels[:len(entropy_in)] = 1\n",
    "    examples = np.concatenate([entropy_in, entropy_out])\n",
    "    auroc_ent = roc_auc_score(labels, examples)\n",
    "    return(auroc_ent)\n",
    "\n",
    "def auroc_variance(alphas_in, alphas_out, method='mean'):\n",
    "    \n",
    "    if method=='mean':\n",
    "        variance_in = alphas_variance(alphas_in).mean(1)\n",
    "        variance_out = alphas_variance(alphas_out).mean(1)\n",
    "    elif method=='max':\n",
    "        variance_in = alphas_variance(alphas_in).max(1)\n",
    "        variance_out = alphas_variance(alphas_out).max(1)\n",
    "    labels = np.zeros(len(variance_in)+len(variance_out), dtype='int32')\n",
    "    labels[:len(variance_in)] = 1\n",
    "    examples = np.concatenate([variance_in, variance_out])\n",
    "    auroc_ent = roc_auc_score(labels, examples)\n",
    "    return(auroc_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"auroc entropy: MNIST in, FMNIST out: \", 1 - auroc_entropy(alphas_in=mnist_test_in_DIR_LPA, alphas_out=mnist_test_out_FMNIST_DIR_LPA))\n",
    "print(\"auroc entropy: MNIST in, notMNIST out: \", 1 - auroc_entropy(alphas_in=mnist_test_in_DIR_LPA, alphas_out=mnist_test_out_notMNIST_DIR_LPA))\n",
    "print(\"auroc entropy: MNIST in, KMNIST out: \", 1 - auroc_entropy(alphas_in=mnist_test_in_DIR_LPA, alphas_out=mnist_test_out_KMNIST_DIR_LPA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"auroc variance: MNIST in, FMNIST out: \", 1-auroc_variance(alphas_in=mnist_test_in_DIR_LPA, alphas_out=mnist_test_out_FMNIST_DIR_LPA, method='mean'))\n",
    "print(\"auroc variance: MNIST in, notMNIST out: \", 1-auroc_variance(alphas_in=mnist_test_in_DIR_LPA, alphas_out=mnist_test_out_notMNIST_DIR_LPA, method='mean'))\n",
    "print(\"auroc variance: MNIST in, KMNIST out: \", 1-auroc_variance(alphas_in=mnist_test_in_DIR_LPA, alphas_out=mnist_test_out_KMNIST_DIR_LPA, method='mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"auroc variance: MNIST in, FMNIST out: \", 1-auroc_variance(alphas_in=mnist_test_in_DIR_LPA, alphas_out=mnist_test_out_FMNIST_DIR_LPA, method='max'))\n",
    "print(\"auroc variance: MNIST in, notMNIST out: \", 1-auroc_variance(alphas_in=mnist_test_in_DIR_LPA, alphas_out=mnist_test_out_notMNIST_DIR_LPA, method='max'))\n",
    "print(\"auroc variance: MNIST in, KMNIST out: \", 1-auroc_variance(alphas_in=mnist_test_in_DIR_LPA, alphas_out=mnist_test_out_KMNIST_DIR_LPA, method='max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
